---
applyTo: '**'
---
Provide project context and coding guidelines that AI should follow when generating code, answering questions, or reviewing changes.

# 知識グラフベクトルデータベース要件定義仕様書

**プロジェクト**: long_memory_MCP  
**作成日**: 2025年8月18日  
**バージョン**: v1.0  
**対象**: 知識グラフ + ベクトルデータベース統合アーキテクチャ  

---

## 📋 **文書概要**

long_memory_MCPプロジェクトは、LLMの長期記憶問題を解決するために、**ハイブリッドデータベース設計**を採用しています。本仕様書では、知識グラフとベクトルデータベースの統合要件を詳細に定義します。

### **解決すべき課題**

1. **LLMの記憶喪失**: 数百行を超えると前提条件を忘れる
2. **セマンティック検索**: 意味的類似性による記憶検索
3. **構造化知識**: エンティティ間の関係性管理
4. **透明なUX**: ユーザーに意識させない自動記憶補完

---

## 🎓 **知識グラフ入門 - 初心者向け解説**

### **🏠 知識グラフって何？～家系図から始めよう～**

知識グラフとは、**「情報同士のつながりを見える化したもの」**です。一番身近な例は**家系図**です！

```text
    おじいちゃん ━━━ おばあちゃん
         │
    ┌────┴────┐
   お父さん    叔父さん
    │         │
   あなた    いとこ
```

この家系図では：

- **ノード（丸）**: 人物（おじいちゃん、お父さん、あなた など）
- **エッジ（線）**: 関係性（「親子」「夫婦」「兄弟」）

### **🗺️ 駅の路線図で考えてみよう**

もう一つの例は**電車の路線図**です：

```text
新宿駅 ━━ 代々木駅 ━━ 原宿駅 ━━ 表参道駅
  │                        │
渋谷駅 ━━━━━━━━━━━━━━━━ 明治神宮前駅
```

- **ノード**: 各駅
- **エッジ**: 路線（「JR山手線でつながっている」「徒歩5分」）
- **検索**: 「新宿から表参道まで最短ルートは？」→ グラフを辿って答えを見つける

### **🧠 long_memory_MCPの知識グラフ**

私たちのシステムでは、**あなたの記憶や知識**を家系図や路線図のように整理します：

```text
    プロジェクトA
        │
    ┌───┼───┐
   田中さん  APIキー  締切日
    │       │       │
  同僚関係  管理者   2025/8/20
```

- **ノード**: 人物、プロジェクト、ファイル、アイデア など
- **エッジ**: 「関わっている」「使用している」「期限がある」など

### **🔍 なぜ知識グラフが必要？**

#### **1. 忘れた時の思い出しやすさ**

**普通のメモ帳の場合:**

```text
・田中さんとミーティング
・APIキーの更新
・プロジェクトAの締切
```

→ バラバラで関係性が分からない 😵

**知識グラフの場合:**

```text
田中さん ━━ プロジェクトA ━━ 締切日
            │
         APIキー更新
```

→ 「あ、田中さんのプロジェクトでAPIキーの件があったな！」と芋づる式に思い出せる 💡

#### **2. 意外な発見**

- 「田中さん」で検索 → プロジェクトA → 似たような過去のプロジェクトB → 「そういえばあの時の解決策が使えるかも！」

#### **3. 自動的な記憶の整理**

- 新しい情報「田中さんからメール」→ 自動で「田中さん」ノードに接続
- 「プロジェクトA」の関連情報として整理される

### **🤖 ベクトルデータベースとの組み合わせ**

知識グラフだけだと「完全一致」でしか探せません。そこで**ベクトルデータベース**を組み合わせます。

#### **例：あいまい検索**

- あなた：「確か去年の夏に誰かとやったプロジェクトで...」
- 普通の検索：「"去年の夏"」「"プロジェクト"」で完全一致検索 → 見つからない 😞
- ベクトル検索：「夏っぽい」「プロジェクトっぽい」で意味的に似た記憶を発見 → 「7月の田中さんとのシステム開発」が見つかる！ 🎯

### **🎯 long_memory_MCPでの実際の使い方**

1. **記憶の保存**: 「田中さんとミーティングした」

   - 自動で「田中さん」「ミーティング」「今日の日付」のノードを作成
   - あなたの過去の「田中さん」記憶と自動でつなげる

2. **記憶の検索**: 「田中さんのプロジェクトどうなったっけ？」

   - 「田中さん」ノードから関連する全ての記憶を芋づる式に取得
   - 時系列や重要度で整理して表示

3. **透明な体験**: あなたは何も意識しない

   - GitHub CopilotやClaude Desktopが裏で自動実行
   - 普通に会話しているだけで、関連する記憶が自動で思い出される

### **📚 専門用語の簡単説明**

| 専門用語 | 簡単な説明 | たとえ |
|---------|-----------|-------|
| **ノード** | 情報の塊、丸いポイント | 駅、人物 |
| **エッジ** | つながり、関係性 | 路線、親子関係 |
| **グラフ** | ノードとエッジの全体 | 路線図、家系図 |
| **ベクトル** | 意味を数値で表現したもの | 「犬」と「ワンちゃん」は似ている数値になる |
| **セマンティック検索** | 意味で検索すること | 「犬」で検索して「ワンちゃん」も見つかる |
| **エンティティ** | 「もの」「こと」の単位 | 人、場所、出来事 |

---

## 🏗️ **アーキテクチャ設計**

### **レイヤード・アーキテクチャ**

```text
┌─────────────────────────┐
│   知識グラフ層（論理層）   │  ← エンティティ関係性の抽象化
├─────────────────────────┤
│  ベクトル検索層（sqlite-vec） │  ← セマンティック類似性検索
├─────────────────────────┤
│ 構造化データ層（SQLite）   │  ← メタデータ、関係性、エンティティ管理
└─────────────────────────┘
```

#### **1. 構造化データ層（SQLite）**

- **目的**: メタデータ、関係性、エンティティ管理
- **役割**: 正確なデータ整合性、複雑なクエリ、トランザクション管理

#### **2. ベクトル検索層（sqlite-vec）**

- **目的**: セマンティック類似性検索
- **役割**: 意味的近似、あいまい検索、テキスト埋め込み

#### **3. 知識グラフ層（論理層）**

- **目的**: エンティティ関係性の抽象化
- **役割**: グラフトラバーサル、パス検索、関係推論

---

## 🗃️ **データベーススキーマ設計**

### **🎯 スキーマ設計の基本思想～お料理のレシピ本で例えよう～**

データベーススキーマは**「料理のレシピ本の構成」**のようなものです！

#### **📖 普通のレシピ本（単純なデータベース）**

```text
ページ1: カレーの作り方
ページ2: パスタの作り方
ページ3: サラダの作り方
```

→ レシピ同士の関係が分からない😞

#### **🌐 知識グラフレシピ本（私たちのシステム）**

```text
カレー ━━━ ニンジン ━━━ サラダ
  │         │          │
スパイス    根菜       野菜
  │         │          │
インド料理  煮物    ヘルシー料理
```

→ 材料から新しいレシピを発見！✨

#### **🔍 意味検索レシピ本**

「辛い料理が作りたい」→ カレー、キムチ、麻婆豆腐 が自動で見つかる！

### **🏗️ 私たちのテーブル設計戦略**

#### **1️⃣ memories テーブル = レシピカード**

- 1つ1つのレシピ（記憶）を丁寧に保存
- 材料（キーワード）、作り方（内容）、評価（重要度）

#### **2️⃣ memory_links テーブル = 関連性カード**

- レシピ同士の関係を記録
- 「カレーとナンは相性が良い」「パスタとサラダはセット」

#### **3️⃣ entities テーブル = 材料・道具カタログ**

- 人物、場所、物、概念を整理
- 「ニンジン」「フライパン」「田中さん」「プロジェクトA」

---

### **1. コアテーブル構造**

#### **1.1 memories テーブル（記憶の宝石箱）**

##### **💎 あなたの記憶を丁寧に保管する宝石箱**

```sql
CREATE TABLE memories (
    -- 🆔 基本識別情報（身元証明書）
    id INTEGER PRIMARY KEY AUTOINCREMENT,  -- 記憶の背番号
    user_id TEXT NOT NULL,                 -- 「これは誰の記憶？」
    device_id TEXT NOT NULL,               -- 「どのデバイスから生まれた？」
    session_id TEXT NOT NULL,              -- 「どの会話セッションで？」
    
    -- 📝 記憶の実体（記憶の中身そのもの）
    raw_text TEXT NOT NULL,                -- あなたが実際に言った言葉（絶対に改変しない）
    raw_audio BLOB,                        -- 音声データ（将来実装予定）
    summary_text TEXT,                     -- 人間が読みやすい要約
    micro_summary TEXT,                    -- 超短要約（50-80文字、一覧表示用）
    
    -- 📊 メタデータ（記憶の性質・品質情報）
    importance_score REAL,                 -- 重要度（0-1、1が最重要）
    category TEXT,                         -- カテゴリ分類（work/personal/learningなど）
    usage_count INTEGER DEFAULT 0,         -- 何回参照されたか（人気度）
    decay_score REAL,                      -- 時間減衰後の記憶の強さ
    consolidated_flag INTEGER DEFAULT 0,   -- 他の記憶と統合済みか（重複排除）
    relation_labels TEXT,                  -- 関係性ラベル（JSON配列形式）
    
    -- 📍 位置・時間情報（記憶の文脈）
    latitude REAL,                         -- 緯度（どこで生まれた記憶？）
    longitude REAL,                        -- 経度
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, -- 記憶の誕生日時
    updated_at DATETIME,                   -- 最後に内容が更新された日時
    last_used_at DATETIME,                 -- 最後に参照された日時
    invalidated_at DATETIME,               -- 無効になった日時（削除予定）
    
    -- 🔧 拡張データ（将来の機能用）
    extra_data JSON                        -- 何でも入る魔法のポケット
);
```

##### **🔍 重要フィールドの詳細解説**

| フィールド | 料理例 | プログラミング例 | なぜ重要？ |
|-----------|--------|-----------------|-----------|
| **raw_text** | 「塩を少々」 | 「バグ修正完了」 | あなたの言葉をそのまま保存。後で「なんて言ったっけ？」に対応 |
| **summary_text** | 「塩分調整」 | 「不具合解決」 | 長い文章をスッキリ要約。検索・表示しやすく |
| **importance_score** | 0.9（秘伝のコツ）| 0.8（重要なバグ）| 大事な記憶を優先表示 |
| **usage_count** | 10回参照 | 3回参照 | よく使う記憶ほど上位表示 |
| **decay_score** | 0.7（少し忘れかけ）| 0.9（最近の記憶）| 古い記憶は薄れるが、重要なものは残る |

#### **🚀 高速検索のためのインデックス（辞書の見出し）**

```sql
-- 📖 よく使われる検索パターンに対応
CREATE INDEX idx_memories_user_id ON memories(user_id);              -- ユーザー別高速検索
CREATE INDEX idx_memories_session_id ON memories(session_id);        -- セッション別表示
CREATE INDEX idx_memories_created_at ON memories(created_at);        -- 時系列ソート
CREATE INDEX idx_memories_importance_score ON memories(importance_score);
CREATE INDEX idx_memories_category ON memories(category);
CREATE INDEX idx_memories_decay_score ON memories(decay_score);
```

#### **1.2 memory_links テーブル（知識グラフエッジ）**

##### **💕 記憶同士の絆を記録する相関図**

このテーブルは**「SNSの友達関係図」**のようなものです：

```text
田中さんのプロフィール ━━━ プロジェクトAのプロフィール
        │                        │
    「同僚関係」              「参加している」
    ├─ 信頼度: 0.8            ├─ 信頼度: 0.9
    ├─ 証拠: 3回一緒に言及      ├─ 証拠: 5回言及
    └─ 方向: 双方向           └─ 方向: 一方向
```

**🎯 なぜ関係性を記録するの？**

- **芋づる式発見**: 「田中さん」→「プロジェクトA」→「期限」→「重要事項」
- **文脈理解**: 単体では意味不明な記憶も、関係性で理解可能
- **予測推論**: 過去パターンから「AならばおそらくB」を推測

```sql
CREATE TABLE memory_links (
    -- 🆔 基本情報（関係の身元証明）
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    src_memory_id INTEGER NOT NULL,  -- 関係の始点「Aさんは...」
    dst_memory_id INTEGER NOT NULL,  -- 関係の終点「...Bさんと友達」
    user_id TEXT NOT NULL,           -- ユーザー分離（他人の人間関係と混ざらない）
    
    -- 🔗 関係性定義（どんな関係？）
    relation_type TEXT NOT NULL DEFAULT 'co_occurrence', -- 関係の種類
    relation_subtype TEXT,           -- より詳細な関係（「親友」「元恋人」「部下」など）
    direction TEXT DEFAULT 'bidirectional', -- 方向性（片想い？両想い？）
    
    -- ⚖️ 証拠・重み（どれくらい確からしい？）
    weight REAL NOT NULL DEFAULT 1.0,      -- この関係の強さ（0-1）
    evidence_count INTEGER NOT NULL DEFAULT 1, -- 証拠の回数「3回一緒に言及」
    confidence_score REAL DEFAULT 0.5,     -- 関係の確信度（AIの推定精度）
    
    -- 🔬 抽出情報（どうやって関係を発見した？）
    extraction_method TEXT,          -- 発見手法（AI判定/ルール/手動入力）
    extraction_confidence REAL,     -- 抽出時のAI信頼度
    keywords_common TEXT,            -- 共通して出現するキーワード
    context_window INTEGER,          -- 何文字範囲で一緒に出現したか
    
    -- ⏰ 時間管理（関係の履歴）
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, -- 関係発見日時
    updated_at DATETIME,             -- 関係情報更新日時
    last_used_at DATETIME,           -- 最後に参照された日時
    last_evidence_at DATETIME,       -- 最後に証拠が見つかった日時
    
    -- ✅ 品質管理（関係の信頼性）
    validation_status TEXT DEFAULT 'unvalidated', -- 検証状態
    validation_by TEXT,              -- 誰が検証したか（user/system/AI）
    notes TEXT,                      -- 関係性の説明メモ（128文字以下）
    
    -- 🔗 外部キー制約（データ整合性）
    FOREIGN KEY (src_memory_id) REFERENCES memories(id) ON DELETE CASCADE,
    FOREIGN KEY (dst_memory_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- ユニーク制約（同一関係の重複防止）
CREATE UNIQUE INDEX uq_memory_links_pair 
ON memory_links(src_memory_id, dst_memory_id, relation_type);

##### **🌟 関係タイプの実例**

| relation_type | 日本語 | 実例 | direction | なぜ重要？ |
|--------------|--------|------|-----------|----------|
| **co_occurrence** | 共起 | 「田中さん」と「プロジェクトA」が同じ文に登場 | 双方向 | 基本的な関連性発見 |
| **temporal_sequence** | 時系列 | 「ミーティング」→「議事録作成」 | 一方向 | 作業フローの理解 |
| **semantic_similarity** | 意味類似 | 「開発」と「実装」 | 双方向 | 同義語・類語の発見 |
| **causality** | 因果関係 | 「バグ発見」→「修正作業」 | 一方向 | 原因と結果の理解 |
| **reference** | 参照 | 「前回の件」→ 具体的な過去記憶 | 一方向 | 文脈の復元 |

```sql
-- 検索用インデックス
CREATE INDEX idx_memory_links_src ON memory_links(src_memory_id);
CREATE INDEX idx_memory_links_dst ON memory_links(dst_memory_id);
CREATE INDEX idx_memory_links_user_id ON memory_links(user_id);
CREATE INDEX idx_memory_links_relation_type ON memory_links(relation_type);
CREATE INDEX idx_memory_links_weight ON memory_links(weight);
CREATE INDEX idx_memory_links_confidence ON memory_links(confidence_score);
CREATE INDEX idx_memory_links_last_used ON memory_links(last_used_at);
```

#### **1.3 entities テーブル（構造化エンティティ）**

##### **🏷️ 人物・場所・物事の名札システム**

entitiesテーブルは**「図書館の分類システム」**のようなものです：

```text
【人物カード】田中さん
├─ 正式名: 田中太郎
├─ 別名: 田中, たなかさん, Tanaka
├─ 分類: 同僚, エンジニア, プロジェクトリーダー
├─ 特徴: Python得意, コーヒー好き
└─ 最終言及: 2025/8/18

【プロジェクトカード】プロジェクトA
├─ 正式名: 新ECサイト開発
├─ 別名: プロジェクトA, EC案件
├─ 分類: Webアプリ開発, 商用システム
├─ 特徴: React使用, 3ヶ月案件
└─ 期限: 2025/12/1
```

##### **🎯 エンティティ管理の利点**

1. **名寄せ**: 「田中さん」「田中」「Tanaka」→ 同一人物として統合
2. **属性管理**: 人物の特徴、場所の詳細、概念の定義を整理
3. **横断検索**: 「田中さん関連の全記憶」を一発検索

```sql
CREATE TABLE entities (
    -- 🆔 基本識別（エンティティの身元証明書）
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    entity_id TEXT NOT NULL,         -- グローバル一意ID（パスポートのような番号）
    user_id TEXT NOT NULL,           -- ユーザー分離
    
    -- 🏷️ エンティティ属性（名札の内容）
    entity_type TEXT NOT NULL,       -- 大分類（Person/Location/Event/Concept/Object）
    entity_subtype TEXT,             -- 小分類（Engineer/Restaurant/Meeting/Programming）
    name TEXT NOT NULL,              -- 正式名称（「田中太郎」「プロジェクトA」）
    aliases TEXT,                    -- 別名・呼び方リスト（JSON配列）
    description TEXT,                -- 詳細説明（「Pythonが得意な同僚」）
    
    -- ✅ 品質・信頼性（この情報はどれくらい確か？）
    confidence_score REAL DEFAULT 0.5,     -- エンティティ情報の信頼度
    extraction_count INTEGER DEFAULT 1,    -- 何回言及されたか
    validation_status TEXT DEFAULT 'unvalidated', -- 検証済みかどうか
    
    -- 📋 属性情報（エンティティタイプ別の詳細情報）
    attributes JSON,                 -- 柔軟な属性格納（スキル、特徴、仕様など）
    coordinates JSON,                -- 位置情報（緯度経度、住所など）
    temporal_info JSON,              -- 時間情報（開始日、終了日、期限など）
    
    -- 📊 メタデータ（重要度・使用状況）
    importance_score REAL DEFAULT 0.5,     -- このエンティティの重要度
    usage_count INTEGER DEFAULT 0,         -- 参照回数
    last_mentioned_at DATETIME,            -- 最後に言及された日時
    
    -- ⏰ 時間管理
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME,
    merged_from TEXT,                -- 統合元エンティティID（重複解消履歴）
    
    -- 🔧 拡張データ
    extra_data JSON                  -- 将来の機能拡張用
);
```

##### **🔍 エンティティタイプの分類例**

| entity_type | 日本語 | 実例 | attributes例 |
|-------------|--------|------|-------------|
| **Person** | 人物 | 田中さん、佐藤部長 | `{"role": "engineer", "skills": ["Python"], "department": "IT"}` |
| **Location** | 場所 | 会議室A、カフェ | `{"address": "東京都...", "capacity": 10}` |
| **Event** | イベント | ミーティング、研修 | `{"date": "2025-08-20", "duration": "2h"}` |
| **Concept** | 概念 | プロジェクト、API | `{"status": "active", "tech_stack": ["React"]}` |
| **Object** | 物体 | 資料、ファイル | `{"format": "PDF", "size": "2MB"}` |

```sql
-- インデックス定義
CREATE UNIQUE INDEX uq_entities_user_entity_id ON entities(user_id, entity_id);
CREATE INDEX idx_entities_user_id ON entities(user_id);
CREATE INDEX idx_entities_type ON entities(entity_type);
CREATE INDEX idx_entities_name ON entities(name);
CREATE INDEX idx_entities_importance ON entities(importance_score);
CREATE INDEX idx_entities_last_mentioned ON entities(last_mentioned_at);
```

#### **1.4 entity_memory_links テーブル（エンティティ-記憶リンク）**

```sql
CREATE TABLE entity_memory_links (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    entity_id TEXT NOT NULL,
    memory_id INTEGER NOT NULL,
    user_id TEXT NOT NULL,
    
    -- リンク属性
    link_type TEXT NOT NULL,         -- mentions/describes/involves等
    relevance_score REAL DEFAULT 0.5, -- 関連度
    position_in_text INTEGER,        -- テキスト内位置
    context_window TEXT,             -- 周辺コンテキスト
    
    -- 抽出情報
    extraction_method TEXT,
    extraction_confidence REAL,
    
    -- 時間管理
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME,
    
    -- 外部キー制約
    FOREIGN KEY (entity_id) REFERENCES entities(entity_id),
    FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- インデックス定義
CREATE INDEX idx_entity_memory_links_entity ON entity_memory_links(entity_id);
CREATE INDEX idx_entity_memory_links_memory ON entity_memory_links(memory_id);
CREATE INDEX idx_entity_memory_links_user ON entity_memory_links(user_id);
CREATE INDEX idx_entity_memory_links_type ON entity_memory_links(link_type);
```

### **2. ベクトルテーブル構造（sqlite-vec）**

#### **🔬 ベクトル検索って何？～翻訳機の仕組みで理解しよう～**

ベクトルテーブルは**「Google翻訳の内部構造」**のようなものです：

##### **📝 従来の検索（完全一致）**

```text
「犬の飼い方」で検索
→ 「犬」「飼い方」が含まれる文章のみヒット
→ 「ワンちゃんのお世話」は見つからない 😞
```

##### **🧠 ベクトル検索（意味検索）**

```text
「犬の飼い方」で検索
↓ 意味をベクトル（数字の配列）に変換
[0.2, 0.8, 0.1, 0.9, ...] （384個の数字）
↓ 似た意味のベクトルを検索
「ワンちゃんのお世話」[0.3, 0.7, 0.2, 0.8, ...]
「ペットケア」[0.1, 0.9, 0.1, 0.7, ...]
→ 意味が似ている記憶も発見！✨
```

**🎯 なぜベクトル化するの？**

1. **言い換え対応**: 「急ぎ」「至急」「緊急」を同じ意味として検索
2. **部分一致**: 「プロジェクトの進捗」で「案件の状況」も発見
3. **感情理解**: 「困った」「やばい」「大変」の似た感情を検出

#### **2.1 vss_memories テーブル（メイン検索）**

##### **🚀 超高速意味検索の秘密基地**

```sql
-- sqlite-vec仮想テーブル（特殊な高速検索テーブル）
CREATE VIRTUAL TABLE vss_memories USING vec0(
    memory_id INTEGER PRIMARY KEY,  -- 記憶のID（memoriesテーブルと連携）
    embedding FLOAT[384],           -- 意味ベクトル（384個の数字で意味を表現）
                                   -- 既定: paraphrase-multilingual-MiniLM-L12-v2（ローカル/低コスト）
    user_id TEXT,                  -- ユーザー分離（他人の記憶と混ざらない）
    session_id TEXT,               -- セッション別管理
    extra_data JSON                -- 追加メタデータ
);

-- メタデータテーブル（検索フィルタ用）
CREATE TABLE vector_metadata (
    memory_id INTEGER PRIMARY KEY,
    user_id TEXT NOT NULL,
    session_id TEXT NOT NULL,
    device_id TEXT,
    
    -- 内容メタデータ
    text_length INTEGER,
    language TEXT,
    content_hash TEXT,              -- 内容のハッシュ値
    
    -- ベクトル情報
    embedding_model TEXT,           -- 使用した埋め込みモデル
    embedding_version TEXT,         -- モデルバージョン
    vector_dimension INTEGER,       -- ベクトル次元数
    
    -- 品質情報
    quality_score REAL,
    is_synthetic BOOLEAN DEFAULT FALSE, -- 合成データかどうか
    
    -- 時間情報
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    last_accessed_at DATETIME,
    
    -- 外部キー
    FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- インデックス定義
CREATE INDEX idx_vector_metadata_user_id ON vector_metadata(user_id);
CREATE INDEX idx_vector_metadata_session_id ON vector_metadata(session_id);
CREATE INDEX idx_vector_metadata_embedding_model ON vector_metadata(embedding_model);
CREATE INDEX idx_vector_metadata_content_hash ON vector_metadata(content_hash);
```

#### **2.2 vss_entities テーブル（エンティティベクトル）**

```sql
-- エンティティ用ベクトルテーブル
CREATE VIRTUAL TABLE vss_entities USING vec0(
    entity_id TEXT PRIMARY KEY,
    embedding FLOAT[384],           -- 既定: paraphrase-multilingual-MiniLM-L12-v2（ローカル/低コスト）
    user_id TEXT,
    entity_type TEXT
);

-- エンティティベクトルメタデータ
CREATE TABLE entity_vector_metadata (
    entity_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,
    entity_type TEXT NOT NULL,
    
    -- ベクトル生成情報
    source_type TEXT,               -- description/name/context等
    generation_method TEXT,         -- direct/aggregated/synthetic
    aggregated_from TEXT,           -- 集約元記憶ID（JSON配列）
    
    -- 品質情報
    confidence_score REAL,
    update_frequency INTEGER DEFAULT 0,
    
    -- 時間情報
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME,
    
    -- 外部キー
    FOREIGN KEY (entity_id) REFERENCES entities(entity_id)
);
```

### **3. 補助テーブル**

#### **3.1 graph_cache テーブル（経路キャッシュ）**

```sql
CREATE TABLE graph_cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    cache_key TEXT NOT NULL,        -- src_id|dst_id|depth_hash形式
    user_id TEXT NOT NULL,
    
    -- キャッシュ内容
    path_nodes TEXT NOT NULL,       -- ノード列（JSON配列）
    path_length INTEGER NOT NULL,
    total_weight REAL,
    
    -- メタデータ
    query_type TEXT,                -- shortest/strongest/recent等
    computation_cost INTEGER,       -- 計算コスト（ms）
    
    -- 時間管理
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    accessed_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    access_count INTEGER DEFAULT 1,
    ttl_seconds INTEGER DEFAULT 3600, -- 生存時間
    
    -- インデックス
    UNIQUE(cache_key, user_id)
);

CREATE INDEX idx_graph_cache_user_id ON graph_cache(user_id);
CREATE INDEX idx_graph_cache_accessed_at ON graph_cache(accessed_at);
```

#### **3.2 entity_types テーブル（エンティティタイプ管理）**

```sql
CREATE TABLE entity_types (
    type_name TEXT PRIMARY KEY,
    display_name TEXT NOT NULL,
    description TEXT,
    icon TEXT,                      -- 可視化用アイコン
    color TEXT,                     -- 可視化用色
    
    -- 階層構造
    parent_type TEXT,
    level INTEGER DEFAULT 0,
    
    -- 属性定義
    required_attributes JSON,       -- 必須属性リスト
    optional_attributes JSON,       -- オプション属性リスト
    validation_rules JSON,          -- 検証ルール
    
    -- メタデータ
    is_system_type BOOLEAN DEFAULT TRUE,
    is_user_defined BOOLEAN DEFAULT FALSE,
    usage_count INTEGER DEFAULT 0,
    
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME,
    
    FOREIGN KEY (parent_type) REFERENCES entity_types(type_name)
);

-- 基本エンティティタイプの初期データ
INSERT INTO entity_types (type_name, display_name, description, level) VALUES
('Person', '人物', '個人・人物・キャラクター', 0),
('Location', '場所', '地理的位置・建物・空間', 0),
('Event', '出来事', 'イベント・行動・変化', 0),
('Concept', '概念', '抽象的概念・アイデア', 0),
('Object', '物体', '有形・無形のオブジェクト', 0),
('Organization', '組織', '会社・団体・グループ', 0),
('TimeUnit', '時間', '時刻・期間・スケジュール', 0),
('Task', 'タスク', '作業・TODO・プロジェクト', 0),
('Document', '文書', 'ファイル・記録・参考資料', 0),
('Technology', '技術', 'ツール・システム・技術要素', 0);
```

#### **3.3 relation_types テーブル（関係タイプ管理）**

```sql
CREATE TABLE relation_types (
    type_name TEXT PRIMARY KEY,
    display_name TEXT NOT NULL,
    description TEXT,
    
    -- 関係属性
    is_directed BOOLEAN DEFAULT TRUE,    -- 有向性
    is_symmetric BOOLEAN DEFAULT FALSE,  -- 対称性
    transitivity TEXT DEFAULT 'none',    -- none/full/limited
    
    -- 適用可能エンティティタイプ
    source_types JSON,              -- 起点エンティティタイプ
    target_types JSON,              -- 終点エンティティタイプ
    
    -- 重み・信頼度
    default_weight REAL DEFAULT 1.0,
    confidence_threshold REAL DEFAULT 0.3,
    
    -- 可視化
    color TEXT,
    line_style TEXT,                -- solid/dashed/dotted
    arrow_style TEXT,
    
    -- システム属性
    is_system_type BOOLEAN DEFAULT TRUE,
    extraction_rules JSON,          -- 自動抽出ルール
    
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME
);

-- 基本関係タイプの初期データ
INSERT INTO relation_types (type_name, display_name, description, is_directed) VALUES
('mentions', '言及', 'エンティティへの言及・参照', FALSE),
('relates_to', '関連', '一般的な関連性', FALSE),
('contains', '包含', '物理的・論理的包含関係', TRUE),
('located_at', '位置', '場所・位置関係', TRUE),
('participates_in', '参加', 'イベント・活動への参加', TRUE),
('causes', '原因', '因果関係', TRUE),
('co_occurrence', '共起', '同時出現・共起', FALSE),
('sequence', '連続', '時系列・順序関係', TRUE),
('similarity', '類似', '類似性・共通性', FALSE),
('opposition', '対立', '対立・対比関係', FALSE),
('dependency', '依存', '依存関係', TRUE),
('ownership', '所有', '所有・帰属関係', TRUE);
```

---

## 🔗 **データ間関係性設計**

### **1. 主要な関係パターン**

#### **1.1 記憶-記憶関係（MemoryLink）**

```python
# 関係タイプ分類
MEMORY_RELATION_TYPES = {
    # 時間的関係
    'temporal_sequence': '時間的連続',      # 時系列
    'temporal_parallel': '時間的並行',      # 同時期
    'temporal_causality': '時間的因果',     # 前後関係
    
    # 内容的関係
    'semantic_similarity': '意味的類似',    # 内容類似
    'thematic_connection': 'テーマ関連',    # 同一テーマ
    'conceptual_hierarchy': '概念階層',     # 上下関係
    
    # 構造的関係
    'reference': '参照',                   # 明示的参照
    'elaboration': '詳細化',              # 詳細説明
    'contradiction': '矛盾',              # 矛盾関係
    
    # コンテキスト関係
    'same_session': '同一セッション',       # セッション内
    'conversation_flow': '会話流れ',       # 対話の流れ
    'co_occurrence': '共起',              # 単純共起
}
```

#### **1.2 エンティティ-記憶関係（EntityMemoryLink）**

```python
# リンクタイプ分類
ENTITY_MEMORY_LINK_TYPES = {
    'mentions': '言及',                    # 単純言及
    'describes': '説明',                   # 詳細説明
    'defines': '定義',                     # 定義・説明
    'involves': '関与',                    # 関与・参加
    'located_at': '場所',                  # 位置関係
    'performed_by': '実行',                # 行為者
    'affects': '影響',                     # 影響関係
    'creates': '作成',                     # 作成関係
    'uses': '使用',                        # 使用関係
    'owns': '所有',                        # 所有関係
}
```

#### **1.3 エンティティ-エンティティ関係（推論）**

```python
# エンティティ間関係（memory_linksから推論）
ENTITY_RELATION_TYPES = {
    # 人物関係
    'family_member': '家族',
    'friend': '友人',
    'colleague': '同僚',
    'knows': '知人',
    
    # 場所関係
    'located_in': '所在',
    'near_to': '近接',
    'part_of': '部分',
    
    # 組織関係
    'member_of': '所属',
    'works_for': '勤務',
    'leads': '指導',
    
    # 抽象関係
    'instance_of': 'インスタンス',
    'type_of': 'タイプ',
    'similar_to': '類似',
}
```

### **2. ID管理戦略**

#### **2.1 識別子設計**

```python
# IDの形式定義
ID_FORMATS = {
    'memory_id': 'integer',           # SQLite AUTOINCREMENT
    'entity_id': 'uuid4',             # グローバル一意
    'user_id': 'string',              # 外部認証システム由来
    'session_id': 'ulid',             # 時系列ソート可能
    'device_id': 'string',            # デバイス識別子
    'link_id': 'integer',             # AUTOINCREMENT
}

# 複合user_id（エンティティパック分離用）
COMPOSITE_USER_ID_FORMAT = {
    'pattern': '{base_user_id}#{pack_type}',
    'examples': [
        'user_123#lifelog_pack',
        'user_123#work_pack',
        'user_123#dev_pack'
    ]
}
```

#### **2.2 外部キー関係**

```sql
-- 整合性制約
ALTER TABLE memory_links 
ADD CONSTRAINT fk_memory_links_src 
FOREIGN KEY (src_memory_id) REFERENCES memories(id) ON DELETE CASCADE;

ALTER TABLE memory_links 
ADD CONSTRAINT fk_memory_links_dst 
FOREIGN KEY (dst_memory_id) REFERENCES memories(id) ON DELETE CASCADE;

ALTER TABLE entity_memory_links 
ADD CONSTRAINT fk_entity_memory_entity 
FOREIGN KEY (entity_id) REFERENCES entities(entity_id) ON DELETE CASCADE;

ALTER TABLE entity_memory_links 
ADD CONSTRAINT fk_entity_memory_memory 
FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE;
```

---

## 🧠 **ベクトル化戦略**

### **🎯 なぜ複数の埋め込みモデルを用意するの？～車の種類選択で例えよう～**

埋め込みモデル選択は**「車の選択」**のようなものです：

#### **🚗 軽自動車（paraphrase-multilingual-MiniLM-L12-v2）**

- **燃費**: 最高（ローカル実行、API費用なし）
- **用途**: 日常使い、初心者向け
- **制約**: 精度はそこそこ、384次元
- **適用**: カジュアルユーザー、個人利用

#### **🚙 乗用車（text-embedding-3-small）**

- **燃費**: 普通（API費用発生）
- **用途**: 高精度が必要な業務
- **制約**: インターネット必須、1536次元
- **適用**: 企業利用、重要プロジェクト

#### **🚛 トラック（bge-m3）**

- **燃費**: 重い（計算資源大）
- **用途**: 多言語・大規模データ
- **制約**: 専用環境必要、1024次元
- **適用**: 国際企業、研究機関

### **1. 埋め込み生成方針**

#### **1.1 記憶ベクトル化**

##### **📝 テキストを数字に変換する魔法の工程**

```python
MEMORY_VECTORIZATION = {
    'primary_source': 'raw_text',           # 主要入力（あなたの生の言葉）
    'fallback_source': 'summary_text',      # フォールバック（要約版）
    'preprocessing': [
        'text_normalization',               # 正規化（「！！！」→「!」など）
        'language_detection',               # 言語検出（日本語？英語？）
        'noise_removal',                    # ノイズ除去（絵文字、URL削除）
        'chunking_if_long'                  # 長文分割（長すぎる場合は分割）
    ],
    'embedding_models': {
        'default': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',  # 既定（ローカル/低コスト/多言語）
        'alternatives': [
            'text-embedding-3-small',  # 1536次元（高精度/要OpenAI API）
            'bge-m3'                   # 1024次元（多言語対応）
        ]
    },
    'dimensions': {
        'paraphrase-multilingual-MiniLM-L12-v2': 384,  # 軽量モデル
        'text-embedding-3-small': 1536,                # 高精度モデル
        'bge-m3': 1024                                  # バランス型
    }
}
```

#### **1.2 エンティティベクトル化**

```python
ENTITY_VECTORIZATION = {
    'generation_methods': {
        'name_based': {
            'source': 'entity.name + entity.description',
            'weight': 0.7
        },
        'context_aggregated': {
            'source': 'related_memories_text',
            'aggregation': 'weighted_average',
            'weight': 0.3
        },
        'hybrid': {
            'combination': 'weighted_sum',
            'update_strategy': 'incremental'
        }
    },
    'update_triggers': [
        'new_memory_link',                  # 新規関連記憶
        'entity_description_change',        # 説明変更
        'threshold_reached'                 # 閾値到達
    ]
}
```

#### **1.3 関係性ベクトル化**

```python
RELATION_VECTORIZATION = {
    'link_embedding': {
        'method': 'relation_aware',         # 関係性考慮
        'input': 'src_entity + relation_type + dst_entity',
        'model': 'specialized_relation_model'
    },
    'path_embedding': {
        'method': 'path_aggregation',       # 経路集約
        'input': 'multi_hop_path',
        'aggregation': 'attention_weighted'
    }
}
```

### **2. 検索戦略**

#### **2.1 ハイブリッド検索**

```python
HYBRID_SEARCH_STRATEGY = {
    'phases': [
        {
            'name': 'vector_retrieval',
            'method': 'cosine_similarity',
            'top_k': 100,
            'threshold': 0.3
        },
        {
            'name': 'graph_expansion',
            'method': 'bfs_traversal',
            'max_depth': 3,
            'weight_decay': 0.8
        },
        {
            'name': 'relevance_ranking',
            'method': 'combined_score',
            'weights': {
                'semantic_similarity': 0.6,
                'graph_proximity': 0.3,
                'recency': 0.1
            }
        }
    ]
}
```

#### **2.2 検索モード**

```python
SEARCH_MODES = {
    'semantic_only': {
        'description': 'ベクトル類似度のみ',
        'use_case': '意味的類似性重視'
    },
    'graph_only': {
        'description': '構造的関係のみ',
        'use_case': '論理的関係追跡'
    },
    'hybrid': {
        'description': 'セマンティック + グラフ',
        'use_case': '総合的関連性'
    },
    'temporal': {
        'description': '時間重視',
        'use_case': '時系列順検索'
    },
    'entity_focused': {
        'description': 'エンティティ中心',
        'use_case': '特定エンティティ関連'
    }
}
```

---

## 🔍 **グラフアルゴリズム設計**

### **1. 経路探索アルゴリズム**

#### **1.1 基本探索**

```python
GRAPH_ALGORITHMS = {
    'shortest_path': {
        'algorithm': 'bidirectional_bfs',
        'max_depth': 4,
        'weight_consideration': True,
        'time_complexity': 'O(b^(d/2))'
    },
    'strongest_path': {
        'algorithm': 'weighted_dijkstra',
        'optimization': 'max_weight',
        'confidence_threshold': 0.5
    },
    'all_paths': {
        'algorithm': 'dfs_with_cycle_detection',
        'max_paths': 10,
        'similarity_deduplication': True
    }
}
```

#### **1.2 グラフ統計・分析**

```python
GRAPH_ANALYTICS = {
    'centrality_measures': [
        'betweenness_centrality',          # 媒介中心性
        'degree_centrality',               # 次数中心性
        'eigenvector_centrality',          # 固有ベクトル中心性
        'pagerank'                         # PageRank
    ],
    'community_detection': [
        'modularity_optimization',         # モジュラリティ最適化
        'label_propagation',              # ラベル伝播
        'louvain_method'                  # Louvain法
    ],
    'structural_analysis': [
        'clustering_coefficient',         # クラスタ係数
        'small_world_properties',         # スモールワールド性
        'scale_free_properties'           # スケールフリー性
    ]
}
```

### **2. グラフ最適化**

#### **2.1 性能最適化**

```python
GRAPH_OPTIMIZATION = {
    'caching_strategy': {
        'path_cache': {
            'ttl': 3600,                   # 1時間
            'max_entries': 10000,
            'eviction': 'lru'
        },
        'subgraph_cache': {
            'ttl': 1800,                   # 30分
            'max_size_mb': 100
        }
    },
    'indexing_strategy': {
        'adjacency_index': 'btree',
        'weight_index': 'btree',
        'type_index': 'hash'
    },
    'pruning_rules': [
        'low_confidence_edges',            # 低信頼度エッジ
        'isolated_nodes',                 # 孤立ノード
        'redundant_paths'                 # 冗長経路
    ]
}
```

#### **2.2 品質管理**

```python
GRAPH_QUALITY = {
    'validation_rules': [
        {
            'name': 'no_self_loops',
            'description': '自己ループ禁止',
            'severity': 'error'
        },
        {
            'name': 'weight_range',
            'description': '重み範囲チェック',
            'range': [0.0, 1.0],
            'severity': 'warning'
        },
        {
            'name': 'confidence_threshold',
            'description': '信頼度下限',
            'threshold': 0.1,
            'severity': 'info'
        }
    ],
    'cleaning_schedule': {
        'low_confidence_cleanup': 'weekly',
        'orphan_removal': 'monthly',
        'statistical_recompute': 'monthly'
    }
}
```

---

## 📊 **API設計仕様**

### **🎯 APIって何？～レストランの注文システムで理解しよう～**

APIは**「レストランの注文システム」**のようなものです：

#### **🍽️ 従来のレストラン（直接調理）**

```text
お客さん → 「チャーハン作って」 → シェフが直接作る
```

- お客さんがキッチンに入る必要がある
- 作り方を知っている必要がある
- 一人ずつしか対応できない

#### **🏪 現代のレストラン（API方式）**

```text
お客さん → 「チャーハンください」 → ウェイター → シェフ → 料理完成 → お客さん
```

- **お客さん**: GitHub Copilot、Claude Desktop（AIエージェント）
- **ウェイター**: API（long_memory_MCP）
- **シェフ**: データベース（SQLite + ベクトル検索）
- **メニュー**: save_memory、search_memories

##### **🎯 MCP（Model Context Protocol）の特徴**

- **標準化**: どのAIエージェントでも同じ方法で注文可能
- **透明性**: ユーザーは注文システムを意識しない
- **効率性**: 複数のAIが同時に利用可能

### **1. MCP準拠ツールAPI**

#### **🔧 なぜ `/tools/` プレフィックスが必要？**

MCPプロトコルでは、AIエージェントが**「使える道具」**を自動発見します：

```text
GitHub Copilot「何か便利な道具はありますか？」
↓
long_memory_MCP「tools/list で一覧をお渡しします」
↓
GitHub Copilot「tools/save_memory と tools/search_memories が見つかりました！」
↓
自動で記憶保存・検索機能を使用開始
```

#### **1.1 記憶管理API**

```python
MCP_TOOLS = {
    'save_memory': {
        'endpoint': '/tools/save_memory',
        'method': 'POST',
        'description': '記憶保存（自動ベクトル化・関係抽出）',
        'input': 'MemoryIn',
        'output': 'MemoryOut',
        'features': [
            'automatic_vectorization',
            'entity_extraction',
            'relationship_detection',
            'pack_classification'
        ]
    },
    'search_memories': {
        'endpoint': '/tools/search_memories',
        'method': 'POST',
        'description': 'ハイブリッド記憶検索',
        'input': 'MemorySearchRequest',
        'output': 'MemorySearchResponse',
        'features': [
            'semantic_search',
            'graph_traversal',
            'relevance_ranking',
            'metadata_filtering'
        ]
    },
    'build_context': {
        'endpoint': '/tools/build_context',
        'method': 'POST',
        'description': '短期コンテキスト構築',
        'input': 'ShortTermContextRequest',
        'output': 'ShortTermContextResponse'
    }
}
```

#### **1.2 グラフ操作API**

```python
GRAPH_TOOLS = {
    'graph_snapshot': {
        'endpoint': '/tools/graph_snapshot',
        'description': '知識グラフスナップショット取得',
        'output_format': 'vis.js_compatible'
    },
    'find_path': {
        'endpoint': '/tools/find_path',
        'description': 'エンティティ間経路探索',
        'algorithms': ['shortest', 'strongest', 'all']
    },
    'entity_neighbors': {
        'endpoint': '/tools/entity_neighbors',
        'description': 'エンティティ近傍取得',
        'parameters': ['depth', 'relation_types', 'min_confidence']
    }
}
```

### **2. REST管理API**

#### **2.1 データベース管理**

```python
REST_APIS = {
    'database_stats': {
        'endpoint': '/api/database/stats',
        'method': 'GET',
        'description': 'データベース統計情報'
    },
    'export_database': {
        'endpoint': '/api/database/export',
        'method': 'POST',
        'description': '完全データエクスポート（SQLite + ベクトル）'
    },
    'import_database': {
        'endpoint': '/api/database/import',
        'method': 'POST',
        'description': 'データ復元・移行'
    }
}
```

#### **2.2 グラフ分析API**

```python
GRAPH_ANALYTICS_APIS = {
    'graph_statistics': {
        'endpoint': '/api/graph/statistics',
        'metrics': [
            'node_count', 'edge_count', 'density',
            'average_path_length', 'clustering_coefficient'
        ]
    },
    'entity_analytics': {
        'endpoint': '/api/entities/analytics',
        'analysis': [
            'centrality_ranking', 'community_detection',
            'influence_score', 'growth_trends'
        ]
    }
}
```

---

## 🔧 **実装優先順位**

### **Phase 1: コア基盤（2-3週間）**

#### **Week 1: データベーススキーマ**

- [ ] memoriesテーブル拡張（v3.2フィールド追加）
- [ ] memory_linksテーブル実装
- [ ] entitiesテーブル基本実装
- [ ] ベクトルテーブル（vss_memories）整備

#### **Week 2: 基本API実装**

- [ ] save_memory拡張（エンティティ抽出統合）
- [ ] search_memories拡張（ハイブリッド検索）
- [ ] 基本グラフ操作（ノード・エッジ作成）

#### **Week 3: 関係性抽出**

- [ ] エンティティ自動抽出（MCPサンプリング統合）
- [ ] 関係性検出アルゴリズム
- [ ] 基本経路探索（BFS）

### **Phase 2: 知識グラフ機能（2-3週間）**

#### **Week 4: グラフアルゴリズム**

- [ ] 最短経路探索（Bidirectional BFS）
- [ ] 最強経路探索（重み付きDijkstra）
- [ ] グラフキャッシュシステム

#### **Week 5: エンティティ管理**

- [ ] エンティティ統合・マージ機能
- [ ] エンティティタイプ管理
- [ ] 関係タイプ管理

#### **Week 6: 可視化・分析**

- [ ] インタラクティブグラフ可視化
- [ ] グラフ統計・分析機能
- [ ] コミュニティ検出

### **Phase 3: 高度機能（2-4週間）**

#### **Week 7-8: ベクトル統合**

- [ ] エンティティベクトル化
- [ ] 関係性ベクトル化
- [ ] ハイブリッド検索最適化

#### **Week 9-10: パフォーマンス最適化**

- [ ] インデックス最適化
- [ ] キャッシュ戦略実装
- [ ] バッチ処理最適化

---

## 📈 **品質・監視指標**

### **🎯 なぜパフォーマンス監視が必要？～健康診断の考え方～**

システムの監視は**「健康診断」**のようなものです：

#### **👤 人間の健康診断**
- **血圧**: 心臓の負荷状況
- **血糖値**: エネルギー代謝の状況
- **体重**: 全体的な健康状態

#### **💻 long_memory_MCPの健康診断**
- **レスポンス時間**: システムの負荷状況
- **メモリ使用量**: リソース消費の状況
- **エラー率**: システムの安定性

**🎯 監視の利点**

1. **早期発見**: 問題が大きくなる前に対処
2. **ユーザー体験**: 遅いシステムは使われない
3. **コスト管理**: リソース無駄遣いの防止

### **1. データ品質指標**

#### **📊 データの「栄養バランス」をチェック**

```python
DATA_QUALITY_METRICS = {
    'completeness': {
        'entity_coverage': 'extracted_entities / total_possible',      # 取りこぼしはないか？
        'relationship_coverage': 'detected_relations / total_possible' # 関係性を見逃していないか？
    },
    'accuracy': {
        'entity_precision': 'correct_entities / extracted_entities',   # 正確に抽出できているか？
        'relation_precision': 'correct_relations / detected_relations' # 間違った関係を作っていないか？
    },
    'consistency': {
        'entity_uniqueness': 'unique_entities / total_entities',       # 重複がないか？
        'relation_symmetry': 'symmetric_violations / total_relations'  # 論理的に矛盾していないか？
    }
}
```

### **2. 性能指標**

> **🏃‍♂️ 運動能力テストのようなもの**  
> 健康診断に血液検査があるように、システムにも「どのくらい速く動けるか」「どのくらい多くの処理をこなせるか」を測る指標が必要です。これは陸上競技の記録測定のようなものです。

#### **応答時間（Response Times）- 短距離走のタイム**

システムがユーザーの要求に対してどのくらい速く応答できるかを測ります：

- **save_memory_p95**: 記憶保存の95%が500ms以内
  - 例：「この会議の内容を覚えて」→ 0.5秒以内に「保存完了」
- **search_memories_p95**: 記憶検索の95%が800ms以内  
  - 例：「昨日の会議について教えて」→ 0.8秒以内に検索結果表示
- **graph_query_p95**: 知識グラフ検索の95%が1000ms以内
  - 例：「田中さんに関連するすべての記憶」→ 1秒以内に関係図表示

#### **スループット（Throughput）- 持久力と処理能力**

同時にどのくらい多くの処理をこなせるかを測ります：

- **memories_per_second**: 1秒間に100件以上の記憶を処理
  - 例：会議の議事録100ページを1秒で全部保存
- **concurrent_searches**: 50人が同時に検索しても正常動作
  - 例：チーム全員が同時に「プロジェクトA」で検索しても大丈夫

#### **リソース使用量（Resource Usage）- 燃費と省エネ性能**

システムがどのくらい効率的にコンピュータの資源を使うかを測ります：

- **memory_usage_mb**: メモリ使用量1GB以内（車でいう燃費）
- **disk_space_gb**: ディスク容量10GB以内（車でいう荷物スペース）
- **cpu_usage_percent**: CPU使用率80%以内（車でいうエンジン負荷）

```python
PERFORMANCE_METRICS = {
    'response_times': {
        'save_memory_p95': '< 500ms',      # 記憶保存：500ms以内（コーヒー一口飲む時間）
        'search_memories_p95': '< 800ms',  # 記憶検索：800ms以内（名前を思い出す時間）
        'graph_query_p95': '< 1000ms'      # グラフ検索：1秒以内（地図で道順確認する時間）
    },
    'throughput': {
        'memories_per_second': '> 100',    # 1秒で100件処理（高速読書レベル）
        'concurrent_searches': '> 50'      # 50人同時検索対応（小さな図書館レベル）
    },
    'resource_usage': {
        'memory_usage_mb': '< 1000',       # メモリ1GB以内（スマホアプリ程度）
        'disk_space_gb': '< 10',           # ディスク10GB以内（映画5本分程度）
        'cpu_usage_percent': '< 80'        # CPU80%以内（軽い負荷で安定動作）
    }
}
```

### **3. ビジネス指標**

> **🎯 お店の成績表のようなもの**  
> 技術的な性能だけでなく、「ユーザーが満足しているか」「システムが健全に成長しているか」といった、ビジネス的な成功を測る指標です。レストランでいう「お客様満足度」や「リピート率」のような指標です。

#### **ユーザー満足度（User Engagement）- お客様の評価**

- **search_success_rate**: 検索成功率
  - 計算式：成功した検索 ÷ 全検索回数
  - 例：「探していた情報がちゃんと見つかる確率」→ 理想は90%以上
- **context_relevance_score**: コンテキスト関連性スコア
  - 計算式：ユーザーフィードバックの平均点
  - 例：「AIが提案した情報がどのくらい役に立ったか」→ 5点満点中4点以上

#### **システム健全性（System Health）- お店の運営状況**

- **data_growth_rate**: データ成長率
  - 計算式：1日あたりの新しい記憶数
  - 例：「毎日どのくらい新しい情報が蓄積されているか」→ 安定した増加傾向
- **relationship_density**: 関係密度
  - 計算式：関係の数 ÷ エンティティの数
  - 例：「情報同士がどのくらい豊かにつながっているか」→ 適度な密度が理想
- **graph_connectivity**: グラフ連結性
  - 計算式：連結成分数 ÷ 全ノード数
  - 例：「情報が孤立せずに全体でつながっているか」→ 1に近いほど良い

```python
BUSINESS_METRICS = {
    'user_engagement': {
        'search_success_rate': 'successful_searches / total_searches',      # 検索成功率：探したものが見つかる確率
        'context_relevance_score': 'user_feedback_average'                  # 関連性スコア：提案の的確さ
    },
    'system_health': {
        'data_growth_rate': 'new_memories_per_day',           # データ成長率：日々の蓄積ペース
        'relationship_density': 'edges / nodes',              # 関係密度：情報のつながりの豊かさ
        'graph_connectivity': 'connected_components / total_nodes'  # 連結性：情報の統合度
    }
}
```

---

## 🛡️ **セキュリティ・プライバシー**

> **🏠 家のセキュリティシステムのようなもの**  
> 大切な記憶やプライベートな情報を安全に守るために、家に鍵をかけたり、部屋を分けたりするように、デジタルでも様々な保護対策を行います。

### **1. データ分離**

> **🚪 家族ごとに部屋を分けるシステム**  
> 一つの家（データベース）に複数の家族（ユーザー）が住んでいるとき、それぞれの部屋（データ）を完全に分離して、他の家族の物を見られないようにする仕組みです。

#### **ユーザーレベル分離（User Level Isolation）**

- **user_id_filtering**: 各ユーザーのIDで厳密にフィルタリング
  - 例：田中さんのデータを見ようとしても、佐藤さんのIDでは絶対にアクセスできない
- **database_level**: データベースレベルで強制実行
  - 例：SQLクエリ自体にユーザーID条件を必ず含める
- **api_layer**: API層でも二重チェック
  - 例：万が一データベースの検証をすり抜けても、API層で再度確認

#### **セッション分離（Session Isolation）**

- **session_id_scoping**: セッションIDによる範囲限定
  - 例：ブラウザのタブごとに異なる作業空間を提供
- **automatic_expiry**: 自動期限切れ
  - 例：セッションが終了したら自動的にデータをクリーンアップ

```python
DATA_ISOLATION = {
    'user_level_isolation': {
        'method': 'user_id_filtering',      # ユーザーIDによる厳密フィルタリング
        'enforcement': 'database_level',    # データベースレベルで強制実行
        'validation': 'api_layer'           # API層でも二重チェック
    },
    'session_isolation': {
        'method': 'session_id_scoping',     # セッション単位でデータ分離
        'cleanup': 'automatic_expiry'       # 自動的なクリーンアップ
    }
}
```

### **2. データ保護**

> **🔒 金庫と郵送のセキュリティ**  
> 大切な書類を金庫に保管したり、重要な手紙を書留で送ったりするように、デジタルデータも保存時と送信時の両方で暗号化して保護します。

#### **暗号化（Encryption）- デジタルの鍵**

- **at_rest**: 保存時暗号化（AES-256）
  - 例：ハードディスクに保存される時点で既に暗号化
  - 比喩：金庫に保管する書類を暗号で書くようなもの
- **in_transit**: 通信時暗号化（TLS-1.3）
  - 例：インターネット上でのデータ送信時も暗号化
  - 比喩：手紙を暗号で書いて書留で送るようなもの

#### **匿名化（Anonymization）- 個人情報の保護**

- **pii_detection**: 個人情報の自動検出
  - 例：「田中太郎, 03-1234-5678」→ 自動で個人情報として認識
- **scrubbing**: 設定可能な情報除去
  - 例：「[名前], [電話番号]」のように匿名化して保存

#### **バックアップ（Backup）- 万が一の備え**

- **frequency**: 毎日自動バックアップ
- **retention**: 30日間保持
- **encryption**: バックアップファイルも暗号化

```python
DATA_PROTECTION = {
    'encryption': {
        'at_rest': 'AES-256',         # 保存時：軍事レベルの暗号化
        'in_transit': 'TLS-1.3'       # 通信時：最新の安全な通信プロトコル
    },
    'anonymization': {
        'pii_detection': 'automatic',  # 個人情報の自動検出
        'scrubbing': 'configurable'    # 設定可能な情報除去
    },
    'backup': {
        'frequency': 'daily',          # 毎日バックアップ
        'retention': '30_days',        # 30日間保持
        'encryption': 'enabled'        # バックアップも暗号化
    }
}
```

---

## 🚀 **将来拡張計画**

> **🌱 植物の成長計画のようなもの**  
> 現在の基礎がしっかりできたら、将来的にはどんな新しい機能や能力を育てていくかの計画です。庭師が「来年は花を増やそう」「再来年は実のなる木を植えよう」と計画するように、システムも段階的に成長させていきます。

### **1. スケーラビリティ向上**

> **🏗️ 建物の増築工事のようなもの**  
> 今は一軒家（小規模）だけど、将来的にはマンション（中規模）やオフィスビル（大規模）に対応できるように構造を強化する計画です。

- **分散処理**: 大規模グラフ処理の分散化
  - 例：1つのコンピュータで処理していたものを、複数のコンピュータで分担
  - 比喩：一人で料理していたのを、チーム料理にして効率化
- **クラスタリング**: ノード・エッジの効率的クラスタ化
  - 例：関連する情報をグループにまとめて、検索速度を向上
  - 比喩：図書館の本を分野別に整理するように、データも分類整理
- **ストリーミング**: リアルタイムデータ処理
  - 例：データが入力されるとすぐに処理して、即座に検索可能にする
  - 比喩：生放送のように、データをリアルタイムで処理

### **2. AI機能強化**

> **🧠 AI の学習進歩のようなもの**  
> 現在は基本的な記憶と検索ができるAIを、将来的にはもっと賢く、自動で考えて判断できるAIに進化させる計画です。

- **自動関係推論**: 未知の関係性自動推論
  - 例：「田中さんと佐藤さんが同じプロジェクトにいる」→「同僚である可能性が高い」と推論
  - 比喻：探偵が手がかりから推理するように、AIがデータから関係を推測
- **エンティティ解決**: 重複エンティティ自動統合
  - 例：「田中太郎」「田中」「Tanaka」が同一人物だと自動判定して統合
  - 比喻：同じ人の名刺が複数あっても、自動で同一人物として整理
- **予測機能**: 将来の関係性予測
  - 例：現在の関係性から「来月この2人は一緒に仕事する可能性が高い」と予測
  - 比喻：天気予報のように、過去のパターンから未来を予測

### **3. インターフェース拡張**

> **🌐 多言語対応・マルチメディア対応**  
> 現在は日本語のテキストメインだけど、将来的には世界中の言語や、画像・音声なども扱えるように拡張する計画です。

- **多言語対応**: 多言語エンティティ・関係処理
  - 例：日本語、英語、中国語の記憶を混在させても正しく処理
  - 比喻：多言語対応の翻訳機のように、どの言語でも理解
- **マルチモーダル**: 画像・音声エンティティ対応
  - 例：会議の音声記録や、写真の内容も記憶として保存・検索
  - 比喻：文字だけでなく、写真アルバムや録音も整理できる記憶システム
- **API拡張**: GraphQL、WebSocket対応
  - 例：より柔軟なデータ取得方法や、リアルタイム通信に対応
  - 比喻：電話（従来API）だけでなく、メールやチャットなど多様な連絡手段に対応

```python
# 将来拡張計画のロードマップ
EXPANSION_ROADMAP = {
    'phase1_scalability': {
        'distributed_processing': '分散処理対応',      # 複数マシンでの並列処理
        'clustering_optimization': 'クラスタ最適化',   # データの効率的グループ化
        'streaming_support': 'ストリーミング対応'       # リアルタイム処理
    },
    'phase2_ai_enhancement': {
        'relation_inference': '関係推論AI',           # 未知の関係を自動推測
        'entity_resolution': 'エンティティ統合AI',     # 重複データの自動統合
        'predictive_modeling': '予測機能'             # 将来の関係性予測
    },
    'phase3_interface_expansion': {
        'multilingual_support': '多言語対応',         # 世界中の言語サポート
        'multimodal_entities': 'マルチモーダル',      # 画像・音声対応
        'advanced_apis': '高度API',                 # GraphQL, WebSocket対応
    }
}
```

---

## 📝 **まとめ**

> **🎓 卒業論文のようなもの**  
> これまでに学んだすべての内容を整理して、「このシステムで何ができるようになったか」「どんな価値があるか」を総括する部分です。

本仕様書は、long_memory_MCPプロジェクトの知識グラフベクトルデータベースの包括的な要件を定義しました。

### **主要成果物**

> **🏆 プロジェクトの主な成果**  
> 家を建てる時の設計図一式のように、システム全体を構築するための完全な設計書を作成しました。

1. **統合データベース設計**: SQLite + sqlite-vec の最適なハイブリッド構成
   - 比喻：図書館（構造化データ）＋検索エンジン（ベクトル検索）の融合
   - 価値：高速で柔軟な記憶システムの基盤

2. **知識グラフスキーマ**: エンティティ・関係性の柔軟な管理
   - 比喻：家系図のように人やモノの関係を整理する仕組み
   - 価値：情報同士のつながりを自動で理解・活用

3. **ベクトル検索統合**: セマンティック検索と構造化検索の融合
   - 比喩：Google検索（意味理解）＋データベース検索（正確性）の組み合わせ
   - 価値：「なんとなく覚えている」レベルでも正確な情報を発見

4. **API仕様**: MCP準拠の透明なツールインターフェース
   - 比喻：レストランの注文システム（簡単な要求で複雑な処理を実行）
   - 価値：AIエージェントが自動で記憶を活用、ユーザーは意識不要

5. **実装ロードマップ**: 段階的開発計画
   - 比喻：建築工事の工程表（基礎→躯体→内装の順番）
   - 価値：確実で効率的な開発の道筋

### **技術的革新**

> **🚀 従来システムからの革新ポイント**  
> 今までにない新しい価値や、従来の問題を解決する画期的な仕組みを実現しました。

- **透明なUX**: ユーザーに意識させない記憶補完
  - 革新性：コマンド入力不要、普通の会話で自動的に記憶を活用
  - 価値：技術を意識せずに、自然にAIとの会話が向上

- **ハイブリッド検索**: ベクトル + グラフの統合検索
  - 革新性：意味検索と構造検索の同時実行で高精度を実現
  - 価値：「曖昧な記憶」から「正確な情報」への自動変換

- **自動関係抽出**: MCPホストLLMによる高精度抽出
  - 革新性：人間の自然な表現から自動で知識グラフを構築
  - 価値：手動整理不要、自然に話すだけで知識が蓄積・整理

- **スケーラブル設計**: 個人から企業まで対応
  - 革新性：同一システムで個人利用から大規模利用まで対応
  - 価値：小さく始めて大きく育てられる成長型システム

### **実現される未来**

> **🌟 このシステムがもたらす理想の世界**  
> 技術的な改善が、最終的にどんな素晴らしい体験や価値につながるかを描いています。

1. **AIとの自然な対話**: 前提条件を忘れない、文脈を理解したAI
2. **個人知識の永続化**: 重要な記憶を失わない、蓄積し続ける知識ベース
3. **自動的な洞察発見**: 隠れた関係性やパターンの自動発見
4. **カジュアルな高度機能**: 専門知識不要で最先端AI技術を活用

この仕様書に基づいて実装することで、**LLMの記憶喪失問題を根本解決**し、真の長期記憶システムを実現できます！

---

**文書管理情報**  

- **バージョン**: v1.0
- **最終更新**: 2025年8月18日
- **承認者**: プロジェクトチーム
- **次回レビュー**: Phase 1完了時
