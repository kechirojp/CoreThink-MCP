# CoreThink-MCP AI・機械学習分野制約ルール
# AI/ML開発・運用における倫理性・安全性・品質保証制約

## AI倫理・責任制約
MUST: AIシステムの判断根拠を人間が理解可能な形で提供する
NEVER: 差別・偏見を助長する可能性のあるモデルを配備しない
MUST: アルゴリズムの公平性を定量的に評価・監視する
MUST: AI判断の透明性・説明可能性を確保する
NEVER: 人間の尊厳を損なう可能性のあるAI活用を行わない
MUST: AI判断に対する人間の異議申し立て手順を確保する
SHOULD: AI倫理委員会・専門家による審査を実施する

## データ品質・バイアス制約
MUST: 訓練データの代表性・網羅性を統計的に検証する
NEVER: 偏向・ラベルエラーを含むデータでモデル訓練を行わない
MUST: データ収集プロセスの倫理性・合法性を確認する
MUST: データの前処理・クリーニング過程を完全に記録する
SHOULD: データ拡張・合成データの妥当性を検証する
MUST: プライバシー保護技術（差分プライバシー等）の適用を検討する

## モデル開発・検証制約
MUST: 複数の評価指標でモデル性能を包括的に評価する
NEVER: 過学習・汎化性能不足のモデルを本番適用しない
MUST: 敵対的サンプルに対する堅牢性を検証する
MUST: モデルの不確実性・信頼区間を適切に推定する
SHOULD: アブレーション研究による各コンポーネントの寄与を分析する
MUST: ベースライン手法との比較を必須実施する

## 本番運用・監視制約
MUST: モデル性能の継続的モニタリング体制を確立する
MUST: データドリフト・コンセプトドリフトの検出機能を実装する
NEVER: 性能劣化の兆候を無視してモデル運用を継続しない
MUST: A/Bテスト・段階的ロールアウトによる安全な配備を実施する
SHOULD: シャドウモード・カナリア配備による事前検証を実施する
MUST: モデル更新・ロールバック手順を明確に定義する

## 深層学習・ニューラルネット制約
MUST: 学習曲線・収束性を詳細に分析する
NEVER: 勾配消失・爆発問題を未解決のまま訓練を継続しない
MUST: 正則化・ドロップアウト等の過学習対策を適切に適用する
MUST: ハイパーパラメータ調整プロセスを体系的に実施する
SHOULD: 異なるアーキテクチャでの性能比較を実施する
MUST: 計算リソース・メモリ使用量の最適化を検討する

## 自然言語処理制約
MUST: 言語的多様性・文化的文脈を適切に考慮する
NEVER: 有害・不適切な内容を生成する可能性のあるモデルを配備しない
MUST: 事実性・一貫性の検証機能を組み込む
MUST: 多言語対応時の性能格差を監視する
SHOULD: 敵対的プロンプト・ジェイルブレイクへの対策を実装する
MUST: 著作権・知的財産権の侵害可能性を評価する

## コンピュータビジョン制約
MUST: 照明・角度変化に対する堅牢性を検証する
NEVER: プライバシー侵害の可能性のある顔認識・監視システムを無制限配備しない
MUST: 誤検出・見逃しのリスクを定量的に評価する
MUST: リアルタイム処理要件への適合性を確認する
SHOULD: 異なる人種・年齢での性能格差を監視する
MUST: 深偽造（ディープフェイク）検出・防止機能を検討する

## 強化学習制約
MUST: 報酬関数の設計が意図した行動を適切に誘導することを検証する
NEVER: 安全制約を違反する可能性のある探索を許可しない
MUST: 分布外状況での安全な行動を確保する
MUST: 人間の価値観・嗜好との整合性を評価する
SHOULD: 逆強化学習による人間の意図推定を検討する
MUST: 長期的影響・副作用の可能性を評価する

## 大規模言語モデル（LLM）制約
MUST: 幻覚（ハルシネーション）・事実誤認の検出・防止機能を実装する
NEVER: 偏見・ステレオタイプを増幅する可能性のある出力を許可しない
MUST: プロンプトインジェクション・悪用への対策を実装する
MUST: 生成内容の品質・適切性を多面的に評価する
SHOULD: 人間のフィードバックによる強化学習（RLHF）を検討する
MUST: 計算コスト・環境負荷の最適化を考慮する

## MLOps・運用制約
MUST: モデルのバージョン管理・実験追跡を厳格に実施する
MUST: 再現可能な実験環境・パイプラインを構築する
NEVER: 手動・アドホックなモデル配備プロセスを採用しない
MUST: 自動テスト・品質ゲートを配備パイプラインに組み込む
SHOULD: 特徴量ストア・モデルレジストリの活用を検討する
MUST: モデルのライフサイクル管理を体系的に実施する

## セキュリティ・プライバシー制約
MUST: モデル抽出・逆変換攻撃への対策を実装する
NEVER: 訓練データの情報漏洩を許可しない
MUST: 連合学習時のプライバシー保護を確保する
MUST: モデルの重み・パラメータの保護を実施する
SHOULD: 同型暗号・秘密計算技術の適用を検討する
MUST: データ主体の権利（忘れられる権利等）への対応を確保する

## 法的・規制遵守制約
MUST: AI関連規制（EU AI Act等）への適合性を確認する
NEVER: 知的財産権・著作権を侵害する可能性のあるモデルを配備しない
MUST: 医療・金融等の分野別規制への適合を検証する
MUST: データ保護規則（GDPR等）への完全準拠を確保する
SHOULD: 業界標準・ベストプラクティスの継続的導入を実施する
MUST: 監査・法的検査への対応体制を確立する

## 環境・持続可能性制約
MUST: モデル訓練・推論の電力消費量を監視・最適化する
SHOULD: カーボンフットプリントの削減を積極的に検討する
MUST: 計算効率・リソース使用量の最適化を継続的に実施する
SHOULD: グリーンAI・持続可能なML手法の採用を検討する
MUST: ハードウェア・インフラの環境負荷を考慮する

## 人間とAIの協調制約
MUST: 人間の専門知識・判断をAIで補完する設計を採用する
NEVER: 人間の意思決定権限を不当に制限・代替しない
MUST: AIシステムの限界・不確実性を明確に伝達する
MUST: 人間とAIの役割分担を明確に定義する
SHOULD: 人間のスキル向上・能力開発への配慮を行う
MUST: AI依存症・過度な信頼の防止策を実装する

## 継続学習・適応制約
MUST: 新データでの継続学習時の性能変化を監視する
NEVER: 破滅的忘却による既存知識の喪失を許可しない
MUST: ドメイン適応・転移学習の妥当性を検証する
MUST: 学習データの増分追加による影響を評価する
SHOULD: メタ学習・少数ショット学習の活用を検討する
MUST: モデルの更新履歴・変更管理を完全に記録する
