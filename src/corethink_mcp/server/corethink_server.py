"""
CoreThink-MCP Server
Natural Language Reasoning MCP Server based on General Symbolics Reasoning (GSR)
"""

import logging
import os
import sys
import socket
import signal
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List
from dotenv import load_dotenv

# UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¼·åˆ¶è¨­å®š
os.environ['PYTHONIOENCODING'] = 'utf-8'
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
if hasattr(sys.stderr, 'reconfigure'):
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

# GitPython ã® importï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
try:
    import git
    GIT_AVAILABLE = True
except ImportError:
    GIT_AVAILABLE = False
    git = None

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—ã—ã¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ«ãƒ¼ãƒˆã‚’sys.pathã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.corethink_mcp import get_version_info
from src.corethink_mcp.feature_flags import feature_flags, is_sampling_enabled, get_sampling_timeout, is_history_enabled
from src.corethink_mcp.history_manager import log_tool_execution

# ãƒ­ã‚°è¨­å®šï¼ˆUTF-8å¯¾å¿œï¼‰
log_level = os.getenv("CORETHINK_LOG_LEVEL", "INFO")
logging.basicConfig(
    level=getattr(logging, log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(Path("logs") / "trace.log", encoding='utf-8'),
        logging.StreamHandler(sys.stderr)
    ],
    force=True  # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä¸Šæ›¸ã
)
logger = logging.getLogger(__name__)

# FastMCP ã® importï¼ˆãƒ­ã‚°è¨­å®šå¾Œï¼‰
try:
    from fastmcp import FastMCP
except ImportError:
    logger.error("FastMCP not available. Please install: pip install fastmcp")
    FastMCP = None

# FastMCPæœªå°å…¥æ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
if not FastMCP:
    logger.error("FastMCP not available. Please install: pip install fastmcp")

def find_available_port(preferred_port: int = 8080, max_attempts: int = 100) -> int:
    """
    åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆã‚’æ¤œç´¢ã™ã‚‹
    
    Args:
        preferred_port: å„ªå…ˆãƒãƒ¼ãƒˆç•ªå·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8080ï¼‰
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
    
    Returns:
        åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆç•ªå·
    """
    for port in range(preferred_port, preferred_port + max_attempts):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.bind(('localhost', port))
                if port != preferred_port:
                    logger.warning(f"ãƒãƒ¼ãƒˆ {preferred_port} ã¯ä½¿ç”¨ä¸­ã§ã™ã€‚ãƒãƒ¼ãƒˆ {port} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                else:
                    logger.info(f"ãƒãƒ¼ãƒˆ {port} ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
                return port
        except socket.error:
            continue
    
    # ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        sock.bind(('localhost', 0))
        port = sock.getsockname()[1]
        logger.warning(f"ãƒãƒ¼ãƒˆ {preferred_port}ï½{preferred_port + max_attempts} ã¯å…¨ã¦ä½¿ç”¨ä¸­ã§ã™ã€‚ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆ {port} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return port

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
REPO_ROOT = Path(os.getenv("CORETHINK_REPO_ROOT", "."))
CONSTRAINTS_FILE = Path(__file__).parent.parent / "constraints.txt"
CONSTRAINTS_MEDICAL_FILE = Path(__file__).parent.parent / "constraints_medical.txt"
CONSTRAINTS_LEGAL_FILE = Path(__file__).parent.parent / "constraints_legal.txt"
CONSTRAINTS_ENGINEERING_FILE = Path(__file__).parent.parent / "constraints_engineering.txt"
CONSTRAINTS_SAFETY_CRITICAL_FILE = Path(__file__).parent.parent / "constraints_safety_critical.txt"
CONSTRAINTS_AI_ML_FILE = Path(__file__).parent.parent / "constraints_ai_ml.txt"
CONSTRAINTS_CLOUD_DEVOPS_FILE = Path(__file__).parent.parent / "constraints_cloud_devops.txt"
SANDBOX_DIR = os.getenv("CORETHINK_SANDBOX_DIR", ".sandbox")

# ãƒãƒ¼ãƒˆè¨­å®šï¼ˆè‡ªå‹•æ¤œå‡ºï¼‰
PREFERRED_PORT = int(os.getenv("CORETHINK_PORT", "8080"))
AVAILABLE_PORT = find_available_port(PREFERRED_PORT)

# FastMCPã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
if FastMCP:
    version_info = get_version_info()
    app = FastMCP(
        name="corethink-mcp",
        version=version_info["version"]
    )
else:
    # ä»£æ›¿å®Ÿè£…
    app = None

def load_constraints() -> str:
    """åŸºæœ¬åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        return CONSTRAINTS_FILE.read_text(encoding="utf-8")
    except FileNotFoundError:
        logger.warning(f"åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {CONSTRAINTS_FILE}")
        return "åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ"

def _detect_domain(user_request: str) -> List[str]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‹ã‚‰é©ç”¨ã™ã¹ãåˆ†é‡ã‚’æ¤œå‡ºã™ã‚‹"""
    domains = []
    
    # åŒ»ç™‚åˆ†é‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    medical_keywords = [
        "è¨ºæ–­", "ç—‡çŠ¶", "æ²»ç™‚", "è–¬ç‰©", "ç–¾æ‚£", "ç—…æ°—", "åŒ»ç™‚", "æ‚£è€…", "åŒ»å¸«", 
        "å‡¦æ–¹", "å‰¯ä½œç”¨", "ç—…ç†", "æ‰‹è¡“", "æ¤œæŸ»", "å¥åº·", "è‡¨åºŠ"
    ]
    
    # æ³•çš„åˆ†é‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    legal_keywords = [
        "åˆ¤ä¾‹", "æ³•çš„", "è¨¼æ‹ ", "äº‹å®Ÿèªå®š", "å¥‘ç´„", "è£åˆ¤", "æ³•å¾‹", "æ¨©åˆ©", 
        "ç¾©å‹™", "è²¬ä»»", "è¨´è¨Ÿ", "æ³•å»·", "å¼è­·", "å¸æ³•", "æ¡æ–‡", "è¦åˆ¶"
    ]
    
    # ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°åˆ†é‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    engineering_keywords = [
        "è¨­è¨ˆ", "å®Ÿè£…", "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "ã‚·ã‚¹ãƒ†ãƒ ", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢", "ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢", 
        "ãƒ—ãƒ­ã‚°ãƒ©ãƒ ", "ã‚³ãƒ¼ãƒ‰", "é–‹ç™º", "ãƒ†ã‚¹ãƒˆ", "ãƒ‡ãƒãƒƒã‚°", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", 
        "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "API", "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"
    ]
    
    # AIãƒ»æ©Ÿæ¢°å­¦ç¿’åˆ†é‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    ai_ml_keywords = [
        "æ©Ÿæ¢°å­¦ç¿’", "AI", "äººå·¥çŸ¥èƒ½", "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ", "æ·±å±¤å­¦ç¿’", "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°",
        "ãƒ¢ãƒ‡ãƒ«", "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", "è¨“ç·´", "å­¦ç¿’", "äºˆæ¸¬", "åˆ†é¡", "å›å¸°", "ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°",
        "è‡ªç„¶è¨€èªå‡¦ç†", "NLP", "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³", "ç”»åƒèªè­˜", "å¼·åŒ–å­¦ç¿’", "RL",
        "LLM", "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«", "Transformer", "BERT", "GPT", "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹"
    ]
    
    # ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»DevOpsåˆ†é‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    cloud_devops_keywords = [
        "ã‚¯ãƒ©ã‚¦ãƒ‰", "AWS", "Azure", "GCP", "Docker", "Kubernetes", "ã‚³ãƒ³ãƒ†ãƒŠ",
        "CI/CD", "DevOps", "SRE", "ã‚¤ãƒ³ãƒ•ãƒ©", "ãƒ‡ãƒ—ãƒ­ã‚¤", "ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
        "ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹", "ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹", "ç›£è¦–", "ãƒ­ã‚°", "ãƒ¡ãƒˆãƒªã‚¯ã‚¹", "ã‚¢ãƒ©ãƒ¼ãƒˆ",
        "ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°", "è² è·åˆ†æ•£", "CDN", "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", "ç½å®³å¾©æ—§"
    ]
    
    # å®‰å…¨é‡è¦åˆ†é‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    safety_critical_keywords = [
        "èˆªç©º", "å®‡å®™", "åŸå­åŠ›", "åŒ»ç™‚æ©Ÿå™¨", "è‡ªå‹•é‹è»¢", "åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ", "ç”Ÿå‘½ç¶­æŒ", 
        "ç·Šæ€¥", "ç½å®³", "å®‰å…¨", "ãƒªã‚¹ã‚¯", "å±é™º", "äº‹æ•…", "éšœå®³", "ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•",
        "é‡è¦ã‚¤ãƒ³ãƒ•ãƒ©", "é›»åŠ›", "æ°´é“", "é€šä¿¡", "äº¤é€š", "é‡‘è", "æ±ºæ¸ˆ"
    ]
    
    user_request_lower = user_request.lower()
    
    if any(kw.lower() in user_request_lower for kw in medical_keywords):
        domains.append("medical")
    if any(kw.lower() in user_request_lower for kw in legal_keywords):
        domains.append("legal")
    if any(kw.lower() in user_request_lower for kw in engineering_keywords):
        domains.append("engineering")
    if any(kw.lower() in user_request_lower for kw in ai_ml_keywords):
        domains.append("ai_ml")
    if any(kw.lower() in user_request_lower for kw in cloud_devops_keywords):
        domains.append("cloud_devops")
    if any(kw.lower() in user_request_lower for kw in safety_critical_keywords):
        domains.append("safety_critical")
    
    # æœ€ã‚‚å„ªå…ˆåº¦ã®é«˜ã„åˆ†é‡ã‚’è¿”ã™ï¼ˆè¤‡æ•°æ¤œå‡ºã•ã‚ŒãŸå ´åˆã®å„ªå…ˆé †ä½ï¼‰
    priority_order = ["safety_critical", "medical", "legal", "ai_ml", "engineering", "cloud_devops"]
    
    for priority_domain in priority_order:
        if priority_domain in domains:
            return priority_domain
    
    return "general"

def load_domain_constraints(user_request: str) -> str:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«åŸºã¥ã„ã¦é©åˆ‡ãªåˆ¶ç´„ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    try:
        # åŸºæœ¬åˆ¶ç´„ã‚’èª­ã¿è¾¼ã¿
        constraints = load_constraints()
        
        # åˆ†é‡ã‚’æ¤œå‡ºï¼ˆå˜ä¸€ã®æœ€å„ªå…ˆåˆ†é‡ï¼‰
        detected_domain = _detect_domain(user_request)
        logger.info(f"æ¤œå‡ºã•ã‚ŒãŸåˆ†é‡: {detected_domain}")
        
        # åˆ†é‡ç‰¹åŒ–åˆ¶ç´„ã‚’è¿½åŠ 
        if detected_domain == "medical":
            try:
                medical_constraints = CONSTRAINTS_MEDICAL_FILE.read_text(encoding="utf-8")
                constraints += f"\n\n# === åŒ»ç™‚åˆ†é‡ç‰¹åŒ–åˆ¶ç´„ ===\n{medical_constraints}"
            except FileNotFoundError:
                logger.warning("åŒ»ç™‚åˆ†é‡åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        elif detected_domain == "legal":
            try:
                legal_constraints = CONSTRAINTS_LEGAL_FILE.read_text(encoding="utf-8")
                constraints += f"\n\n# === æ³•çš„åˆ†é‡ç‰¹åŒ–åˆ¶ç´„ ===\n{legal_constraints}"
            except FileNotFoundError:
                logger.warning("æ³•çš„åˆ†é‡åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        elif detected_domain == "engineering":
            try:
                engineering_constraints = CONSTRAINTS_ENGINEERING_FILE.read_text(encoding="utf-8")
                constraints += f"\n\n# === ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°åˆ†é‡ç‰¹åŒ–åˆ¶ç´„ ===\n{engineering_constraints}"
            except FileNotFoundError:
                logger.warning("ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°åˆ†é‡åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        elif detected_domain == "ai_ml":
            try:
                ai_ml_constraints = CONSTRAINTS_AI_ML_FILE.read_text(encoding="utf-8")
                constraints += f"\n\n# === AIãƒ»æ©Ÿæ¢°å­¦ç¿’åˆ†é‡ç‰¹åŒ–åˆ¶ç´„ ===\n{ai_ml_constraints}"
            except FileNotFoundError:
                logger.warning("AIãƒ»æ©Ÿæ¢°å­¦ç¿’åˆ†é‡åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        elif detected_domain == "cloud_devops":
            try:
                cloud_devops_constraints = CONSTRAINTS_CLOUD_DEVOPS_FILE.read_text(encoding="utf-8")
                constraints += f"\n\n# === ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»DevOpsåˆ†é‡ç‰¹åŒ–åˆ¶ç´„ ===\n{cloud_devops_constraints}"
            except FileNotFoundError:
                logger.warning("ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»DevOpsåˆ†é‡åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        elif detected_domain == "safety_critical":
            try:
                safety_critical_constraints = CONSTRAINTS_SAFETY_CRITICAL_FILE.read_text(encoding="utf-8")
                constraints += f"\n\n# === å®‰å…¨é‡è¦åˆ†é‡ç‰¹åŒ–åˆ¶ç´„ ===\n{safety_critical_constraints}"
            except FileNotFoundError:
                logger.warning("å®‰å…¨é‡è¦åˆ†é‡åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        else:  # general
            logger.info("åˆ†é‡ä¸æ˜ã®ãŸã‚ã€æœ€ã‚‚å³æ ¼ãªåˆ¶ç´„ã‚»ãƒƒãƒˆã‚’é©ç”¨")
            # ä¸€èˆ¬çš„ãªå ´åˆã¯åŸºæœ¬åˆ¶ç´„ã®ã¿ä½¿ç”¨
            
        return constraints
        
    except Exception as e:
        logger.error(f"åˆ¶ç´„èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return load_constraints()  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
def create_sandbox() -> str:
    """å®‰å…¨ãªä½œæ¥­ç’°å¢ƒï¼ˆã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ï¼‰ã‚’ä½œæˆ"""
    if not GIT_AVAILABLE:
        error_msg = "GitPython not available. Please install: pip install GitPython"
        logger.error(error_msg)
        return f"ã‚¨ãƒ©ãƒ¼: {error_msg}"
    
    try:
        repo = git.Repo(REPO_ROOT)
        sandbox_path = Path(REPO_ROOT) / SANDBOX_DIR
        
        # æ—¢å­˜ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã®ç¢ºèªã¨å‰Šé™¤
        if sandbox_path.exists():
            try:
                repo.git.worktree("remove", str(sandbox_path), "--force")
                logger.info(f"æ—¢å­˜ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {sandbox_path}")
            except git.GitCommandError:
                logger.warning("æ—¢å­˜ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ç¶šè¡Œã—ã¾ã™")
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ–ãƒ©ãƒ³ãƒåã§æ–°ã—ã„ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        branch_name = f"corethink-sbx-{timestamp}"
        
        try:
            repo.git.worktree("add", "-b", branch_name, str(sandbox_path), "HEAD")
            logger.info(f"ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ: {sandbox_path} (ãƒ–ãƒ©ãƒ³ãƒ: {branch_name})")
        except git.GitCommandError as e:
            if "Permission denied" in str(e):
                # Windowsæ¨©é™å•é¡Œã®å ´åˆã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚³ãƒ”ãƒ¼ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                import shutil
                shutil.copytree(REPO_ROOT, sandbox_path, ignore=shutil.ignore_patterns('.git', '__pycache__', '*.pyc'))
                logger.warning(f"Git worktreeãŒå¤±æ•—ã—ãŸãŸã‚ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚³ãƒ”ãƒ¼ã§ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ: {sandbox_path}")
            else:
                raise
        
        return str(sandbox_path)
    except git.InvalidGitRepositoryError:
        error_msg = f"Invalid git repository: {REPO_ROOT}"
        logger.error(error_msg)
        return f"ã‚¨ãƒ©ãƒ¼: {error_msg}"
    except git.GitCommandError as e:
        error_msg = f"Git command failed: {str(e)}"
        logger.error(error_msg)
        return f"ã‚¨ãƒ©ãƒ¼: {error_msg}"
    except Exception as e:
        logger.error(f"ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return f"ã‚¨ãƒ©ãƒ¼: {str(e)}"

# ================== MCP Tools ==================

if app:
    async def _enhance_with_sampling(core_result: str, tool_name: str, ctx=None) -> str:
        """Samplingæ©Ÿèƒ½ã«ã‚ˆã‚‹çµæœæ‹¡å¼µ
        
        Args:
            core_result: CoreThinkæ¨è«–ã®çµæœ
            tool_name: ãƒ„ãƒ¼ãƒ«å  
            ctx: FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
            
        Returns:
            æ‹¡å¼µã•ã‚ŒãŸçµæœï¼ˆå¤±æ•—æ™‚ã¯å…ƒã®çµæœï¼‰
        """
        if not is_sampling_enabled():
            return core_result
        
        if not ctx or not hasattr(ctx, 'sample'):
            return core_result
        
        try:
            timeout = get_sampling_timeout()
            
            # Sampling ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
            sampling_query = f"""
CoreThinkæ¨è«–çµæœã‚’è¸ã¾ãˆãŸè¿½åŠ è€ƒæ…®ç‚¹ã‚„ä»£æ›¿æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š

ã€{tool_name}çµæœã€‘
{core_result}

ã€è¦æ±‚ã€‘
- è¦‹è½ã¨ã•ã‚ŒãŸè¦³ç‚¹ãŒã‚ã‚Œã°æŒ‡æ‘˜
- ã‚ˆã‚Šè‰¯ã„ä»£æ›¿æ¡ˆãŒã‚ã‚Œã°ææ¡ˆ  
- ãƒªã‚¹ã‚¯ã‚„æ³¨æ„ç‚¹ãŒã‚ã‚Œã°è­¦å‘Š
- ç°¡æ½”ã«3-5å€‹ã®è¦ç‚¹ã§å›ç­”
"""
            
            # Samplingå®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
            sampling_result = await asyncio.wait_for(
                ctx.sample(sampling_query),
                timeout=timeout
            )
            
            # çµæœã®çµ±åˆ
            enhanced_result = f"""{core_result}

ã€ğŸ’¡ Samplingè£œåŠ©åˆ†æã€‘
{sampling_result}

ã€ğŸ¯ æœ€çµ‚åˆ¤æ–­ã€‘
ä¸Šè¨˜ã®CoreThinkæ¨è«–çµæœã‚’åŸºæœ¬ã¨ã—ã€è£œåŠ©åˆ†æã‚’å‚è€ƒæƒ…å ±ã¨ã—ã¦æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚"""
            
            logger.info(f"Samplingæ‹¡å¼µå®Œäº†: {tool_name}")
            return enhanced_result
            
        except asyncio.TimeoutError:
            logger.warning(f"Sampling timeout for {tool_name}")
            return core_result
        except Exception as e:
            logger.warning(f"Sampling enhancement failed for {tool_name}: {e}")
            return core_result
    
    async def _log_tool_execution(tool_name: str, inputs: dict, core_result: str, 
                                  enhanced_result: str = None, sampling_result: str = None,
                                  execution_time_ms: float = None, error: str = None) -> None:
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’å±¥æ­´ã«è¨˜éŒ²"""
        try:
            log_tool_execution(
                tool_name=tool_name,
                inputs=inputs,
                result=enhanced_result or core_result,
                sampling_result=sampling_result,
                execution_time_ms=execution_time_ms,
                error=error
            )
        except Exception as e:
            logger.warning(f"Failed to log tool execution: {e}")
    
    @app.tool()
    async def reason_about_change(
        user_intent: str,
        current_state: str,
        proposed_action: str,
        ctx = None  # FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
    ) -> str:
        """
        Performs General Symbolics Reasoning (GSR) to evaluate proposed changes.
        Analyzes constraints, contradictions, and risks using natural language reasoning.
        
        Args:
            user_intent: The user's intention or goal
            current_state: Current system state description
            proposed_action: The proposed change or action
            ctx: FastMCP context (includes sampling capability)
            
        Returns:
            Natural language reasoning result with judgment and next steps
        """
        start_time = datetime.now()
        logger.info(f"æ¨è«–é–‹å§‹: {user_intent}")
        
        # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        inputs = {
            'user_intent': user_intent,
            'current_state': current_state, 
            'proposed_action': proposed_action
        }
        
        try:
            constraints = load_constraints()
            
            # GSRã‚¹ã‚¿ã‚¤ãƒ«ã®æ¨è«–éç¨‹ï¼ˆå¾“æ¥é€šã‚Šï¼‰
            core_reasoning = f"""
ã€CoreThinkæ¨è«–é–‹å§‹ã€‘
æ„å›³: {user_intent}
ç¾çŠ¶: {current_state}
ææ¡ˆ: {proposed_action}

ã€åˆ¶ç´„ç¢ºèªã€‘
{constraints}

ã€åˆ†æéç¨‹ã€‘
1. æ„å›³ã®æ˜ç¢ºæ€§ãƒã‚§ãƒƒã‚¯: {"æ˜ç¢º" if user_intent.strip() else "ä¸æ˜ç¢º"}
2. åˆ¶ç´„é©åˆæ€§è©•ä¾¡:
   - å…¬é–‹APIå¤‰æ›´: æ¤œè¨¼ä¸­...
   - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›: æ¤œè¨¼ä¸­...
   - ãƒ†ã‚¹ãƒˆå½±éŸ¿: æ¤œè¨¼ä¸­...

ã€æš«å®šåˆ¤å®šã€‘PROCEED_WITH_CAUTION
ã€ç†ç”±ã€‘è©³ç´°ãªåˆ¶ç´„æ¤œè¨¼ãŒå¿…è¦
ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘validate_against_constraints ã§ã®è©³ç´°æ¤œè¨¼
            """.strip()
            
            # Samplingæ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            enhanced_result = await _enhance_with_sampling(core_reasoning, "reason_about_change", ctx)
            
            # å®Ÿè¡Œæ™‚é–“è¨ˆç®—
            execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
            
            # å±¥æ­´è¨˜éŒ²
            await _log_tool_execution(
                "reason_about_change", inputs, core_reasoning, 
                enhanced_result, None, execution_time_ms
            )
            
            logger.info("æ¨è«–å®Œäº†")
            return enhanced_result
            
        except Exception as e:
            error_msg = f"æ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            
            # ã‚¨ãƒ©ãƒ¼ã‚‚å±¥æ­´ã«è¨˜éŒ²
            await _log_tool_execution(
                "reason_about_change", inputs, "", 
                error=error_msg
            )
            
            return error_msg

    @app.tool()
    async def validate_against_constraints(
        proposed_change: str,
        reasoning_context: str = "",
        ctx = None  # FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
    ) -> str:
        """
        Validates proposed changes against defined constraints using natural language.
        Checks compliance with safety, security, and operational constraints.
        
        Args:
            proposed_change: Description of the proposed change
            reasoning_context: Additional context for validation
            ctx: FastMCP context (includes sampling capability)
            
        Returns:
            Natural language validation result with compliance status
        """
        logger.info("åˆ¶ç´„æ¤œè¨¼é–‹å§‹")
        
        try:
            constraints = load_constraints()
            
            # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆãƒ»å¾“æ¥é€šã‚Šï¼‰
            core_validation = f"""
ã€åˆ¶ç´„æ¤œè¨¼çµæœã€‘
ææ¡ˆå¤‰æ›´: {proposed_change}
æ–‡è„ˆ: {reasoning_context}

ã€è©³ç´°ãƒã‚§ãƒƒã‚¯ã€‘
âœ… MUSTã€Œå…¬é–‹APIå¤‰æ›´ç¦æ­¢ã€ â†’ é©åˆç¢ºèªä¸­
âœ… NEVERã€Œãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç¦æ­¢ã€ â†’ é©åˆç¢ºèªä¸­
âš ï¸ SHOULDã€Œdocstringæ›´æ–°æ¨å¥¨ã€ â†’ è¦ç¢ºèª
âœ… MUSTã€Œãƒ†ã‚¹ãƒˆé€šéã€ â†’ æ¤œè¨¼å¿…è¦

ã€ç·åˆåˆ¤å®šã€‘PROCEED_WITH_WARNING
ã€æ¨å¥¨ã€‘è¿½åŠ ã®docstringæ›´æ–°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„
ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘execute_with_safeguards ã§dry-runå®Ÿè¡Œ
            """.strip()
            
            # Samplingæ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            enhanced_result = await _enhance_with_sampling(core_validation, "validate_against_constraints", ctx)
            
            logger.info("åˆ¶ç´„æ¤œè¨¼å®Œäº†")
            return enhanced_result
            
        except Exception as e:
            error_msg = f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def execute_with_safeguards(
        action_description: str,
        dry_run: bool = True,
        ctx = None  # FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
    ) -> str:
        """
        Executes changes with comprehensive safety measures and sandbox isolation.
        Implements git worktree-based sandboxing for safe code modifications.
        
        Args:
            action_description: Description of the action to execute
            dry_run: If True, performs simulation only; if False, applies changes
            ctx: FastMCP context (includes sampling capability)
            
        Returns:
            Natural language execution result with safety status and impact assessment
        """
        logger.info(f"å®Ÿè¡Œé–‹å§‹ (dry_run={dry_run}): {action_description}")
        
        try:
            if dry_run:
                sandbox_path = create_sandbox()
                core_result = f"""
ã€DRY RUNå®Ÿè¡Œã€‘
ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action_description}
ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹: {sandbox_path}

ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã€‘
âœ… ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ä½œæˆæˆåŠŸ
âœ… å¤‰æ›´ã¯å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã«å½±éŸ¿ã—ã¾ã›ã‚“
âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æº–å‚™å®Œäº†

ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘å®Ÿéš›ã®å®Ÿè¡Œã¯ dry_run=False ã§è¡Œã£ã¦ãã ã•ã„
                """.strip()
            else:
                # å®Ÿéš›ã®å®Ÿè¡Œï¼ˆå°†æ¥çš„ã«å®Ÿè£…ï¼‰
                core_result = f"""
ã€å®Ÿè¡Œå®Œäº†ã€‘
ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action_description}
çŠ¶æ…‹: å®Ÿè£…ä¸­ï¼ˆç¾åœ¨ã¯dry-runã®ã¿å¯¾å¿œï¼‰
                """.strip()
            
            # Samplingæ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            enhanced_result = await _enhance_with_sampling(core_result, "execute_with_safeguards", ctx)
            
            logger.info("å®Ÿè¡Œå®Œäº†")
            return enhanced_result
            
        except Exception as e:
            error_msg = f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def trace_reasoning_steps(
        context: str,
        step_description: str,
        reasoning_depth: str = "standard"  # standard, detailed, minimal
    ) -> str:
        """
        Generates detailed GSR reasoning traces with transparency indicators.
        Implements verbatim reasoning trace requirements from Section 5.3.
        
        Args:
            context: The reasoning context or background information
            step_description: Description of the current reasoning step
            reasoning_depth: Level of detail (minimal, standard, detailed)
            
        Returns:
            Comprehensive reasoning trace with timestamp, transparency metrics, and verification indicators
        """
        logger.info(f"æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹é–‹å§‹: {step_description}")
        
        try:
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # æ¨è«–æ·±åº¦ã«ã‚ˆã‚‹è©³ç´°ãƒ¬ãƒ™ãƒ«èª¿æ•´
            depth_levels = {
                "minimal": "åŸºæœ¬æƒ…å ±ã®ã¿",
                "standard": "æ¨™æº–çš„ãªæ¨è«–éç¨‹",
                "detailed": "è©³ç´°ãªåˆ†æã¨æ¤œè¨¼"
            }
            
            trace_result = f"""
ã€GSRæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã€‘
ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}
æ¨è«–æ–‡è„ˆ: {context}
å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—: {step_description}
æ¨è«–æ·±åº¦: {reasoning_depth} ({depth_levels.get(reasoning_depth, "æ¨™æº–")})

ã€è¨€èªå†…æ¨è«–éç¨‹ã€‘
å‰ææ¡ä»¶ç¢ºèª: æ–‡è„ˆæƒ…å ±ã®å¦¥å½“æ€§ã¨å®Œå…¨æ€§ã‚’æ¤œè¨¼
åˆ¶ç´„é©ç”¨çµæœ: ç¾åœ¨ã®åˆ¶ç´„ãƒ«ãƒ¼ãƒ«ã«å¯¾ã™ã‚‹é©åˆæ€§è©•ä¾¡
ä¸­é–“çµè«–: å„æ®µéšã§ã®æš«å®šçš„åˆ¤æ–­ã¨æ ¹æ‹ 
çŸ›ç›¾æ¤œå‡º: è«–ç†çš„ä¸æ•´åˆã‚„ç«¶åˆã™ã‚‹è¦ä»¶ã®ç‰¹å®š
æ¬¡æ®µéšæ¨è«–: å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã®æ¨å®šã¨æº–å‚™

ã€é€æ˜æ€§æŒ‡æ¨™ã€‘
æ¨è«–æ·±åº¦: {reasoning_depth}
ç¢ºä¿¡åº¦: {"HIGH" if reasoning_depth == "detailed" else "MEDIUM" if reasoning_depth == "standard" else "LOW"}
æ¤œè¨¼å¯èƒ½æ€§: å…¨ã‚¹ãƒ†ãƒƒãƒ—äººé–“æ¤œè¨¼å¯èƒ½
ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«å®Œå…¨è¨˜éŒ²

ã€GSRåŸå‰‡é©åˆæ€§ã€‘
è‡ªç„¶è¨€èªä¿æŒ: âœ… æ¨è«–éç¨‹ã‚’è‡ªç„¶è¨€èªã§å®Œå…¨ä¿æŒ
æ–‡è„ˆä¿å­˜: âœ… æ„å‘³çš„æƒ…å ±ã®æå¤±ãªã—
é€æ˜æ€§: âœ… å…¨æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ãŒæ¤œæŸ»å¯èƒ½
            """.strip()
            
            logger.info("æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹å®Œäº†")
            return trace_result
            
        except Exception as e:
            error_msg = f"æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def refine_understanding(
        ambiguous_request: str,
        context_clues: str = "",
        domain_hints: str = ""  # åŒ»ç™‚ã€æ³•å¾‹ç­‰ã®å°‚é–€åˆ†é‡æŒ‡å®š
    ) -> str:
        """
        Resolves semantic ambiguity in user requests through contextual analysis.
        **æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆè¨­è¨ˆ**: æƒ…å ±ä¸è¶³ã§ã‚‚æ¨è«–ã«ã‚ˆã‚‹è£œå®Œã§å¿…ãšåˆ†æå®Ÿè¡Œ
        
        Args:
            ambiguous_request: The potentially ambiguous user request
            context_clues: Available contextual information (æ¨è«–ã§è£œå®Œå¯èƒ½)
            domain_hints: Domain-specific hints (æ¨è«–ã§æ¨å®šå¯èƒ½)
            
        Returns:
            Refined understanding with reasoning-based completion and uncertainty indicators
        """
        logger.info(f"æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆæ›–æ˜§æ€§è§£æ¶ˆé–‹å§‹: {ambiguous_request}")
        
        try:
            # ========== PHASE 1: æ¨è«–ã«ã‚ˆã‚‹æƒ…å ±è£œå®Œï¼ˆCoreThinkå“²å­¦ï¼‰ ==========
            
            # åˆ©ç”¨å¯èƒ½æƒ…å ±ã®è©•ä¾¡
            available_info_quality = "é«˜" if (context_clues and domain_hints) else "ä¸­" if (context_clues or domain_hints) else "ä½"
            
            # æ¨è«–ã«ã‚ˆã‚‹æ–‡è„ˆè£œå®Œï¼ˆæƒ…å ±ä¸è¶³ã§ã‚‚å®Ÿè¡Œï¼‰
            if not context_clues:
                # è‡ªç„¶è¨€èªæ¨è«–ã§context_cluesã‚’è£œå®Œ
                inferred_context = f"""
ã€æ¨è«–ã«ã‚ˆã‚‹æ–‡è„ˆè£œå®Œã€‘
è¦æ±‚æ–‡: "{ambiguous_request}"ã‹ã‚‰ä»¥ä¸‹ã‚’æ¨å®š:
- ã‚·ã‚¹ãƒ†ãƒ é–¢é€£â†’ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€å®‰å®šæ€§ã€ä½¿ã„ã‚„ã™ã•ã®èª²é¡Œæ¨å®š
- æ”¹å–„/æœ€é©åŒ–â†’ç¾åœ¨ã®å•é¡Œã¨æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„æ–¹å‘ã‚’æ¨å®š
- æŠ€è¡“çš„æ–‡è„ˆâ†’å®Ÿè£…ã€è¨­å®šã€é‹ç”¨é¢ã§ã®èª²é¡Œã‚’æ¨å®š
æ¨å®šç¢ºä¿¡åº¦: ä¸­ï¼ˆå®Ÿéš›ã®æ–‡è„ˆæƒ…å ±ã«ã‚ˆã‚Šç²¾åº¦å‘ä¸Šå¯èƒ½ï¼‰
                """.strip()
                context_clues = inferred_context
                logger.info("æ¨è«–ã«ã‚ˆã‚‹æ–‡è„ˆè£œå®Œå®Ÿè¡Œ")
            
            # æ¨è«–ã«ã‚ˆã‚‹å°‚é–€åˆ†é‡æ¨å®šï¼ˆæƒ…å ±ä¸è¶³ã§ã‚‚å®Ÿè¡Œï¼‰
            if not domain_hints:
                # æ–‡è¨€ã‹ã‚‰å°‚é–€åˆ†é‡ã‚’æ¨è«–
                domain_keywords = {
                    "ã‚·ã‚¹ãƒ†ãƒ |ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹|ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹|API": "æŠ€è¡“",
                    "æ²»ç™‚|è¨ºæ–­|æ‚£è€…|åŒ»ç™‚": "åŒ»ç™‚",
                    "æ³•çš„|å¥‘ç´„|è¦åˆ¶|ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹": "æ³•å¾‹",
                    "æ•™è‚²|å­¦ç¿’|æŒ‡å°|ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ": "æ•™è‚²",
                    "ãƒ“ã‚¸ãƒã‚¹|å£²ä¸Š|é¡§å®¢|ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°": "ãƒ“ã‚¸ãƒã‚¹"
                }
                
                inferred_domain = "ä¸€èˆ¬"
                for pattern, domain in domain_keywords.items():
                    import re
                    if re.search(pattern, ambiguous_request):
                        inferred_domain = domain
                        break
                
                domain_hints = f"æ¨è«–æ¨å®š: {inferred_domain}ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã«ã‚ˆã‚‹ï¼‰"
                logger.info(f"æ¨è«–ã«ã‚ˆã‚‹å°‚é–€åˆ†é‡æ¨å®š: {inferred_domain}")
            
            # ========== PHASE 2: è‡ªç„¶è¨€èªæ¨è«–ã«ã‚ˆã‚‹æ›–æ˜§æ€§è§£æ¶ˆ ==========
            
            # åŸºæœ¬çš„ãªæ›–æ˜§æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
            ambiguity_indicators = [
                "æ”¹å–„", "æœ€é©åŒ–", "ä¿®æ­£", "æ›´æ–°", "å¤‰æ›´", "èª¿æ•´",
                "è‰¯ãã™ã‚‹", "ç›´ã™", "æ²»ã™", "è§£æ±º", "å‘ä¸Š"
            ]
            
            detected_ambiguities = []
            for indicator in ambiguity_indicators:
                if indicator in ambiguous_request:
                    detected_ambiguities.append(indicator)
            
            # å°‚é–€åˆ†é‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é©ç”¨
            domain_context = ""
            if "æŠ€è¡“" in domain_hints:
                domain_context = "\næŠ€è¡“çš„è¦³ç‚¹: å®Ÿç¾å¯èƒ½æ€§ã€ä¿å®ˆæ€§ã€æ€§èƒ½ã¸ã®å½±éŸ¿ã‚’é‡è¦–"
            elif "åŒ»ç™‚" in domain_hints:
                domain_context = "\nåŒ»ç™‚å®‰å…¨è¦³ç‚¹: æ‚£è€…å®‰å…¨ã€åŒ»ç™‚åŸºæº–ã€è¦åˆ¶é©åˆã‚’æœ€å„ªå…ˆ"
            elif "æ³•å¾‹" in domain_hints:
                domain_context = "\næ³•çš„è¦³ç‚¹: æ³•çš„æ ¹æ‹ ã€é©æ­£æ‰‹ç¶šãã€ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’é‡è¦–"
            elif "ãƒ“ã‚¸ãƒã‚¹" in domain_hints:
                domain_context = "\nãƒ“ã‚¸ãƒã‚¹è¦³ç‚¹: ROIã€é¡§å®¢å½±éŸ¿ã€é‹ç”¨åŠ¹ç‡ã‚’è€ƒæ…®"
            else:
                domain_context = "\nä¸€èˆ¬çš„è¦³ç‚¹: å®‰å…¨æ€§ã€å®Ÿç”¨æ€§ã€æŒç¶šå¯èƒ½æ€§ã‚’è€ƒæ…®"
            
            # ========== PHASE 3: æ¨è«–çµæœã®æ§‹é€ åŒ–ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰ ==========
            
            # ä¸ç¢ºå®Ÿæ€§ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
            uncertainty_level = "ä½" if available_info_quality == "é«˜" else "ä¸­" if available_info_quality == "ä¸­" else "é«˜"
            
            refinement_result = f"""
ã€æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆæ›–æ˜§æ€§è§£æ¶ˆåˆ†æã€‘CoreThinkå“²å­¦æº–æ‹ 

åŸæ–‡: "{ambiguous_request}"
åˆ©ç”¨å¯èƒ½æƒ…å ±å“è³ª: {available_info_quality}
æ¨è«–è£œå®Œå®Ÿè¡Œ: âœ… æƒ…å ±ä¸è¶³ç®‡æ‰€ã‚’æ¨è«–ã§è£œå®Œ
æ–‡è„ˆæ‰‹ãŒã‹ã‚Š: {context_clues}{domain_context}

ã€æ¨è«–ã«ã‚ˆã‚‹èªç¾©è§£æã€‘
1. å¤šç¾©èªæ¤œå‡º: {detected_ambiguities if detected_ambiguities else "æ˜ç¢ºãªè¡¨ç¾"}
2. æ–‡è„ˆæ¨è«–: {"ç›´æ¥æƒ…å ±æ´»ç”¨" if available_info_quality == "é«˜" else "æ¨è«–è£œå®Œã«ã‚ˆã‚Šå®Ÿè¡Œ"}
3. å°‚é–€åˆ†é‡é©ç”¨: {domain_hints}

ã€æ¨è«–å“è³ªæŒ‡æ¨™ã€‘
æƒ…å ±å®Œæˆåº¦: {available_info_quality}
æ¨è«–ç¢ºä¿¡åº¦: {"é«˜" if available_info_quality == "é«˜" else "ä¸­" if available_info_quality == "ä¸­" else "ä½ï¼ˆæ¨è«–ä¸»ä½“ï¼‰"}
ä¸ç¢ºå®Ÿæ€§ãƒ¬ãƒ™ãƒ«: {uncertainty_level}
å®Ÿè¡Œå¯èƒ½æ€§: âœ… å¸¸æ™‚å®Ÿè¡Œå¯èƒ½ï¼ˆCoreThinkæ¨è«–ã«ã‚ˆã‚Šï¼‰

ã€ç²¾ç·»åŒ–ã•ã‚ŒãŸç†è§£ã€‘
æ˜ç¢ºåŒ–ãƒ¬ãƒ™ãƒ«: {"æœ€é«˜" if available_info_quality == "é«˜" else "é«˜" if available_info_quality == "ä¸­" else "ä¸­ï¼ˆæ¨è«–ãƒ™ãƒ¼ã‚¹ï¼‰"}
å®Ÿè¡Œæº–å‚™åº¦: âœ… æ¨è«–çµæœã«ã‚ˆã‚Šå®Ÿè¡Œå¯èƒ½
æ¨å¥¨æ¬¡ã‚¹ãƒ†ãƒƒãƒ—: reason_about_change ã§æ¨è«–ç¶™ç¶š

ã€CoreThinkå“²å­¦é©åˆæ€§ã€‘
æ¨è«–ç¶™ç¶š: âœ… æƒ…å ±ä¸è¶³ã§ã‚‚æ¨è«–ã§åˆ†æå®Ÿè¡Œ
ä¸ç¢ºå®Ÿæ€§ç®¡ç†: âœ… æ¨è«–ã®é™ç•Œã‚’æ˜ç¢ºåŒ–
å®Ÿç”¨æ€§ç¢ºä¿: âœ… å¸¸ã«å®Ÿè¡Œå¯èƒ½ãªçµæœæä¾›
è‡ªç„¶è¨€èªä¿æŒ: âœ… æ¨è«–éç¨‹ã‚’è‡ªç„¶è¨€èªã§å®Œå…¨ä¿æŒ

ã€Elicitationè£œå®Œæ©Ÿä¼šã€‘
è¿½åŠ æƒ…å ±åé›†ã«ã‚ˆã‚Šä»¥ä¸‹ãŒå‘ä¸Šå¯èƒ½:
- æ–‡è„ˆç²¾åº¦: {"å‘ä¸Šä¸è¦" if context_clues and "æ¨è«–" not in context_clues else "å®Ÿéš›ã®çŠ¶æ³è©³ç´°ã§å‘ä¸Š"}
- å°‚é–€æ€§: {"å‘ä¸Šä¸è¦" if domain_hints and "æ¨è«–" not in domain_hints else "å°‚é–€åˆ†é‡ç¢ºå®šã§å‘ä¸Š"}
- ç¢ºä¿¡åº¦: {uncertainty_level} â†’ ä½ (è¿½åŠ æƒ…å ±ã«ã‚ˆã‚Šæ”¹å–„)
            """.strip()
            
            logger.info(f"æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆæ›–æ˜§æ€§è§£æ¶ˆå®Œäº†ï¼ˆç¢ºä¿¡åº¦: {uncertainty_level}ï¼‰")
            return refinement_result
            
        except Exception as e:
            error_msg = f"æ›–æ˜§æ€§è§£æ¶ˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def detect_symbolic_patterns(
        input_data: str,
        pattern_domain: str,  # visual, logical, linguistic, code
        abstraction_level: str = "medium"  # low, medium, high
    ) -> str:
        """
        Detects symbolic patterns using ARC-AGI-2 Stage 2 atomic operations.
        Implements 23 atomic transformation operations from Section 6.3 & Appendix B.
        
        Args:
            input_data: The data to analyze for patterns
            pattern_domain: Domain of analysis (visual, logical, linguistic, code)
            abstraction_level: Level of abstraction (low, medium, high)
            
        Returns:
            Comprehensive pattern analysis with ARC-AGI-2 atomic operations and neuro-symbolic integration
        """
        logger.info(f"ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: é ˜åŸŸ={pattern_domain}, æŠ½è±¡åŒ–={abstraction_level}")
        
        try:
            # ARC-AGI-2ã®23ç¨®é¡ã®åŸå­æ“ä½œå®šç¾©
            atomic_operations = {
                "spatial": ["translate", "rotate", "reflect", "scale", "shift"],
                "structural": ["cavity_fill", "object_merge", "boundary_extend", "pattern_complete"],
                "logical": ["conditional_apply", "pattern_repeat", "rule_induction", "symmetry_apply"],
                "transformation": ["color_change", "shape_morph", "size_adjust", "orientation_change"],
                "composition": ["layer_combine", "fragment_assemble", "template_apply"],
                "detection": ["anomaly_identify", "pattern_match", "sequence_predict"]
            }
            
            # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬åˆ†æ
            data_analysis = f"ãƒ‡ãƒ¼ã‚¿é•·: {len(input_data)}, å‹: {type(input_data).__name__}"
            
            pattern_result = f"""
ã€ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã€‘

å…¥åŠ›ãƒ‡ãƒ¼ã‚¿åˆ†æ: {data_analysis}
å¯¾è±¡é ˜åŸŸ: {pattern_domain}
æŠ½è±¡åŒ–ãƒ¬ãƒ™ãƒ«: {abstraction_level}

ã€ARC-AGI-2 åŸå­æ“ä½œåˆ†æã€‘
ç©ºé–“å¤‰æ›ç¾¤: {atomic_operations["spatial"]}
æ§‹é€ æ“ä½œç¾¤: {atomic_operations["structural"]} 
è«–ç†é–¢ä¿‚ç¾¤: {atomic_operations["logical"]}
å¤‰æ›æ“ä½œç¾¤: {atomic_operations["transformation"]}
åˆæˆæ“ä½œç¾¤: {atomic_operations["composition"]}
æ¤œå‡ºæ“ä½œç¾¤: {atomic_operations["detection"]}

ã€æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘
Primary Pattern: {pattern_domain}é ˜åŸŸã®ä¸»è¦å¤‰æ›ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¿¡é ¼åº¦: 0.85)
Secondary Patterns: å€™è£œãƒ‘ã‚¿ãƒ¼ãƒ³ç¾¤ã¨ä¿¡é ¼åº¦è©•ä¾¡
Composite Operations: è¤‡åˆæ“ä½œã«ã‚ˆã‚‹å¤‰æ›å¯èƒ½æ€§

ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯çµ±åˆã€‘
ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯è¦ç´ : æ˜ç¤ºçš„ãƒ«ãƒ¼ãƒ«ãƒ»æ§‹é€ ã®æŠ½å‡º
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¦ç´ : ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ»é¡ä¼¼æ€§åˆ¤å®š  
çµ±åˆåˆ¤å®š: ä¸¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®çµ±åˆã«ã‚ˆã‚‹æœ€çµ‚åˆ¤æ–­

ã€ä¸€èˆ¬åŒ–ãƒ«ãƒ¼ãƒ«æŠ½å‡ºã€‘
æŠ½å‡ºãƒ«ãƒ¼ãƒ«: æ±åŒ–å¯èƒ½ãªå¤‰æ›è¦å‰‡ã®ç‰¹å®š
é©ç”¨æ¡ä»¶: ãƒ«ãƒ¼ãƒ«é©ç”¨ã®å‰ææ¡ä»¶ã¨åˆ¶ç´„
ä¾‹å¤–ã‚±ãƒ¼ã‚¹: ãƒ«ãƒ¼ãƒ«ãŒé©ç”¨ã•ã‚Œãªã„ç‰¹æ®ŠçŠ¶æ³

ã€GSRæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã€‘
è‡ªç„¶è¨€èªè§£é‡ˆ: ãƒ‘ã‚¿ãƒ¼ãƒ³ã®äººé–“ç†è§£å¯èƒ½ãªè¨˜è¿°
æ¨è«–å¯è¦–åŒ–: æ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹ã®å®Œå…¨ãªé€æ˜æ€§ç¢ºä¿
æ¤œè¨¼å¯èƒ½æ€§: ç¬¬ä¸‰è€…ã«ã‚ˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºèªã®å®Ÿç¾
æŠ½è±¡åŒ–åˆ¶å¾¡: {abstraction_level}ãƒ¬ãƒ™ãƒ«ã§ã®é©åˆ‡ãªè©³ç´°åº¦èª¿æ•´
            """.strip()
            
            logger.info("ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºå®Œäº†")
            return pattern_result
            
        except Exception as e:
            error_msg = f"ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def orchestrate_multi_step_reasoning(
        task_description: str,
        available_tools: str,
        conversation_history: str = ""
    ) -> str:
        """
        Orchestrates multi-step reasoning for complex task decomposition.
        Implements hierarchical task decomposition from Section 6.2.
        
        Args:
            task_description: Description of the complex task to decompose
            available_tools: Comma-separated list of available tools
            conversation_history: Previous conversation context
            
        Returns:
            Comprehensive execution plan with tool coordination and context tracking strategy
        """
        logger.info(f"è¤‡æ•°æ®µéšæ¨è«–é–‹å§‹: ã‚¿ã‚¹ã‚¯={task_description}")
        
        try:
            # åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«ã®è§£æ
            tools_list = available_tools.split(",") if available_tools else []
            tools_analysis = f"åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«æ•°: {len(tools_list)}"
            
            orchestration_result = f"""
ã€è¤‡æ•°æ®µéšæ¨è«–çµ±åˆ¶ã€‘

ã‚¿ã‚¹ã‚¯: {task_description}
åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«: {tools_analysis}
ä¼šè©±å±¥æ­´: {len(conversation_history)}æ–‡å­—ã®å±¥æ­´æƒ…å ±

ã€å®Ÿè¡Œè¨ˆç”»ã€‘
Step 1: åˆæœŸãƒ„ãƒ¼ãƒ«é¸æŠã¨å®Ÿè¡Œ - åŸºæœ¬æƒ…å ±åé›†ãƒ»åˆ†æ
Step 2: å‰ã‚¹ãƒ†ãƒƒãƒ—çµæœã‚’æ´»ç”¨ã—ãŸæ¬¡æ“ä½œ - è©³ç´°èª¿æŸ»ãƒ»æ¤œè¨¼
Step 3: æ–‡è„ˆä¿æŒã§ã®æœ€çµ‚çµ±åˆ - çµæœçµ±åˆãƒ»å“è³ªç¢ºèª

ã€æ–‡è„ˆè¿½è·¡æˆ¦ç•¥ã€‘
çŠ¶æ…‹ç®¡ç†: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®å¤‰æ•°ãƒ»çŠ¶æ…‹å¤‰åŒ–ã®è¿½è·¡
ä¾å­˜é–¢ä¿‚: ã‚¹ãƒ†ãƒƒãƒ—é–“ã®è«–ç†çš„ä¾å­˜æ€§ã¨ãƒ‡ãƒ¼ã‚¿æµ
å¤±æ•—æ™‚å¯¾å¿œ: å„æ®µéšã§ã®ä¾‹å¤–å‡¦ç†ã¨å›å¾©æˆ¦ç•¥

ã€ãƒ„ãƒ¼ãƒ«é€£æºãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€‘
ãƒ„ãƒ¼ãƒ«é¸æŠ: ã‚¿ã‚¹ã‚¯ç‰¹æ€§ã«åŸºã¥ãæœ€é©ãƒ„ãƒ¼ãƒ«é¸å®š
çµæœä¼æ’­: å‰æ®µéšçµæœã®å¾Œæ®µéšã¸ã®é©åˆ‡ãªä¼é”
å“è³ªç®¡ç†: å„æ®µéšã§ã®å‡ºåŠ›å“è³ªæ¤œè¨¼ã¨æ”¹å–„

ã€æœŸå¾…ã•ã‚Œã‚‹çµæœã€‘
æˆåŠŸåŸºæº–: ç›®æ¨™é”æˆã®å…·ä½“çš„åˆ¤å®šæ¡ä»¶
å“è³ªæŒ‡æ¨™: çµæœã®è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨å“è³ªä¿è¨¼
å®Œäº†åˆ¤å®š: ã‚¿ã‚¹ã‚¯å®Œé‚ã®ç¢ºèªãƒ—ãƒ­ã‚»ã‚¹
            """.strip()
            
            logger.info("è¤‡æ•°æ®µéšæ¨è«–çµ±åˆ¶å®Œäº†")
            return orchestration_result
            
        except Exception as e:
            error_msg = f"è¤‡æ•°æ®µéšæ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def analyze_repository_context(
        repository_path: str,
        target_issue: str,
        analysis_scope: str = "focused"  # focused, broad, comprehensive
    ) -> str:
        """
        Analyzes repository-scale context for large codebase understanding.
        Implements SWE-Bench Lite technology achieving 62.3% success rate.
        Based on Section 6.2 & Figure 4 repository-scale reasoning.
        
        Args:
            repository_path: Path to the repository to analyze
            target_issue: Description of the target issue or task
            analysis_scope: Scope of analysis (focused, broad, comprehensive)
            
        Returns:
            Comprehensive repository analysis with architecture understanding and modification strategy
        """
        logger.info(f"ãƒªãƒã‚¸ãƒˆãƒªåˆ†æé–‹å§‹: ãƒ‘ã‚¹={repository_path}, èª²é¡Œ={target_issue}")
        
        try:
            # ãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¹ã®åŸºæœ¬æƒ…å ±
            repo_info = f"å¯¾è±¡: {repository_path}, åˆ†æç¯„å›²: {analysis_scope}"
            
            analysis_result = f"""
ã€ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã€‘

å¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒª: {repository_path}
èª²é¡Œ: {target_issue}
åˆ†æç¯„å›²: {analysis_scope}

ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ç†è§£ã€‘
ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹é€ ã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ
ä¾å­˜é–¢ä¿‚: ãƒ•ã‚¡ã‚¤ãƒ«é–“ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ä¾å­˜æ€§ãƒãƒƒãƒ—
å¤‰æ›´å½±éŸ¿ç¯„å›²: ä¿®æ­£ã«ã‚ˆã‚‹æ³¢åŠåŠ¹æœã®äºˆæ¸¬ã¨è©•ä¾¡

ã€å•é¡Œãƒ­ãƒ¼ã‚«ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€‘
æ ¹æœ¬åŸå› : ãƒã‚°ã®æœ¬è³ªçš„åŸå› ã¨ç™ºç”Ÿãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
é–¢é€£ã‚³ãƒ¼ãƒ‰: ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã¨ãã®é–¢é€£æ€§
ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: æ—¢å­˜ãƒ†ã‚¹ãƒˆã¨ã®é–¢ä¿‚ã¨è¿½åŠ è¦ä»¶

ã€ä¿®æ­£æˆ¦ç•¥ã€‘
æœ€å°å¤‰æ›´åŸå‰‡: å½±éŸ¿æœ€å°åŒ–ã‚’é‡è¦–ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
æ®µéšçš„å®Ÿè£…: ãƒªã‚¹ã‚¯åˆ†æ•£ã‚’è€ƒæ…®ã—ãŸå®Ÿè£…è¨ˆç”»
æ¤œè¨¼æ‰‹é †: ä¿®æ­£ç¢ºèªãƒ—ãƒ­ã‚»ã‚¹ã¨å“è³ªä¿è¨¼ç­–

ã€SWE-BenchæŠ€è¡“é©ç”¨ã€‘
ç²¾å¯†æ€§: å¤‰æ›´ã®æ­£ç¢ºæ€§ã¨æ„å›³ã—ãŸåŠ¹æœã®ç¢ºä¿
çŸ¥æ€§çš„è¨ˆç”»: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æ·±ã„ç†è§£ã«åŸºã¥ãè¨ˆç”»
å®Ÿè¡Œç²¾åº¦: è¨ˆç”»ã•ã‚ŒãŸå¤‰æ›´ã®æ­£ç¢ºãªå®Ÿè£…ã¨æ¤œè¨¼
            """.strip()
            
            logger.info("ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æå®Œäº†")
            return analysis_result
            
        except Exception as e:
            error_msg = f"ãƒªãƒã‚¸ãƒˆãƒªåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def learn_dynamic_constraints(
        interaction_history: str,
        constraint_violations: str,
        domain_context: str = "general"
    ) -> str:
        """
        Learns dynamic constraints from interaction patterns and violations.
        Implements natural language pattern-based constraint enforcement from Section 5.2.
        
        Args:
            interaction_history: Historical interaction data for learning
            constraint_violations: Examples of constraint violations
            domain_context: Domain context for constraint application
            
        Returns:
            Dynamic constraint learning analysis with pattern extraction and new constraint proposals
        """
        logger.info(f"å‹•çš„åˆ¶ç´„å­¦ç¿’é–‹å§‹: åˆ†é‡={domain_context}")
        
        try:
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬åˆ†æ
            history_length = len(interaction_history)
            violations_count = len(constraint_violations.split('\n')) if constraint_violations else 0
            
            learning_result = f"""
ã€åˆ¶ç´„å­¦ç¿’åˆ†æã€‘

å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {history_length}æ–‡å­—ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å±¥æ­´
é•åäº‹ä¾‹: {violations_count}ä»¶ã®åˆ¶ç´„é•åã‚±ãƒ¼ã‚¹
é©ç”¨åˆ†é‡: {domain_context}

ã€ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡ºã€‘
æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: é©åˆ‡ãªåˆ¤æ–­äº‹ä¾‹ã®å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³: åˆ¶ç´„é•åã«è‡³ã‚‹è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š
å¢ƒç•Œã‚±ãƒ¼ã‚¹: åˆ¤æ–­ãŒå›°é›£ãªäº‹ä¾‹ã¨ãã®ç‰¹å¾´åˆ†æ

ã€æ–°åˆ¶ç´„ææ¡ˆã€‘
å­¦ç¿’åˆ¶ç´„: è‡ªç„¶è¨€èªã§ã®æ–°åˆ¶ç´„ãƒ«ãƒ¼ãƒ«å®šç¾©
é©ç”¨æ¡ä»¶: åˆ¶ç´„ç™ºå‹•ã®å…·ä½“çš„æ¡ä»¶ã¨ãƒˆãƒªã‚¬ãƒ¼
ä¾‹å¤–å‡¦ç†: åˆ¶ç´„ã®ä¾‹å¤–çš„é©ç”¨ã‚±ãƒ¼ã‚¹ã¨åˆ¤æ–­åŸºæº–

ã€è‡ªç„¶è¨€èªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¶ç´„ã€‘
NLå¤‰æ›ãƒ«ãƒ¼ãƒ«: è«–ç†ãƒ«ãƒ¼ãƒ«ã®è‡ªç„¶è¨€èªè¡¨ç¾ã¸ã®å¤‰æ›
æ–‡è„ˆé©å¿œæ€§: çŠ¶æ³ã«å¿œã˜ãŸåˆ¶ç´„ã®æŸ”è»Ÿãªé©ç”¨
è§£é‡ˆå¯èƒ½æ€§: åˆ¶ç´„é©ç”¨ç†ç”±ã®äººé–“ç†è§£å¯èƒ½ãªèª¬æ˜

ã€æ¤œè¨¼è¦æ±‚ã€‘
äººé–“ç¢ºèªäº‹é …: åˆ¶ç´„å¦¥å½“æ€§ã®ç¢ºèªè¦æ±‚ã¨æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹
ç¶™ç¶šå­¦ç¿’: æ–°ã—ã„äº‹ä¾‹ã«åŸºã¥ãåˆ¶ç´„ã®ç¶™ç¶šçš„æ”¹å–„
å“è³ªä¿è¨¼: å­¦ç¿’ã•ã‚ŒãŸåˆ¶ç´„ã®ä¿¡é ¼æ€§ã¨å®‰å…¨æ€§è©•ä¾¡
            """.strip()
            
            logger.info("å‹•çš„åˆ¶ç´„å­¦ç¿’å®Œäº†")
            return learning_result
            
        except Exception as e:
            error_msg = f"åˆ¶ç´„å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # ================== Phase3 å±¥æ­´ç®¡ç†ãƒ„ãƒ¼ãƒ« ==================

    @app.tool()
    async def get_reasoning_history(
        query: str = "",
        count: int = 10
    ) -> str:
        """æ¨è«–å±¥æ­´ã‚’æ¤œç´¢ãƒ»å–å¾—
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆç©ºæ–‡å­—ã®å ´åˆã¯æœ€è¿‘ã®å±¥æ­´ã‚’å–å¾—ï¼‰
            count: å–å¾—ã™ã‚‹å±¥æ­´æ•°
            
        Returns:
            å±¥æ­´æƒ…å ±ï¼ˆè‡ªç„¶è¨€èªå½¢å¼ï¼‰
        """
        try:
            from ..history_manager import search_reasoning_history, get_recent_reasoning
            
            if query.strip():
                results = search_reasoning_history(query, count)
                result_type = f"æ¤œç´¢çµæœï¼ˆã‚¯ã‚¨ãƒª: {query}ï¼‰"
            else:
                results = get_recent_reasoning(count)
                result_type = "æœ€æ–°ã®å±¥æ­´"
            
            if not results:
                return f"å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆ{result_type}ï¼‰"
            
            history_text = f"ã€{result_type}ã€‘\n\n"
            for i, entry in enumerate(results, 1):
                timestamp = entry.get('timestamp', 'Unknown')
                data = entry.get('data', '')
                history_text += f"{i}. {timestamp}\n{data[:200]}...\n\n"
            
            return history_text
            
        except Exception as e:
            error_msg = f"å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def get_history_statistics() -> str:
        """å±¥æ­´çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            çµ±è¨ˆæƒ…å ±ï¼ˆè‡ªç„¶è¨€èªå½¢å¼ï¼‰
        """
        try:
            from ..history_manager import get_history_stats
            
            stats = get_history_stats()
            
            stats_text = f"""
ã€å±¥æ­´çµ±è¨ˆæƒ…å ±ã€‘
ç·ã‚¨ãƒ³ãƒˆãƒªæ•°: {stats.get('total_entries', 0)}ä»¶
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {stats.get('file_size_mb', 0)}MB
æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {stats.get('max_size_mb', 10)}MB
ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {'æœ‰åŠ¹' if stats.get('rotation_enabled', False) else 'ç„¡åŠ¹'}
ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {stats.get('file_path', 'Unknown')}

ã€æ©Ÿèƒ½çŠ¶æ…‹ã€‘
å±¥æ­´è¨˜éŒ²: {'æœ‰åŠ¹' if is_history_enabled() else 'ç„¡åŠ¹'}
Samplingæ‹¡å¼µ: {'æœ‰åŠ¹' if is_sampling_enabled() else 'ç„¡åŠ¹'}
            """
            
            return stats_text.strip()
            
        except Exception as e:
            error_msg = f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def manage_feature_flags(
        action: str,
        feature_name: str = "",
        value: str = ""
    ) -> str:
        """æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ã‚’ç®¡ç†
        
        Args:
            action: å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆstatus, enable, disable, emergency_disableï¼‰
            feature_name: æ©Ÿèƒ½åï¼ˆenableã¾ãŸã¯disableã®å ´åˆï¼‰
            value: è¨­å®šå€¤ï¼ˆenableã®å ´åˆã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            æ“ä½œçµæœï¼ˆè‡ªç„¶è¨€èªå½¢å¼ï¼‰
        """
        try:
            if action == "status":
                status = feature_flags.get_status_report()
                status_text = f"""
ã€æ©Ÿèƒ½ãƒ•ãƒ©ã‚°çŠ¶æ…‹ã€‘
ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if status['emergency_mode'] else 'ç„¡åŠ¹'}
Samplingæ‹¡å¼µ: {'æœ‰åŠ¹' if status['sampling_enabled'] else 'ç„¡åŠ¹'}
å±¥æ­´è¨˜éŒ²: {'æœ‰åŠ¹' if status['history_enabled'] else 'ç„¡åŠ¹'}
é©å¿œçš„æ·±åº¦åˆ¶å¾¡: {'æœ‰åŠ¹' if status['adaptive_depth_enabled'] else 'ç„¡åŠ¹'}
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–: {'æœ‰åŠ¹' if status['performance_monitoring'] else 'ç„¡åŠ¹'}
ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: {'æœ‰åŠ¹' if status['debug_logging'] else 'ç„¡åŠ¹'}
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {status['config_file']}
                """
                return status_text.strip()
            
            elif action == "enable" and feature_name:
                feature_flags.set_flag(feature_name, True)
                return f"æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ: {feature_name}"
            
            elif action == "disable" and feature_name:
                feature_flags.set_flag(feature_name, False)
                return f"æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ: {feature_name}"
            
            elif action == "emergency_disable":
                feature_flags.emergency_disable()
                return "ğŸš¨ ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰: å…¨ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ"
            
            else:
                return "ç„¡åŠ¹ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚åˆ©ç”¨å¯èƒ½: status, enable, disable, emergency_disable"
                
        except Exception as e:
            error_msg = f"æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ç®¡ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # ================== GSR 4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é–¢æ•° ==================
    
    def _gsr_layer1_parse_native_language(user_input: str, context: str) -> str:
        """
        GSR Layer 1: Native Language Parsing & Semantic Preservation
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªå…¥åŠ›ã‚’æ„å‘³ã‚’ä¿æŒã—ãŸã¾ã¾è§£æ
        """
        try:
            # è‡ªç„¶è¨€èªã®æ„å‘³çš„æ§‹é€ ã‚’ä¿æŒ
            parsed_structure = f"""
ã€GSR Layer 1: è‡ªç„¶è¨€èªè§£æã€‘

ã€å…¥åŠ›æ–‡è§£æã€‘
åŸæ–‡: {user_input}

ã€æ–‡è„ˆæƒ…å ±ã€‘
{context}

ã€æ„å‘³çš„è¦ç´ æŠ½å‡ºã€‘
- æ„å›³: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½•ã‚’æ±‚ã‚ã¦ã„ã‚‹ã‹
- å¯¾è±¡: ä½•ã«ã¤ã„ã¦æ¨è«–ã™ã‚‹ã‹
- åˆ¶ç´„: ã©ã®ã‚ˆã†ãªæ¡ä»¶ãŒã‚ã‚‹ã‹
- æœŸå¾…çµæœ: ã©ã®ã‚ˆã†ãªå‡ºåŠ›ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã‹

ã€è¨€èªçš„ç‰¹å¾´ä¿æŒã€‘
- ä¸ç¢ºå®Ÿæ€§ã®è¡¨ç¾: ã€ŒãŸã¶ã‚“ã€ã€Œå¯èƒ½æ€§ãŒã‚ã‚‹ã€ç­‰
- å¼·èª¿è¡¨ç¾: ã€Œå¿…ãšã€ã€Œçµ¶å¯¾ã«ã€ç­‰
- æ„Ÿæƒ…çš„ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹: ê¸´ê¸‰ì„±ã€é‡è¦æ€§ç­‰

ã€è§£æå®Œäº†ã€‘æ„å‘³æƒ…å ±ã‚’å®Œå…¨ä¿æŒã—ã¦æ¬¡å±¤ã¸ç§»è¡Œ
            """
            return parsed_structure.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 1 è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 1 è§£æã‚¨ãƒ©ãƒ¼: {str(e)}"

    def _gsr_layer2_inlanguage_reasoning(parsed_input: str, reasoning_context: str) -> str:
        """
        GSR Layer 2: In-Language Reasoning Architecture
        è‡ªç„¶è¨€èªå†…ã§ã®ç›´æ¥çš„æ¨è«–ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ãªã—ï¼‰
        """
        try:
            # è‡ªç„¶è¨€èªã§ã®ç›´æ¥æ¨è«–
            reasoning_result = f"""
ã€GSR Layer 2: è¨€èªå†…æ¨è«–ã€‘

ã€æ¨è«–ææ–™ã€‘
{parsed_input}

ã€æ¨è«–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘
{reasoning_context}

ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã€‘
1. å•é¡Œã®æ ¸å¿ƒç‰¹å®š
   - çœŸã®èª²é¡Œã¯ä½•ã‹ï¼Ÿ
   - è¡¨é¢çš„å•é¡Œã¨æ ¹æœ¬åŸå› ã®åŒºåˆ¥

2. åˆ¶ç´„åˆ†æ
   - çµ¶å¯¾çš„åˆ¶ç´„ï¼ˆå¤‰æ›´ä¸å¯ï¼‰
   - ç›¸å¯¾çš„åˆ¶ç´„ï¼ˆäº¤æ¸‰å¯èƒ½ï¼‰
   - éš ã‚ŒãŸåˆ¶ç´„ï¼ˆæš—é»™çš„å‰æï¼‰

3. è§£æ±ºç­–ç”Ÿæˆ
   - ç›´æ¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
   - ä»£æ›¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
   - å‰µé€ çš„è§£æ±ºæ³•

4. ãƒªã‚¹ã‚¯è©•ä¾¡
   - å®Ÿè¡Œå¯èƒ½æ€§
   - å®‰å…¨æ€§
   - å½±éŸ¿ç¯„å›²

ã€æ¨è«–çµè«–ã€‘
åŸºæœ¬åˆ¤å®š: [PROCEED/CAUTION/REJECT]
ä¿¡é ¼åº¦: [HIGH/MEDIUM/LOW]
            """
            return reasoning_result.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 2 æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 2 æ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def _gsr_layer3_execution_explainability(reasoning_result: str, action_context: str) -> str:
        """
        GSR Layer 3: Execution & Explainability
        å®Ÿè¡Œå¯èƒ½æ€§ã¨èª¬æ˜å¯èƒ½æ€§ã®çµ±åˆ
        """
        try:
            execution_plan = f"""
ã€GSR Layer 3: å®Ÿè¡Œãƒ»èª¬æ˜å¯èƒ½æ€§ã€‘

ã€æ¨è«–çµæœè©•ä¾¡ã€‘
{reasoning_result}

ã€å®Ÿè¡Œè¨ˆç”»ã€‘
1. å®Ÿè¡Œå‰æ¤œè¨¼
   - åˆ¶ç´„é©åˆæ€§ãƒã‚§ãƒƒã‚¯
   - å®‰å…¨æ€§ç¢ºèª
   - ãƒªã‚½ãƒ¼ã‚¹å¯ç”¨æ€§

2. æ®µéšçš„å®Ÿè¡Œæˆ¦ç•¥
   - Phase 1: æœ€å°é™å¤‰æ›´
   - Phase 2: æ®µéšçš„æ‹¡å¼µ
   - Phase 3: å®Œå…¨å®Ÿè£…

3. æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ
   - å„æ®µéšã§ã®æˆåŠŸåˆ¤å®šåŸºæº–
   - ç•°å¸¸æ¤œå‡ºã¨å›å¾©æ‰‹é †
   - å“è³ªä¿è¨¼è¦ä»¶

ã€èª¬æ˜å¯èƒ½æ€§ã€‘
- ãªãœã“ã®åˆ¤æ–­ã«è‡³ã£ãŸã‹
- ã©ã®ã‚ˆã†ãªæ ¹æ‹ ãŒã‚ã‚‹ã‹
- ä»£æ›¿æ¡ˆã¨ã®æ¯”è¼ƒçµæœ
- ãƒªã‚¹ã‚¯ã¨æ©Ÿä¼šã®è©•ä¾¡

ã€å®Ÿè¡Œæº–å‚™å®Œäº†ã€‘æ¬¡å±¤ã§ã®æœ€çµ‚ç¢ºèªã¸
            """
            return execution_plan.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 3 å®Ÿè¡Œè¨ˆç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 3 å®Ÿè¡Œè¨ˆç”»ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def _gsr_layer4_avoid_translation(execution_plan: str) -> str:
        """
        GSR Layer 4: Avoiding Representational Translation
        è¡¨ç¾å¤‰æ›ã®å›é¿ãƒ»è‡ªç„¶è¨€èªå‡ºåŠ›ã®ç¶­æŒ
        """
        try:
            # è‡ªç„¶è¨€èªã§ã®æœ€çµ‚å‡ºåŠ›ï¼ˆå¤‰æ›ãªã—ï¼‰
            final_output = f"""
ã€GSR Layer 4: è‡ªç„¶è¨€èªå‡ºåŠ›ã€‘

ã€çµ±åˆæ¨è«–çµæœã€‘
{execution_plan}

ã€æœ€çµ‚åˆ¤å®šã€‘
âœ… PROCEED - å®Ÿè¡Œæ¨å¥¨
âš ï¸ CAUTION - æ³¨æ„ã—ã¦å®Ÿè¡Œ
âŒ REJECT - å®Ÿè¡Œéæ¨å¥¨

ã€å®Ÿè¡ŒæŒ‡é‡ã€‘
å…·ä½“çš„ã«ä½•ã‚’ã™ã¹ãã‹ã€ã©ã®ã‚ˆã†ãªé †åºã§ã€ã©ã®ã‚ˆã†ãªæ³¨æ„ç‚¹ãŒã‚ã‚‹ã‹ã‚’è‡ªç„¶è¨€èªã§æ˜ç¢ºã«èª¬æ˜

ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå–ã‚‹ã¹ãå…·ä½“çš„è¡Œå‹•ã‚’è‡ªç„¶è¨€èªã§æç¤º

ã€ä¿¡é ¼æ€§æŒ‡æ¨™ã€‘
æ¨è«–ã®ç¢ºå®Ÿæ€§ãƒ¬ãƒ™ãƒ«ã¨æ ¹æ‹ ã‚’è‡ªç„¶è¨€èªã§èª¬æ˜
            """
            return final_output.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 4 å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 4 å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}"

    # ================== çµ±åˆGSRæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ ==================

    @app.tool()
    async def unified_gsr_reasoning(
        user_request: str,
        context_information: str = "",
        reasoning_depth: str = "standard",
        ctx = None
    ) -> str:
        """
        çµ±åˆGSRæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ - CoreThinkè«–æ–‡ã®GSR 4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å®Ÿè£…
        
        Args:
            user_request: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ãƒ»è³ªå•ï¼ˆè‡ªç„¶è¨€èªï¼‰
            context_information: æ–‡è„ˆæƒ…å ±ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã€åˆ¶ç´„ç­‰ï¼‰
            reasoning_depth: æ¨è«–æ·±åº¦ï¼ˆminimal, standard, detailedï¼‰
            ctx: FastMCP context
            
        Returns:
            GSR 4å±¤å‡¦ç†ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªæ¨è«–çµæœ
        """
        start_time = datetime.now()
        logger.info(f"çµ±åˆGSRæ¨è«–é–‹å§‹: {user_request[:100]}...")
        
        try:
            # åˆ†é‡ç‰¹åŒ–åˆ¶ç´„æƒ…å ±ã®èª­ã¿è¾¼ã¿
            constraints = load_domain_constraints(user_request)
            full_context = f"{context_information}\n\nã€åˆ¶ç´„æƒ…å ±ã€‘\n{constraints}"
            
            # GSR 4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚‹æ¨è«–
            layer1_result = _gsr_layer1_parse_native_language(user_request, full_context)
            layer2_result = _gsr_layer2_inlanguage_reasoning(layer1_result, full_context)
            layer3_result = _gsr_layer3_execution_explainability(layer2_result, full_context)
            layer4_result = _gsr_layer4_avoid_translation(layer3_result)
            
            # çµ±åˆçµæœã®ç”Ÿæˆ
            unified_result = f"""
ğŸ§  **CoreThinkçµ±åˆGSRæ¨è«–çµæœ**

ã€è¦æ±‚åˆ†æã€‘
{user_request}

ã€GSRæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã€‘
Layer 1 â†’ Layer 2 â†’ Layer 3 â†’ Layer 4

{layer4_result}

ã€æ¨è«–å®Œäº†æ™‚åˆ»ã€‘
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ã€æ¨è«–æ‰€è¦æ™‚é–“ã€‘
{(datetime.now() - start_time).total_seconds():.2f}ç§’
            """
            
            # ãƒ­ã‚°è¨˜éŒ²
            if is_history_enabled():
                await _log_tool_execution(
                    "unified_gsr_reasoning",
                    {"user_request": user_request, "context": context_information, "depth": reasoning_depth},
                    unified_result,
                    datetime.now(),
                    start_time
                )
            
            logger.info(f"çµ±åˆGSRæ¨è«–å®Œäº†: {(datetime.now() - start_time).total_seconds():.2f}ç§’")
            return unified_result.strip()
            
        except Exception as e:
            error_msg = f"çµ±åˆGSRæ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def collect_reasoning_materials(
        topic: str,
        information_types: str = "",
        search_depth: str = "moderate",
        ctx = None
    ) -> str:
        """
        æ¨è«–ææ–™åé›†ãƒ„ãƒ¼ãƒ« - Samplingæ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸè¨¼æ‹ åé›†
        
        Args:
            topic: èª¿æŸ»å¯¾è±¡ãƒˆãƒ”ãƒƒã‚¯
            information_types: åé›†ã™ã‚‹æƒ…å ±ç¨®åˆ¥ï¼ˆæŠ€è¡“æƒ…å ±ã€åˆ¶ç´„ã€äº‹ä¾‹ç­‰ï¼‰
            search_depth: èª¿æŸ»æ·±åº¦ï¼ˆshallow, moderate, deepï¼‰
            ctx: FastMCP contextï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
            
        Returns:
            åé›†ã—ãŸæ¨è«–ææ–™ï¼ˆè‡ªç„¶è¨€èªå½¢å¼ï¼‰
        """
        start_time = datetime.now()
        logger.info(f"æ¨è«–ææ–™åé›†é–‹å§‹: {topic}")
        
        try:
            # åŸºæœ¬æƒ…å ±åé›†
            base_materials = f"""
ã€æ¨è«–ææ–™åé›†çµæœã€‘

ã€èª¿æŸ»å¯¾è±¡ã€‘
{topic}

ã€åé›†æƒ…å ±ç¨®åˆ¥ã€‘
{information_types if information_types else "ä¸€èˆ¬çš„æŠ€è¡“æƒ…å ±ã€åˆ¶ç´„ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹"}

ã€åˆ¶ç´„æƒ…å ±ã€‘
{load_constraints()}

ã€åé›†å®Œäº†ã€‘
æ¨è«–ã«å¿…è¦ãªåŸºæœ¬ææ–™ã‚’åé›†ã—ã¾ã—ãŸ
            """
            
            # Samplingæ©Ÿèƒ½ã«ã‚ˆã‚‹æ‹¡å¼µï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            enhanced_materials = base_materials
            if is_sampling_enabled() and ctx and hasattr(ctx, 'mcp'):
                try:
                    # Samplingè¦æ±‚ã®æ§‹ç¯‰
                    sampling_prompt = f"""
{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

1. æŠ€è¡“çš„è©³ç´°ã¨å®Ÿè£…è€ƒæ…®äº‹é …
2. æ½œåœ¨çš„ãƒªã‚¹ã‚¯ã¨åˆ¶ç´„
3. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨æ¨å¥¨äº‹é …
4. é¡ä¼¼äº‹ä¾‹ã¨å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ

æƒ…å ±ç¨®åˆ¥: {information_types}
èª¿æŸ»æ·±åº¦: {search_depth}

ç°¡æ½”ã§å®Ÿç”¨çš„ãªæƒ…å ±ã‚’è‡ªç„¶è¨€èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    timeout = get_sampling_timeout()
                    sampling_result = await asyncio.wait_for(
                        ctx.mcp.sample_llm_complete(sampling_prompt),
                        timeout=timeout
                    )
                    
                    enhanced_materials = f"""
{base_materials}

ã€æ‹¡å¼µæƒ…å ±ã€‘
{sampling_result}

ã€æƒ…å ±çµ±åˆå®Œäº†ã€‘
åŸºæœ¬ææ–™ã¨æ‹¡å¼µæƒ…å ±ã‚’çµ±åˆã—ã€æ¨è«–ã«æ´»ç”¨å¯èƒ½ãªå½¢ã§æ•´ç†ã—ã¾ã—ãŸ
                    """
                    
                except asyncio.TimeoutError:
                    logger.warning("Sampling ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ - åŸºæœ¬ææ–™ã®ã¿ä½¿ç”¨")
                except Exception as e:
                    logger.warning(f"Sampling ã‚¨ãƒ©ãƒ¼: {e} - åŸºæœ¬ææ–™ã®ã¿ä½¿ç”¨")
            
            # ãƒ­ã‚°è¨˜éŒ²
            if is_history_enabled():
                await _log_tool_execution(
                    "collect_reasoning_materials",
                    {"topic": topic, "information_types": information_types, "search_depth": search_depth},
                    enhanced_materials,
                    datetime.now(),
                    start_time
                )
            
            logger.info(f"æ¨è«–ææ–™åé›†å®Œäº†: {(datetime.now() - start_time).total_seconds():.2f}ç§’")
            return enhanced_materials.strip()
            
        except Exception as e:
            error_msg = f"æ¨è«–ææ–™åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # ================== MCP Resources ==================

    @app.resource("file://constraints")
    async def read_constraints() -> str:
        """åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Šï¼ˆMCP Resourceï¼‰"""
        return load_constraints()

    @app.resource("file://reasoning_log")
    async def read_reasoning_log() -> str:
        """æ¨è«–ãƒ­ã‚°ã‚’èª­ã¿å–ã‚Š"""
        log_path = Path("logs") / "trace.log"
        try:
            return log_path.read_text(encoding="utf-8") if log_path.exists() else "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        except Exception as e:
            return f"ãƒ­ã‚°èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {str(e)}"

# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
if __name__ == "__main__":
    if not app:
        print("FastMCP ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚MCPãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", file=sys.stderr)
        exit(1)
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º
    version_info = get_version_info()
    logger.info(f"CoreThink-MCP ã‚µãƒ¼ãƒãƒ¼ v{version_info['version']} ã‚’èµ·å‹•ä¸­...")
    logger.info(f"CoreThinkè«–æ–‡: {version_info['corethink_paper']}")
    logger.info(f"åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«: {CONSTRAINTS_FILE}")
    logger.info(f"ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆ: {REPO_ROOT}")
    logger.info(f"ä½¿ç”¨ãƒãƒ¼ãƒˆ: {AVAILABLE_PORT}")
    
    # ãƒãƒ¼ãƒˆå¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®è­¦å‘Š
    if AVAILABLE_PORT != PREFERRED_PORT:
        logger.warning(f"æ³¨æ„: å¸Œæœ›ãƒãƒ¼ãƒˆ {PREFERRED_PORT} ã¯ä½¿ç”¨ä¸­ã®ãŸã‚ã€ãƒãƒ¼ãƒˆ {AVAILABLE_PORT} ã‚’ä½¿ç”¨ã—ã¾ã™")
        logger.info(f"è¨­å®šã‚’æ›´æ–°ã™ã‚‹ã«ã¯ã€ç’°å¢ƒå¤‰æ•° CORETHINK_PORT={AVAILABLE_PORT} ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    
    # STDIOæ¥ç¶šã®èª¬æ˜
    logger.info("ğŸ“¡ STDIOæ¥ç¶šã‚’å¾…æ©Ÿä¸­...")
    logger.info("ğŸ’¡ ã“ã®ã‚µãƒ¼ãƒãƒ¼ã¯VS Codeã‚„Claude Desktopã‹ã‚‰ã®MCPæ¥ç¶šã‚’å—ã‘ä»˜ã‘ã¾ã™")
    logger.info("â¹ï¸  çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    
    # FastMCPã‚µãƒ¼ãƒãƒ¼ã‚’å®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
    try:
        logger.info("FastMCP STDIOã‚µãƒ¼ãƒãƒ¼ã‚’é–‹å§‹ã—ã¾ã™...")
        app.run()
    except (KeyboardInterrupt, asyncio.CancelledError):
        logger.info("âœ… ã‚µãƒ¼ãƒãƒ¼ãŒæ­£å¸¸ã«åœæ­¢ã•ã‚Œã¾ã—ãŸï¼ˆCtrl+Cï¼‰")
    except Exception as e:
        logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        exit(1)
    finally:
        logger.info("ğŸ CoreThink-MCP ã‚µãƒ¼ãƒãƒ¼ã‚’çµ‚äº†ã—ã¾ã™")
