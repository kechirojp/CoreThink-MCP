"""
CoreThink-MCP Server
Natural Language Reasoning MCP Server based on General Symbolics Reasoning (GSR)
"""

import logging
import os
import sys
import socket
import signal
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List
from dotenv import load_dotenv

# UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¼·åˆ¶è¨­å®š
os.environ['PYTHONIOENCODING'] = 'utf-8'
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
if hasattr(sys.stderr, 'reconfigure'):
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

# GitPython ã® importï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
try:
    import git
    GIT_AVAILABLE = True
except ImportError:
    GIT_AVAILABLE = False
    git = None

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—ã—ã¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ«ãƒ¼ãƒˆã‚’sys.pathã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.corethink_mcp import get_version_info
from src.corethink_mcp.feature_flags import feature_flags, is_sampling_enabled, get_sampling_timeout, is_history_enabled
from src.corethink_mcp.history_manager import log_tool_execution

# ãƒ­ã‚°è¨­å®šï¼ˆUTF-8å¯¾å¿œï¼‰
log_level = os.getenv("CORETHINK_LOG_LEVEL", "INFO")
logging.basicConfig(
    level=getattr(logging, log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(Path("logs") / "trace.log", encoding='utf-8'),
        logging.StreamHandler(sys.stderr)
    ],
    force=True  # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä¸Šæ›¸ã
)
logger = logging.getLogger(__name__)

# FastMCP ã® importï¼ˆãƒ­ã‚°è¨­å®šå¾Œï¼‰
try:
    from fastmcp import FastMCP
except ImportError:
    logger.error("FastMCP not available. Please install: pip install fastmcp")
    FastMCP = None

# FastMCPæœªå°å…¥æ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
if not FastMCP:
    logger.error("FastMCP not available. Please install: pip install fastmcp")

def find_available_port(preferred_port: int = 8080, max_attempts: int = 100) -> int:
    """
    åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆã‚’æ¤œç´¢ã™ã‚‹
    
    Args:
        preferred_port: å„ªå…ˆãƒãƒ¼ãƒˆç•ªå·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8080ï¼‰
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
    
    Returns:
        åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆç•ªå·
    """
    for port in range(preferred_port, preferred_port + max_attempts):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.bind(('localhost', port))
                if port != preferred_port:
                    logger.warning(f"ãƒãƒ¼ãƒˆ {preferred_port} ã¯ä½¿ç”¨ä¸­ã§ã™ã€‚ãƒãƒ¼ãƒˆ {port} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                else:
                    logger.info(f"ãƒãƒ¼ãƒˆ {port} ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
                return port
        except socket.error:
            continue
    
    # ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        sock.bind(('localhost', 0))
        port = sock.getsockname()[1]
        logger.warning(f"ãƒãƒ¼ãƒˆ {preferred_port}ï½{preferred_port + max_attempts} ã¯å…¨ã¦ä½¿ç”¨ä¸­ã§ã™ã€‚ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ¼ãƒˆ {port} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return port

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
REPO_ROOT = Path(os.getenv("CORETHINK_REPO_ROOT", "."))
CONSTRAINTS_DIR = Path(__file__).parent.parent / "constraints"
CONSTRAINTS_FILE = CONSTRAINTS_DIR / "constraints.txt"
CONSTRAINTS_CLOUD_DEVOPS_FILE = Path(__file__).parent.parent / "constraints_cloud_devops.txt"
SANDBOX_DIR = os.getenv("CORETHINK_SANDBOX_DIR", ".sandbox")

# ãƒãƒ¼ãƒˆè¨­å®šï¼ˆè‡ªå‹•æ¤œå‡ºï¼‰
PREFERRED_PORT = int(os.getenv("CORETHINK_PORT", "8080"))
AVAILABLE_PORT = find_available_port(PREFERRED_PORT)

# FastMCPã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
if FastMCP:
    version_info = get_version_info()
    app = FastMCP(
        name="corethink-mcp",
        version=version_info["version"]
    )
else:
    # ä»£æ›¿å®Ÿè£…
    app = None

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆèµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘èª­ã¿è¾¼ã¿ï¼‰
_DOMAIN_KEYWORDS_CACHE = {}

def _load_domain_keywords() -> dict[str, list[str]]:
    """å…¨åˆ†é‡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä¸€åº¦ã«èª­ã¿è¾¼ã‚“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    if _DOMAIN_KEYWORDS_CACHE:
        return _DOMAIN_KEYWORDS_CACHE
    
    # åˆ©ç”¨å¯èƒ½ãªåˆ†é‡ãƒªã‚¹ãƒˆ
    domains = ["medical", "legal", "financial", "engineering", "ai_ml", "cloud_devops", "safety_critical"]
    
    for domain in domains:
        try:
            constraints_dir = CONSTRAINTS_FILE.parent
            domain_file = constraints_dir / f"constraints_{domain}.txt"
            
            if domain_file.exists():
                constraints_content, keywords = parse_constraint_file(domain_file)
                if keywords:
                    _DOMAIN_KEYWORDS_CACHE[domain] = keywords
                    logger.debug(f"åˆ†é‡ {domain} ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ {len(keywords)}å€‹ã‚’èª­ã¿è¾¼ã¿")
                else:
                    logger.warning(f"åˆ†é‡ {domain} ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            else:
                logger.warning(f"åˆ†é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {domain_file}")
        except Exception as e:
            logger.error(f"åˆ†é‡ {domain} ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæœ€å°é™ï¼‰
    if not _DOMAIN_KEYWORDS_CACHE.get("medical"):
        _DOMAIN_KEYWORDS_CACHE["medical"] = ["è¨ºæ–­", "ç—‡çŠ¶", "æ²»ç™‚", "åŒ»ç™‚", "æ‚£è€…"]
    
    logger.info(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–å®Œäº†: {len(_DOMAIN_KEYWORDS_CACHE)} åˆ†é‡")
    return _DOMAIN_KEYWORDS_CACHE

def load_constraints() -> str:
    """åŸºæœ¬åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        return CONSTRAINTS_FILE.read_text(encoding="utf-8")
    except FileNotFoundError:
        logger.warning(f"åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {CONSTRAINTS_FILE}")
        return "åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ"

def parse_constraint_file(file_path: Path) -> tuple[str, list[str]]:
    """åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åˆ¶ç´„å†…å®¹ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ†é›¢ã—ã¦èª­ã¿è¾¼ã‚€
    
    Returns:
        tuple[str, list[str]]: (åˆ¶ç´„å†…å®¹, ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ)
    """
    try:
        content = file_path.read_text(encoding="utf-8")
        
        # KEYWORDSã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†é›¢
        if "## KEYWORDS" in content:
            parts = content.split("## KEYWORDS", 1)
            constraints_content = parts[0].strip()
            keywords_section = parts[1].strip()
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¡Œã‚’è§£æï¼ˆã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            keywords = []
            for line in keywords_section.split('\n'):
                line = line.strip()
                if line and not line.startswith('#'):
                    # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ†å‰²
                    keywords.extend([kw.strip() for kw in line.split(',') if kw.strip()])
            
            return constraints_content, keywords
        else:
            # KEYWORDSã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯åˆ¶ç´„ã®ã¿è¿”ã™
            return content, []
            
    except Exception as e:
        logger.error(f"åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
        return "", []

def load_domain_constraints(domain: str) -> str:
    """åˆ†é‡åˆ¥åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        constraints_dir = CONSTRAINTS_FILE.parent
        domain_file = constraints_dir / f"constraints_{domain}.txt"
        
        if domain_file.exists():
            return domain_file.read_text(encoding="utf-8")
        else:
            logger.warning(f"åˆ†é‡åˆ¥åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {domain_file}")
            return ""
    except Exception as e:
        logger.error(f"åˆ†é‡åˆ¥åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def load_combined_constraints(user_request: str = "") -> str:
    """åŸºæœ¬åˆ¶ç´„ã¨åˆ†é‡åˆ¥åˆ¶ç´„ã‚’çµ„ã¿åˆã‚ã›ã¦èª­ã¿è¾¼ã‚€"""
    # åŸºæœ¬åˆ¶ç´„ã‚’èª­ã¿è¾¼ã‚€
    base_constraints = load_constraints()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‹ã‚‰åˆ†é‡ã‚’æ¤œå‡º
    if user_request:
        domain = _detect_domain(user_request)
        if domain != "general":
            domain_constraints = load_domain_constraints(domain)
            if domain_constraints:
                combined = f"{base_constraints}\n\n## åˆ†é‡ç‰¹åŒ–åˆ¶ç´„ï¼ˆ{domain.upper()}ï¼‰\n{domain_constraints}"
                logger.info(f"åˆ†é‡åˆ¥åˆ¶ç´„ã‚’é©ç”¨: {domain}")
                return combined
    
    return base_constraints

def _detect_domain(user_request: str) -> str:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‹ã‚‰é©ç”¨ã™ã¹ãåˆ†é‡ã‚’æ¤œå‡ºã™ã‚‹ï¼ˆå¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰"""
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿
    domain_keywords = _load_domain_keywords()
    
    domains = []
    user_request_lower = user_request.lower()
    
    # å„åˆ†é‡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒãƒƒãƒãƒ³ã‚°
    for domain, keywords in domain_keywords.items():
        if any(kw.lower() in user_request_lower for kw in keywords):
            domains.append(domain)
    
    # æœ€ã‚‚å„ªå…ˆåº¦ã®é«˜ã„åˆ†é‡ã‚’è¿”ã™ï¼ˆè¤‡æ•°æ¤œå‡ºã•ã‚ŒãŸå ´åˆã®å„ªå…ˆé †ä½ï¼‰
    priority_order = ["safety_critical", "medical", "legal", "financial", "ai_ml", "engineering", "cloud_devops"]
    
    for priority_domain in priority_order:
        if priority_domain in domains:
            logger.debug(f"åˆ†é‡æ¤œå‡º: {priority_domain} (å€™è£œ: {domains})")
            return priority_domain
    
    logger.debug(f"æ±ç”¨åˆ†é‡ã¨ã—ã¦å‡¦ç†: '{user_request[:50]}...'")
    return "general"

def create_sandbox() -> str:
    """å®‰å…¨ãªä½œæ¥­ç’°å¢ƒï¼ˆã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ï¼‰ã‚’ä½œæˆ"""
    if not GIT_AVAILABLE:
        error_msg = "GitPython not available. Please install: pip install GitPython"
        logger.error(error_msg)
        return f"ã‚¨ãƒ©ãƒ¼: {error_msg}"
    
    try:
        repo = git.Repo(REPO_ROOT)
        sandbox_path = Path(REPO_ROOT) / SANDBOX_DIR
        
        # æ—¢å­˜ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã®ç¢ºèªã¨å‰Šé™¤
        if sandbox_path.exists():
            try:
                repo.git.worktree("remove", str(sandbox_path), "--force")
                logger.info(f"æ—¢å­˜ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {sandbox_path}")
            except git.GitCommandError:
                logger.warning("æ—¢å­˜ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ç¶šè¡Œã—ã¾ã™")
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ–ãƒ©ãƒ³ãƒåã§æ–°ã—ã„ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        branch_name = f"corethink-sbx-{timestamp}"
        
        try:
            repo.git.worktree("add", "-b", branch_name, str(sandbox_path), "HEAD")
            logger.info(f"ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ: {sandbox_path} (ãƒ–ãƒ©ãƒ³ãƒ: {branch_name})")
        except git.GitCommandError as e:
            if "Permission denied" in str(e):
                # Windowsæ¨©é™å•é¡Œã®å ´åˆã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚³ãƒ”ãƒ¼ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                import shutil
                shutil.copytree(REPO_ROOT, sandbox_path, ignore=shutil.ignore_patterns('.git', '__pycache__', '*.pyc'))
                logger.warning(f"Git worktreeãŒå¤±æ•—ã—ãŸãŸã‚ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚³ãƒ”ãƒ¼ã§ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ: {sandbox_path}")
            else:
                raise
        
        return str(sandbox_path)
    except git.InvalidGitRepositoryError:
        error_msg = f"Invalid git repository: {REPO_ROOT}"
        logger.error(error_msg)
        return f"ã‚¨ãƒ©ãƒ¼: {error_msg}"
    except git.GitCommandError as e:
        error_msg = f"Git command failed: {str(e)}"
        logger.error(error_msg)
        return f"ã‚¨ãƒ©ãƒ¼: {error_msg}"
    except Exception as e:
        logger.error(f"ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return f"ã‚¨ãƒ©ãƒ¼: {str(e)}"

# ================== MCP Tools ==================

if app:
    async def _enhance_with_sampling(core_result: str, tool_name: str, ctx=None) -> str:
        """Samplingæ©Ÿèƒ½ã«ã‚ˆã‚‹çµæœæ‹¡å¼µ
        
        Args:
            core_result: CoreThinkæ¨è«–ã®çµæœ
            tool_name: ãƒ„ãƒ¼ãƒ«å  
            ctx: FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
            
        Returns:
            æ‹¡å¼µã•ã‚ŒãŸçµæœï¼ˆå¤±æ•—æ™‚ã¯å…ƒã®çµæœï¼‰
        """
        if not is_sampling_enabled():
            return core_result
        
        if not ctx or not hasattr(ctx, 'sample'):
            return core_result
        
        try:
            timeout = get_sampling_timeout()
            
            # Sampling ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
            sampling_query = f"""
CoreThinkæ¨è«–çµæœã‚’è¸ã¾ãˆãŸè¿½åŠ è€ƒæ…®ç‚¹ã‚„ä»£æ›¿æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š

ã€{tool_name}çµæœã€‘
{core_result}

ã€è¦æ±‚ã€‘
- è¦‹è½ã¨ã•ã‚ŒãŸè¦³ç‚¹ãŒã‚ã‚Œã°æŒ‡æ‘˜
- ã‚ˆã‚Šè‰¯ã„ä»£æ›¿æ¡ˆãŒã‚ã‚Œã°ææ¡ˆ  
- ãƒªã‚¹ã‚¯ã‚„æ³¨æ„ç‚¹ãŒã‚ã‚Œã°è­¦å‘Š
- ç°¡æ½”ã«3-5å€‹ã®è¦ç‚¹ã§å›ç­”
"""
            
            # Samplingå®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
            sampling_result = await asyncio.wait_for(
                ctx.sample(sampling_query),
                timeout=timeout
            )
            
            # çµæœã®çµ±åˆ
            enhanced_result = f"""{core_result}

ã€ğŸ’¡ Samplingè£œåŠ©åˆ†æã€‘
{sampling_result}

ã€ğŸ¯ æœ€çµ‚åˆ¤æ–­ã€‘
ä¸Šè¨˜ã®CoreThinkæ¨è«–çµæœã‚’åŸºæœ¬ã¨ã—ã€è£œåŠ©åˆ†æã‚’å‚è€ƒæƒ…å ±ã¨ã—ã¦æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚"""
            
            logger.info(f"Samplingæ‹¡å¼µå®Œäº†: {tool_name}")
            return enhanced_result
            
        except asyncio.TimeoutError:
            logger.warning(f"Sampling timeout for {tool_name}")
            return core_result
        except Exception as e:
            logger.warning(f"Sampling enhancement failed for {tool_name}: {e}")
            return core_result
    
    async def _log_tool_execution(tool_name: str, inputs: dict, core_result: str, 
                                  enhanced_result: str = None, sampling_result: str = None,
                                  execution_time_ms: float = None, error: str = None) -> None:
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’å±¥æ­´ã«è¨˜éŒ²"""
        try:
            log_tool_execution(
                tool_name=tool_name,
                inputs=inputs,
                result=enhanced_result or core_result,
                sampling_result=sampling_result,
                execution_time_ms=execution_time_ms,
                error=error
            )
        except Exception as e:
            logger.warning(f"Failed to log tool execution: {e}")
    
    # @app.tool()  # Phase3çµ±åˆã«ã‚ˆã‚Šå»ƒæ­¢: unified_gsr_reasoning ã«çµ±åˆæ¸ˆã¿
    async def reason_about_change(
        user_intent: str,
        current_state: str,
        proposed_action: str,
        ctx = None  # FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
    ) -> str:
        """
        Performs General Symbolics Reasoning (GSR) to evaluate proposed changes.
        Analyzes constraints, contradictions, and risks using natural language reasoning.
        
        Args:
            user_intent: The user's intention or goal
            current_state: Current system state description
            proposed_action: The proposed change or action
            ctx: FastMCP context (includes sampling capability)
            
        Returns:
            Natural language reasoning result with judgment and next steps
        """
        start_time = datetime.now()
        logger.info(f"æ¨è«–é–‹å§‹: {user_intent}")
        
        # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        inputs = {
            'user_intent': user_intent,
            'current_state': current_state, 
            'proposed_action': proposed_action
        }
        
        try:
            constraints = load_constraints()
            
            # GSRã‚¹ã‚¿ã‚¤ãƒ«ã®æ¨è«–éç¨‹ï¼ˆå¾“æ¥é€šã‚Šï¼‰
            core_reasoning = f"""
ã€CoreThinkæ¨è«–é–‹å§‹ã€‘
æ„å›³: {user_intent}
ç¾çŠ¶: {current_state}
ææ¡ˆ: {proposed_action}

ã€åˆ¶ç´„ç¢ºèªã€‘
{constraints}

ã€åˆ†æéç¨‹ã€‘
1. æ„å›³ã®æ˜ç¢ºæ€§ãƒã‚§ãƒƒã‚¯: {"æ˜ç¢º" if user_intent.strip() else "ä¸æ˜ç¢º"}
2. åˆ¶ç´„é©åˆæ€§è©•ä¾¡:
   - å…¬é–‹APIå¤‰æ›´: æ¤œè¨¼ä¸­...
   - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›: æ¤œè¨¼ä¸­...
   - ãƒ†ã‚¹ãƒˆå½±éŸ¿: æ¤œè¨¼ä¸­...

ã€æš«å®šåˆ¤å®šã€‘PROCEED_WITH_CAUTION
ã€ç†ç”±ã€‘è©³ç´°ãªåˆ¶ç´„æ¤œè¨¼ãŒå¿…è¦
ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘validate_against_constraints ã§ã®è©³ç´°æ¤œè¨¼
            """.strip()
            
            # Samplingæ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            enhanced_result = await _enhance_with_sampling(core_reasoning, "reason_about_change", ctx)
            
            # å®Ÿè¡Œæ™‚é–“è¨ˆç®—
            execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
            
            # å±¥æ­´è¨˜éŒ²
            await _log_tool_execution(
                "reason_about_change", inputs, core_reasoning, 
                enhanced_result, None, execution_time_ms
            )
            
            logger.info("æ¨è«–å®Œäº†")
            return enhanced_result
            
        except Exception as e:
            error_msg = f"æ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            
            # ã‚¨ãƒ©ãƒ¼ã‚‚å±¥æ­´ã«è¨˜éŒ²
            await _log_tool_execution(
                "reason_about_change", inputs, "", 
                error=error_msg
            )
            
            return error_msg

    @app.tool()
    async def validate_against_constraints(
        proposed_change: str,
        reasoning_context: str = "",
        ctx = None  # FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
    ) -> str:
        """
        Validates proposed changes against defined constraints using natural language.
        Checks compliance with safety, security, and operational constraints.
        
        Args:
            proposed_change: Description of the proposed change
            reasoning_context: Additional context for validation
            ctx: FastMCP context (includes sampling capability)
            
        Returns:
            Natural language validation result with compliance status
        """
        logger.info("åˆ¶ç´„æ¤œè¨¼é–‹å§‹")
        
        try:
            # åˆ†é‡åˆ¥åˆ¶ç´„ã‚’å«ã‚€åˆ¶ç´„ã‚’èª­ã¿è¾¼ã¿
            constraints = load_combined_constraints(proposed_change + " " + reasoning_context)
            
            # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆåˆ†é‡åˆ¥åˆ¶ç´„å¯¾å¿œç‰ˆï¼‰
            core_validation = f"""
ã€åˆ¶ç´„æ¤œè¨¼çµæœã€‘
ææ¡ˆå¤‰æ›´: {proposed_change}
æ–‡è„ˆ: {reasoning_context}

ã€é©ç”¨åˆ¶ç´„ã‚»ãƒƒãƒˆã€‘
{constraints[:300]}...

ã€è©³ç´°ãƒã‚§ãƒƒã‚¯ã€‘
âœ… MUSTã€Œå…¬é–‹APIå¤‰æ›´ç¦æ­¢ã€ â†’ é©åˆç¢ºèªä¸­
âœ… NEVERã€Œãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç¦æ­¢ã€ â†’ é©åˆç¢ºèªä¸­
âš ï¸ SHOULDã€Œdocstringæ›´æ–°æ¨å¥¨ã€ â†’ è¦ç¢ºèª
âœ… MUSTã€Œãƒ†ã‚¹ãƒˆé€šéã€ â†’ æ¤œè¨¼å¿…è¦

ã€ç·åˆåˆ¤å®šã€‘PROCEED_WITH_WARNING
ã€æ¨å¥¨ã€‘è¿½åŠ ã®docstringæ›´æ–°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„
ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘execute_with_safeguards ã§dry-runå®Ÿè¡Œ
            """.strip()
            
            # Samplingæ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            enhanced_result = await _enhance_with_sampling(core_validation, "validate_against_constraints", ctx)
            
            logger.info("åˆ¶ç´„æ¤œè¨¼å®Œäº†")
            return enhanced_result
            
        except Exception as e:
            error_msg = f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def execute_with_safeguards(
        action_description: str,
        dry_run: bool = True,
        ctx = None  # FastMCPã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆSamplingæ©Ÿèƒ½å«ã‚€ï¼‰
    ) -> str:
        """
        Executes changes with comprehensive safety measures and sandbox isolation.
        Implements git worktree-based sandboxing for safe code modifications.
        
        Args:
            action_description: Description of the action to execute
            dry_run: If True, performs simulation only; if False, applies changes
            ctx: FastMCP context (includes sampling capability)
            
        Returns:
            Natural language execution result with safety status and impact assessment
        """
        logger.info(f"å®Ÿè¡Œé–‹å§‹ (dry_run={dry_run}): {action_description}")
        
        try:
            if dry_run:
                sandbox_path = create_sandbox()
                core_result = f"""
ã€DRY RUNå®Ÿè¡Œã€‘
ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action_description}
ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹: {sandbox_path}

ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã€‘
âœ… ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ä½œæˆæˆåŠŸ
âœ… å¤‰æ›´ã¯å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã«å½±éŸ¿ã—ã¾ã›ã‚“
âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æº–å‚™å®Œäº†

ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘å®Ÿéš›ã®å®Ÿè¡Œã¯ dry_run=False ã§è¡Œã£ã¦ãã ã•ã„
                """.strip()
            else:
                # å®Ÿéš›ã®å®Ÿè¡Œï¼ˆå°†æ¥çš„ã«å®Ÿè£…ï¼‰
                core_result = f"""
ã€å®Ÿè¡Œå®Œäº†ã€‘
ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action_description}
çŠ¶æ…‹: å®Ÿè£…ä¸­ï¼ˆç¾åœ¨ã¯dry-runã®ã¿å¯¾å¿œï¼‰
                """.strip()
            
            # Samplingæ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            enhanced_result = await _enhance_with_sampling(core_result, "execute_with_safeguards", ctx)
            
            logger.info("å®Ÿè¡Œå®Œäº†")
            return enhanced_result
            
        except Exception as e:
            error_msg = f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def trace_reasoning_steps(
        context: str,
        step_description: str,
        reasoning_depth: str = "standard"  # standard, detailed, minimal
    ) -> str:
        """
        Generates detailed GSR reasoning traces with transparency indicators.
        Implements verbatim reasoning trace requirements from Section 5.3.
        
        Args:
            context: The reasoning context or background information
            step_description: Description of the current reasoning step
            reasoning_depth: Level of detail (minimal, standard, detailed)
            
        Returns:
            Comprehensive reasoning trace with timestamp, transparency metrics, and verification indicators
        """
        logger.info(f"æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹é–‹å§‹: {step_description}")
        
        try:
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # æ¨è«–æ·±åº¦ã«ã‚ˆã‚‹è©³ç´°ãƒ¬ãƒ™ãƒ«èª¿æ•´
            depth_levels = {
                "minimal": "åŸºæœ¬æƒ…å ±ã®ã¿",
                "standard": "æ¨™æº–çš„ãªæ¨è«–éç¨‹",
                "detailed": "è©³ç´°ãªåˆ†æã¨æ¤œè¨¼"
            }
            
            trace_result = f"""
ã€GSRæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã€‘
ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}
æ¨è«–æ–‡è„ˆ: {context}
å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—: {step_description}
æ¨è«–æ·±åº¦: {reasoning_depth} ({depth_levels.get(reasoning_depth, "æ¨™æº–")})

ã€è¨€èªå†…æ¨è«–éç¨‹ã€‘
å‰ææ¡ä»¶ç¢ºèª: æ–‡è„ˆæƒ…å ±ã®å¦¥å½“æ€§ã¨å®Œå…¨æ€§ã‚’æ¤œè¨¼
åˆ¶ç´„é©ç”¨çµæœ: ç¾åœ¨ã®åˆ¶ç´„ãƒ«ãƒ¼ãƒ«ã«å¯¾ã™ã‚‹é©åˆæ€§è©•ä¾¡
ä¸­é–“çµè«–: å„æ®µéšã§ã®æš«å®šçš„åˆ¤æ–­ã¨æ ¹æ‹ 
çŸ›ç›¾æ¤œå‡º: è«–ç†çš„ä¸æ•´åˆã‚„ç«¶åˆã™ã‚‹è¦ä»¶ã®ç‰¹å®š
æ¬¡æ®µéšæ¨è«–: å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã®æ¨å®šã¨æº–å‚™

ã€é€æ˜æ€§æŒ‡æ¨™ã€‘
æ¨è«–æ·±åº¦: {reasoning_depth}
ç¢ºä¿¡åº¦: {"HIGH" if reasoning_depth == "detailed" else "MEDIUM" if reasoning_depth == "standard" else "LOW"}
æ¤œè¨¼å¯èƒ½æ€§: å…¨ã‚¹ãƒ†ãƒƒãƒ—äººé–“æ¤œè¨¼å¯èƒ½
ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«å®Œå…¨è¨˜éŒ²

ã€GSRåŸå‰‡é©åˆæ€§ã€‘
è‡ªç„¶è¨€èªä¿æŒ: âœ… æ¨è«–éç¨‹ã‚’è‡ªç„¶è¨€èªã§å®Œå…¨ä¿æŒ
æ–‡è„ˆä¿å­˜: âœ… æ„å‘³çš„æƒ…å ±ã®æå¤±ãªã—
é€æ˜æ€§: âœ… å…¨æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ãŒæ¤œæŸ»å¯èƒ½
            """.strip()
            
            logger.info("æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹å®Œäº†")
            return trace_result
            
        except Exception as e:
            error_msg = f"æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # @app.tool()  # Phase3çµ±åˆã«ã‚ˆã‚Šå»ƒæ­¢: unified_gsr_reasoning ã«çµ±åˆæ¸ˆã¿
    async def refine_understanding(
        ambiguous_request: str,
        context_clues: str = "",
        domain_hints: str = ""  # åŒ»ç™‚ã€æ³•å¾‹ç­‰ã®å°‚é–€åˆ†é‡æŒ‡å®š
    ) -> str:
        """
        Resolves semantic ambiguity in user requests through contextual analysis.
        **æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆè¨­è¨ˆ**: æƒ…å ±ä¸è¶³ã§ã‚‚æ¨è«–ã«ã‚ˆã‚‹è£œå®Œã§å¿…ãšåˆ†æå®Ÿè¡Œ
        
        Args:
            ambiguous_request: The potentially ambiguous user request
            context_clues: Available contextual information (æ¨è«–ã§è£œå®Œå¯èƒ½)
            domain_hints: Domain-specific hints (æ¨è«–ã§æ¨å®šå¯èƒ½)
            
        Returns:
            Refined understanding with reasoning-based completion and uncertainty indicators
        """
        logger.info(f"æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆæ›–æ˜§æ€§è§£æ¶ˆé–‹å§‹: {ambiguous_request}")
        
        try:
            # ========== PHASE 1: æ¨è«–ã«ã‚ˆã‚‹æƒ…å ±è£œå®Œï¼ˆCoreThinkå“²å­¦ï¼‰ ==========
            
            # åˆ©ç”¨å¯èƒ½æƒ…å ±ã®è©•ä¾¡
            available_info_quality = "é«˜" if (context_clues and domain_hints) else "ä¸­" if (context_clues or domain_hints) else "ä½"
            
            # æ¨è«–ã«ã‚ˆã‚‹æ–‡è„ˆè£œå®Œï¼ˆæƒ…å ±ä¸è¶³ã§ã‚‚å®Ÿè¡Œï¼‰
            if not context_clues:
                # è‡ªç„¶è¨€èªæ¨è«–ã§context_cluesã‚’è£œå®Œ
                inferred_context = f"""
ã€æ¨è«–ã«ã‚ˆã‚‹æ–‡è„ˆè£œå®Œã€‘
è¦æ±‚æ–‡: "{ambiguous_request}"ã‹ã‚‰ä»¥ä¸‹ã‚’æ¨å®š:
- ã‚·ã‚¹ãƒ†ãƒ é–¢é€£â†’ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€å®‰å®šæ€§ã€ä½¿ã„ã‚„ã™ã•ã®èª²é¡Œæ¨å®š
- æ”¹å–„/æœ€é©åŒ–â†’ç¾åœ¨ã®å•é¡Œã¨æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„æ–¹å‘ã‚’æ¨å®š
- æŠ€è¡“çš„æ–‡è„ˆâ†’å®Ÿè£…ã€è¨­å®šã€é‹ç”¨é¢ã§ã®èª²é¡Œã‚’æ¨å®š
æ¨å®šç¢ºä¿¡åº¦: ä¸­ï¼ˆå®Ÿéš›ã®æ–‡è„ˆæƒ…å ±ã«ã‚ˆã‚Šç²¾åº¦å‘ä¸Šå¯èƒ½ï¼‰
                """.strip()
                context_clues = inferred_context
                logger.info("æ¨è«–ã«ã‚ˆã‚‹æ–‡è„ˆè£œå®Œå®Ÿè¡Œ")
            
            # æ¨è«–ã«ã‚ˆã‚‹å°‚é–€åˆ†é‡æ¨å®šï¼ˆæƒ…å ±ä¸è¶³ã§ã‚‚å®Ÿè¡Œï¼‰
            if not domain_hints:
                # æ–‡è¨€ã‹ã‚‰å°‚é–€åˆ†é‡ã‚’æ¨è«–
                domain_keywords = {
                    "ã‚·ã‚¹ãƒ†ãƒ |ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹|ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹|API": "æŠ€è¡“",
                    "æ²»ç™‚|è¨ºæ–­|æ‚£è€…|åŒ»ç™‚": "åŒ»ç™‚",
                    "æ³•çš„|å¥‘ç´„|è¦åˆ¶|ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹": "æ³•å¾‹",
                    "æ•™è‚²|å­¦ç¿’|æŒ‡å°|ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ": "æ•™è‚²",
                    "ãƒ“ã‚¸ãƒã‚¹|å£²ä¸Š|é¡§å®¢|ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°": "ãƒ“ã‚¸ãƒã‚¹"
                }
                
                inferred_domain = "ä¸€èˆ¬"
                for pattern, domain in domain_keywords.items():
                    import re
                    if re.search(pattern, ambiguous_request):
                        inferred_domain = domain
                        break
                
                domain_hints = f"æ¨è«–æ¨å®š: {inferred_domain}ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã«ã‚ˆã‚‹ï¼‰"
                logger.info(f"æ¨è«–ã«ã‚ˆã‚‹å°‚é–€åˆ†é‡æ¨å®š: {inferred_domain}")
            
            # ========== PHASE 2: è‡ªç„¶è¨€èªæ¨è«–ã«ã‚ˆã‚‹æ›–æ˜§æ€§è§£æ¶ˆ ==========
            
            # åŸºæœ¬çš„ãªæ›–æ˜§æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
            ambiguity_indicators = [
                "æ”¹å–„", "æœ€é©åŒ–", "ä¿®æ­£", "æ›´æ–°", "å¤‰æ›´", "èª¿æ•´",
                "è‰¯ãã™ã‚‹", "ç›´ã™", "æ²»ã™", "è§£æ±º", "å‘ä¸Š"
            ]
            
            detected_ambiguities = []
            for indicator in ambiguity_indicators:
                if indicator in ambiguous_request:
                    detected_ambiguities.append(indicator)
            
            # å°‚é–€åˆ†é‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é©ç”¨
            domain_context = ""
            if "æŠ€è¡“" in domain_hints:
                domain_context = "\næŠ€è¡“çš„è¦³ç‚¹: å®Ÿç¾å¯èƒ½æ€§ã€ä¿å®ˆæ€§ã€æ€§èƒ½ã¸ã®å½±éŸ¿ã‚’é‡è¦–"
            elif "åŒ»ç™‚" in domain_hints:
                domain_context = "\nåŒ»ç™‚å®‰å…¨è¦³ç‚¹: æ‚£è€…å®‰å…¨ã€åŒ»ç™‚åŸºæº–ã€è¦åˆ¶é©åˆã‚’æœ€å„ªå…ˆ"
            elif "æ³•å¾‹" in domain_hints:
                domain_context = "\næ³•çš„è¦³ç‚¹: æ³•çš„æ ¹æ‹ ã€é©æ­£æ‰‹ç¶šãã€ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’é‡è¦–"
            elif "ãƒ“ã‚¸ãƒã‚¹" in domain_hints:
                domain_context = "\nãƒ“ã‚¸ãƒã‚¹è¦³ç‚¹: ROIã€é¡§å®¢å½±éŸ¿ã€é‹ç”¨åŠ¹ç‡ã‚’è€ƒæ…®"
            else:
                domain_context = "\nä¸€èˆ¬çš„è¦³ç‚¹: å®‰å…¨æ€§ã€å®Ÿç”¨æ€§ã€æŒç¶šå¯èƒ½æ€§ã‚’è€ƒæ…®"
            
            # ========== PHASE 3: æ¨è«–çµæœã®æ§‹é€ åŒ–ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰ ==========
            
            # ä¸ç¢ºå®Ÿæ€§ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
            uncertainty_level = "ä½" if available_info_quality == "é«˜" else "ä¸­" if available_info_quality == "ä¸­" else "é«˜"
            
            refinement_result = f"""
ã€æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆæ›–æ˜§æ€§è§£æ¶ˆåˆ†æã€‘CoreThinkå“²å­¦æº–æ‹ 

åŸæ–‡: "{ambiguous_request}"
åˆ©ç”¨å¯èƒ½æƒ…å ±å“è³ª: {available_info_quality}
æ¨è«–è£œå®Œå®Ÿè¡Œ: âœ… æƒ…å ±ä¸è¶³ç®‡æ‰€ã‚’æ¨è«–ã§è£œå®Œ
æ–‡è„ˆæ‰‹ãŒã‹ã‚Š: {context_clues}{domain_context}

ã€æ¨è«–ã«ã‚ˆã‚‹èªç¾©è§£æã€‘
1. å¤šç¾©èªæ¤œå‡º: {detected_ambiguities if detected_ambiguities else "æ˜ç¢ºãªè¡¨ç¾"}
2. æ–‡è„ˆæ¨è«–: {"ç›´æ¥æƒ…å ±æ´»ç”¨" if available_info_quality == "é«˜" else "æ¨è«–è£œå®Œã«ã‚ˆã‚Šå®Ÿè¡Œ"}
3. å°‚é–€åˆ†é‡é©ç”¨: {domain_hints}

ã€æ¨è«–å“è³ªæŒ‡æ¨™ã€‘
æƒ…å ±å®Œæˆåº¦: {available_info_quality}
æ¨è«–ç¢ºä¿¡åº¦: {"é«˜" if available_info_quality == "é«˜" else "ä¸­" if available_info_quality == "ä¸­" else "ä½ï¼ˆæ¨è«–ä¸»ä½“ï¼‰"}
ä¸ç¢ºå®Ÿæ€§ãƒ¬ãƒ™ãƒ«: {uncertainty_level}
å®Ÿè¡Œå¯èƒ½æ€§: âœ… å¸¸æ™‚å®Ÿè¡Œå¯èƒ½ï¼ˆCoreThinkæ¨è«–ã«ã‚ˆã‚Šï¼‰

ã€ç²¾ç·»åŒ–ã•ã‚ŒãŸç†è§£ã€‘
æ˜ç¢ºåŒ–ãƒ¬ãƒ™ãƒ«: {"æœ€é«˜" if available_info_quality == "é«˜" else "é«˜" if available_info_quality == "ä¸­" else "ä¸­ï¼ˆæ¨è«–ãƒ™ãƒ¼ã‚¹ï¼‰"}
å®Ÿè¡Œæº–å‚™åº¦: âœ… æ¨è«–çµæœã«ã‚ˆã‚Šå®Ÿè¡Œå¯èƒ½
æ¨å¥¨æ¬¡ã‚¹ãƒ†ãƒƒãƒ—: reason_about_change ã§æ¨è«–ç¶™ç¶š

ã€CoreThinkå“²å­¦é©åˆæ€§ã€‘
æ¨è«–ç¶™ç¶š: âœ… æƒ…å ±ä¸è¶³ã§ã‚‚æ¨è«–ã§åˆ†æå®Ÿè¡Œ
ä¸ç¢ºå®Ÿæ€§ç®¡ç†: âœ… æ¨è«–ã®é™ç•Œã‚’æ˜ç¢ºåŒ–
å®Ÿç”¨æ€§ç¢ºä¿: âœ… å¸¸ã«å®Ÿè¡Œå¯èƒ½ãªçµæœæä¾›
è‡ªç„¶è¨€èªä¿æŒ: âœ… æ¨è«–éç¨‹ã‚’è‡ªç„¶è¨€èªã§å®Œå…¨ä¿æŒ

ã€Elicitationè£œå®Œæ©Ÿä¼šã€‘
è¿½åŠ æƒ…å ±åé›†ã«ã‚ˆã‚Šä»¥ä¸‹ãŒå‘ä¸Šå¯èƒ½:
- æ–‡è„ˆç²¾åº¦: {"å‘ä¸Šä¸è¦" if context_clues and "æ¨è«–" not in context_clues else "å®Ÿéš›ã®çŠ¶æ³è©³ç´°ã§å‘ä¸Š"}
- å°‚é–€æ€§: {"å‘ä¸Šä¸è¦" if domain_hints and "æ¨è«–" not in domain_hints else "å°‚é–€åˆ†é‡ç¢ºå®šã§å‘ä¸Š"}
- ç¢ºä¿¡åº¦: {uncertainty_level} â†’ ä½ (è¿½åŠ æƒ…å ±ã«ã‚ˆã‚Šæ”¹å–„)
            """.strip()
            
            logger.info(f"æ¨è«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆæ›–æ˜§æ€§è§£æ¶ˆå®Œäº†ï¼ˆç¢ºä¿¡åº¦: {uncertainty_level}ï¼‰")
            return refinement_result
            
        except Exception as e:
            error_msg = f"æ›–æ˜§æ€§è§£æ¶ˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # @app.tool()  # Phase3: çµ±åˆã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    async def detect_symbolic_patterns(
        input_data: str,
        pattern_domain: str,  # visual, logical, linguistic, code
        abstraction_level: str = "medium"  # low, medium, high
    ) -> str:
        """
        Detects symbolic patterns using ARC-AGI-2 Stage 2 atomic operations.
        Implements 23 atomic transformation operations from Section 6.3 & Appendix B.
        
        Args:
            input_data: The data to analyze for patterns
            pattern_domain: Domain of analysis (visual, logical, linguistic, code)
            abstraction_level: Level of abstraction (low, medium, high)
            
        Returns:
            Comprehensive pattern analysis with ARC-AGI-2 atomic operations and neuro-symbolic integration
        """
        logger.info(f"ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: é ˜åŸŸ={pattern_domain}, æŠ½è±¡åŒ–={abstraction_level}")
        
        try:
            # ARC-AGI-2ã®23ç¨®é¡ã®åŸå­æ“ä½œå®šç¾©
            atomic_operations = {
                "spatial": ["translate", "rotate", "reflect", "scale", "shift"],
                "structural": ["cavity_fill", "object_merge", "boundary_extend", "pattern_complete"],
                "logical": ["conditional_apply", "pattern_repeat", "rule_induction", "symmetry_apply"],
                "transformation": ["color_change", "shape_morph", "size_adjust", "orientation_change"],
                "composition": ["layer_combine", "fragment_assemble", "template_apply"],
                "detection": ["anomaly_identify", "pattern_match", "sequence_predict"]
            }
            
            # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬åˆ†æ
            data_analysis = f"ãƒ‡ãƒ¼ã‚¿é•·: {len(input_data)}, å‹: {type(input_data).__name__}"
            
            pattern_result = f"""
ã€ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã€‘

å…¥åŠ›ãƒ‡ãƒ¼ã‚¿åˆ†æ: {data_analysis}
å¯¾è±¡é ˜åŸŸ: {pattern_domain}
æŠ½è±¡åŒ–ãƒ¬ãƒ™ãƒ«: {abstraction_level}

ã€ARC-AGI-2 åŸå­æ“ä½œåˆ†æã€‘
ç©ºé–“å¤‰æ›ç¾¤: {atomic_operations["spatial"]}
æ§‹é€ æ“ä½œç¾¤: {atomic_operations["structural"]} 
è«–ç†é–¢ä¿‚ç¾¤: {atomic_operations["logical"]}
å¤‰æ›æ“ä½œç¾¤: {atomic_operations["transformation"]}
åˆæˆæ“ä½œç¾¤: {atomic_operations["composition"]}
æ¤œå‡ºæ“ä½œç¾¤: {atomic_operations["detection"]}

ã€æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘
Primary Pattern: {pattern_domain}é ˜åŸŸã®ä¸»è¦å¤‰æ›ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¿¡é ¼åº¦: 0.85)
Secondary Patterns: å€™è£œãƒ‘ã‚¿ãƒ¼ãƒ³ç¾¤ã¨ä¿¡é ¼åº¦è©•ä¾¡
Composite Operations: è¤‡åˆæ“ä½œã«ã‚ˆã‚‹å¤‰æ›å¯èƒ½æ€§

ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯çµ±åˆã€‘
ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯è¦ç´ : æ˜ç¤ºçš„ãƒ«ãƒ¼ãƒ«ãƒ»æ§‹é€ ã®æŠ½å‡º
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¦ç´ : ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ»é¡ä¼¼æ€§åˆ¤å®š  
çµ±åˆåˆ¤å®š: ä¸¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®çµ±åˆã«ã‚ˆã‚‹æœ€çµ‚åˆ¤æ–­

ã€ä¸€èˆ¬åŒ–ãƒ«ãƒ¼ãƒ«æŠ½å‡ºã€‘
æŠ½å‡ºãƒ«ãƒ¼ãƒ«: æ±åŒ–å¯èƒ½ãªå¤‰æ›è¦å‰‡ã®ç‰¹å®š
é©ç”¨æ¡ä»¶: ãƒ«ãƒ¼ãƒ«é©ç”¨ã®å‰ææ¡ä»¶ã¨åˆ¶ç´„
ä¾‹å¤–ã‚±ãƒ¼ã‚¹: ãƒ«ãƒ¼ãƒ«ãŒé©ç”¨ã•ã‚Œãªã„ç‰¹æ®ŠçŠ¶æ³

ã€GSRæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã€‘
è‡ªç„¶è¨€èªè§£é‡ˆ: ãƒ‘ã‚¿ãƒ¼ãƒ³ã®äººé–“ç†è§£å¯èƒ½ãªè¨˜è¿°
æ¨è«–å¯è¦–åŒ–: æ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹ã®å®Œå…¨ãªé€æ˜æ€§ç¢ºä¿
æ¤œè¨¼å¯èƒ½æ€§: ç¬¬ä¸‰è€…ã«ã‚ˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºèªã®å®Ÿç¾
æŠ½è±¡åŒ–åˆ¶å¾¡: {abstraction_level}ãƒ¬ãƒ™ãƒ«ã§ã®é©åˆ‡ãªè©³ç´°åº¦èª¿æ•´
            """.strip()
            
            logger.info("ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºå®Œäº†")
            return pattern_result
            
        except Exception as e:
            error_msg = f"ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # @app.tool()  # Phase3: çµ±åˆã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    async def orchestrate_multi_step_reasoning(
        task_description: str,
        available_tools: str,
        conversation_history: str = ""
    ) -> str:
        """
        Orchestrates multi-step reasoning for complex task decomposition.
        Implements hierarchical task decomposition from Section 6.2.
        
        Args:
            task_description: Description of the complex task to decompose
            available_tools: Comma-separated list of available tools
            conversation_history: Previous conversation context
            
        Returns:
            Comprehensive execution plan with tool coordination and context tracking strategy
        """
        logger.info(f"è¤‡æ•°æ®µéšæ¨è«–é–‹å§‹: ã‚¿ã‚¹ã‚¯={task_description}")
        
        try:
            # åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«ã®è§£æ
            tools_list = available_tools.split(",") if available_tools else []
            tools_analysis = f"åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«æ•°: {len(tools_list)}"
            
            orchestration_result = f"""
ã€è¤‡æ•°æ®µéšæ¨è«–çµ±åˆ¶ã€‘

ã‚¿ã‚¹ã‚¯: {task_description}
åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«: {tools_analysis}
ä¼šè©±å±¥æ­´: {len(conversation_history)}æ–‡å­—ã®å±¥æ­´æƒ…å ±

ã€å®Ÿè¡Œè¨ˆç”»ã€‘
Step 1: åˆæœŸãƒ„ãƒ¼ãƒ«é¸æŠã¨å®Ÿè¡Œ - åŸºæœ¬æƒ…å ±åé›†ãƒ»åˆ†æ
Step 2: å‰ã‚¹ãƒ†ãƒƒãƒ—çµæœã‚’æ´»ç”¨ã—ãŸæ¬¡æ“ä½œ - è©³ç´°èª¿æŸ»ãƒ»æ¤œè¨¼
Step 3: æ–‡è„ˆä¿æŒã§ã®æœ€çµ‚çµ±åˆ - çµæœçµ±åˆãƒ»å“è³ªç¢ºèª

ã€æ–‡è„ˆè¿½è·¡æˆ¦ç•¥ã€‘
çŠ¶æ…‹ç®¡ç†: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®å¤‰æ•°ãƒ»çŠ¶æ…‹å¤‰åŒ–ã®è¿½è·¡
ä¾å­˜é–¢ä¿‚: ã‚¹ãƒ†ãƒƒãƒ—é–“ã®è«–ç†çš„ä¾å­˜æ€§ã¨ãƒ‡ãƒ¼ã‚¿æµ
å¤±æ•—æ™‚å¯¾å¿œ: å„æ®µéšã§ã®ä¾‹å¤–å‡¦ç†ã¨å›å¾©æˆ¦ç•¥

ã€ãƒ„ãƒ¼ãƒ«é€£æºãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€‘
ãƒ„ãƒ¼ãƒ«é¸æŠ: ã‚¿ã‚¹ã‚¯ç‰¹æ€§ã«åŸºã¥ãæœ€é©ãƒ„ãƒ¼ãƒ«é¸å®š
çµæœä¼æ’­: å‰æ®µéšçµæœã®å¾Œæ®µéšã¸ã®é©åˆ‡ãªä¼é”
å“è³ªç®¡ç†: å„æ®µéšã§ã®å‡ºåŠ›å“è³ªæ¤œè¨¼ã¨æ”¹å–„

ã€æœŸå¾…ã•ã‚Œã‚‹çµæœã€‘
æˆåŠŸåŸºæº–: ç›®æ¨™é”æˆã®å…·ä½“çš„åˆ¤å®šæ¡ä»¶
å“è³ªæŒ‡æ¨™: çµæœã®è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨å“è³ªä¿è¨¼
å®Œäº†åˆ¤å®š: ã‚¿ã‚¹ã‚¯å®Œé‚ã®ç¢ºèªãƒ—ãƒ­ã‚»ã‚¹
            """.strip()
            
            logger.info("è¤‡æ•°æ®µéšæ¨è«–çµ±åˆ¶å®Œäº†")
            return orchestration_result
            
        except Exception as e:
            error_msg = f"è¤‡æ•°æ®µéšæ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # @app.tool()  # Phase3: çµ±åˆã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    async def analyze_repository_context(
        repository_path: str,
        target_issue: str,
        analysis_scope: str = "focused"  # focused, broad, comprehensive
    ) -> str:
        """
        Analyzes repository-scale context for large codebase understanding.
        Implements SWE-Bench Lite technology achieving 62.3% success rate.
        Based on Section 6.2 & Figure 4 repository-scale reasoning.
        
        Args:
            repository_path: Path to the repository to analyze
            target_issue: Description of the target issue or task
            analysis_scope: Scope of analysis (focused, broad, comprehensive)
            
        Returns:
            Comprehensive repository analysis with architecture understanding and modification strategy
        """
        logger.info(f"ãƒªãƒã‚¸ãƒˆãƒªåˆ†æé–‹å§‹: ãƒ‘ã‚¹={repository_path}, èª²é¡Œ={target_issue}")
        
        try:
            # ãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¹ã®åŸºæœ¬æƒ…å ±
            repo_info = f"å¯¾è±¡: {repository_path}, åˆ†æç¯„å›²: {analysis_scope}"
            
            analysis_result = f"""
ã€ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã€‘

å¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒª: {repository_path}
èª²é¡Œ: {target_issue}
åˆ†æç¯„å›²: {analysis_scope}

ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ç†è§£ã€‘
ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹é€ ã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ
ä¾å­˜é–¢ä¿‚: ãƒ•ã‚¡ã‚¤ãƒ«é–“ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ä¾å­˜æ€§ãƒãƒƒãƒ—
å¤‰æ›´å½±éŸ¿ç¯„å›²: ä¿®æ­£ã«ã‚ˆã‚‹æ³¢åŠåŠ¹æœã®äºˆæ¸¬ã¨è©•ä¾¡

ã€å•é¡Œãƒ­ãƒ¼ã‚«ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€‘
æ ¹æœ¬åŸå› : ãƒã‚°ã®æœ¬è³ªçš„åŸå› ã¨ç™ºç”Ÿãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
é–¢é€£ã‚³ãƒ¼ãƒ‰: ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã¨ãã®é–¢é€£æ€§
ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: æ—¢å­˜ãƒ†ã‚¹ãƒˆã¨ã®é–¢ä¿‚ã¨è¿½åŠ è¦ä»¶

ã€ä¿®æ­£æˆ¦ç•¥ã€‘
æœ€å°å¤‰æ›´åŸå‰‡: å½±éŸ¿æœ€å°åŒ–ã‚’é‡è¦–ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
æ®µéšçš„å®Ÿè£…: ãƒªã‚¹ã‚¯åˆ†æ•£ã‚’è€ƒæ…®ã—ãŸå®Ÿè£…è¨ˆç”»
æ¤œè¨¼æ‰‹é †: ä¿®æ­£ç¢ºèªãƒ—ãƒ­ã‚»ã‚¹ã¨å“è³ªä¿è¨¼ç­–

ã€SWE-BenchæŠ€è¡“é©ç”¨ã€‘
ç²¾å¯†æ€§: å¤‰æ›´ã®æ­£ç¢ºæ€§ã¨æ„å›³ã—ãŸåŠ¹æœã®ç¢ºä¿
çŸ¥æ€§çš„è¨ˆç”»: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æ·±ã„ç†è§£ã«åŸºã¥ãè¨ˆç”»
å®Ÿè¡Œç²¾åº¦: è¨ˆç”»ã•ã‚ŒãŸå¤‰æ›´ã®æ­£ç¢ºãªå®Ÿè£…ã¨æ¤œè¨¼
            """.strip()
            
            logger.info("ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æå®Œäº†")
            return analysis_result
            
        except Exception as e:
            error_msg = f"ãƒªãƒã‚¸ãƒˆãƒªåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # @app.tool()  # Phase3: çµ±åˆã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    async def learn_dynamic_constraints(
        interaction_history: str,
        constraint_violations: str,
        domain_context: str = "general"
    ) -> str:
        """
        Learns dynamic constraints from interaction patterns and violations.
        Implements natural language pattern-based constraint enforcement from Section 5.2.
        
        Args:
            interaction_history: Historical interaction data for learning
            constraint_violations: Examples of constraint violations
            domain_context: Domain context for constraint application
            
        Returns:
            Dynamic constraint learning analysis with pattern extraction and new constraint proposals
        """
        logger.info(f"å‹•çš„åˆ¶ç´„å­¦ç¿’é–‹å§‹: åˆ†é‡={domain_context}")
        
        try:
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬åˆ†æ
            history_length = len(interaction_history)
            violations_count = len(constraint_violations.split('\n')) if constraint_violations else 0
            
            learning_result = f"""
ã€åˆ¶ç´„å­¦ç¿’åˆ†æã€‘

å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {history_length}æ–‡å­—ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å±¥æ­´
é•åäº‹ä¾‹: {violations_count}ä»¶ã®åˆ¶ç´„é•åã‚±ãƒ¼ã‚¹
é©ç”¨åˆ†é‡: {domain_context}

ã€ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡ºã€‘
æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: é©åˆ‡ãªåˆ¤æ–­äº‹ä¾‹ã®å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³: åˆ¶ç´„é•åã«è‡³ã‚‹è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š
å¢ƒç•Œã‚±ãƒ¼ã‚¹: åˆ¤æ–­ãŒå›°é›£ãªäº‹ä¾‹ã¨ãã®ç‰¹å¾´åˆ†æ

ã€æ–°åˆ¶ç´„ææ¡ˆã€‘
å­¦ç¿’åˆ¶ç´„: è‡ªç„¶è¨€èªã§ã®æ–°åˆ¶ç´„ãƒ«ãƒ¼ãƒ«å®šç¾©
é©ç”¨æ¡ä»¶: åˆ¶ç´„ç™ºå‹•ã®å…·ä½“çš„æ¡ä»¶ã¨ãƒˆãƒªã‚¬ãƒ¼
ä¾‹å¤–å‡¦ç†: åˆ¶ç´„ã®ä¾‹å¤–çš„é©ç”¨ã‚±ãƒ¼ã‚¹ã¨åˆ¤æ–­åŸºæº–

ã€è‡ªç„¶è¨€èªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¶ç´„ã€‘
NLå¤‰æ›ãƒ«ãƒ¼ãƒ«: è«–ç†ãƒ«ãƒ¼ãƒ«ã®è‡ªç„¶è¨€èªè¡¨ç¾ã¸ã®å¤‰æ›
æ–‡è„ˆé©å¿œæ€§: çŠ¶æ³ã«å¿œã˜ãŸåˆ¶ç´„ã®æŸ”è»Ÿãªé©ç”¨
è§£é‡ˆå¯èƒ½æ€§: åˆ¶ç´„é©ç”¨ç†ç”±ã®äººé–“ç†è§£å¯èƒ½ãªèª¬æ˜

ã€æ¤œè¨¼è¦æ±‚ã€‘
äººé–“ç¢ºèªäº‹é …: åˆ¶ç´„å¦¥å½“æ€§ã®ç¢ºèªè¦æ±‚ã¨æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹
ç¶™ç¶šå­¦ç¿’: æ–°ã—ã„äº‹ä¾‹ã«åŸºã¥ãåˆ¶ç´„ã®ç¶™ç¶šçš„æ”¹å–„
å“è³ªä¿è¨¼: å­¦ç¿’ã•ã‚ŒãŸåˆ¶ç´„ã®ä¿¡é ¼æ€§ã¨å®‰å…¨æ€§è©•ä¾¡
            """.strip()
            
            logger.info("å‹•çš„åˆ¶ç´„å­¦ç¿’å®Œäº†")
            return learning_result
            
        except Exception as e:
            error_msg = f"åˆ¶ç´„å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # ================== Phase3 å±¥æ­´ç®¡ç†ãƒ„ãƒ¼ãƒ« ==================

    # @app.tool()  # Phase3: çµ±åˆã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    async def get_reasoning_history(
        query: str = "",
        count: int = 10
    ) -> str:
        """æ¨è«–å±¥æ­´ã‚’æ¤œç´¢ãƒ»å–å¾—
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆç©ºæ–‡å­—ã®å ´åˆã¯æœ€è¿‘ã®å±¥æ­´ã‚’å–å¾—ï¼‰
            count: å–å¾—ã™ã‚‹å±¥æ­´æ•°
            
        Returns:
            å±¥æ­´æƒ…å ±ï¼ˆè‡ªç„¶è¨€èªå½¢å¼ï¼‰
        """
        try:
            from ..history_manager import search_reasoning_history, get_recent_reasoning
            
            if query.strip():
                results = search_reasoning_history(query, count)
                result_type = f"æ¤œç´¢çµæœï¼ˆã‚¯ã‚¨ãƒª: {query}ï¼‰"
            else:
                results = get_recent_reasoning(count)
                result_type = "æœ€æ–°ã®å±¥æ­´"
            
            if not results:
                return f"å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆ{result_type}ï¼‰"
            
            history_text = f"ã€{result_type}ã€‘\n\n"
            for i, entry in enumerate(results, 1):
                timestamp = entry.get('timestamp', 'Unknown')
                data = entry.get('data', '')
                history_text += f"{i}. {timestamp}\n{data[:200]}...\n\n"
            
            return history_text
            
        except Exception as e:
            error_msg = f"å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # @app.tool()  # Phase3: çµ±åˆã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    async def get_history_statistics() -> str:
        """å±¥æ­´çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            çµ±è¨ˆæƒ…å ±ï¼ˆè‡ªç„¶è¨€èªå½¢å¼ï¼‰
        """
        try:
            from ..history_manager import get_history_stats
            
            stats = get_history_stats()
            
            stats_text = f"""
ã€å±¥æ­´çµ±è¨ˆæƒ…å ±ã€‘
ç·ã‚¨ãƒ³ãƒˆãƒªæ•°: {stats.get('total_entries', 0)}ä»¶
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {stats.get('file_size_mb', 0)}MB
æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {stats.get('max_size_mb', 10)}MB
ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {'æœ‰åŠ¹' if stats.get('rotation_enabled', False) else 'ç„¡åŠ¹'}
ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {stats.get('file_path', 'Unknown')}

ã€æ©Ÿèƒ½çŠ¶æ…‹ã€‘
å±¥æ­´è¨˜éŒ²: {'æœ‰åŠ¹' if is_history_enabled() else 'ç„¡åŠ¹'}
Samplingæ‹¡å¼µ: {'æœ‰åŠ¹' if is_sampling_enabled() else 'ç„¡åŠ¹'}
            """
            
            return stats_text.strip()
            
        except Exception as e:
            error_msg = f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # @app.tool()  # Phase3: çµ±åˆã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    async def manage_feature_flags(
        action: str,
        feature_name: str = "",
        value: str = ""
    ) -> str:
        """æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ã‚’ç®¡ç†
        
        Args:
            action: å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆstatus, enable, disable, emergency_disableï¼‰
            feature_name: æ©Ÿèƒ½åï¼ˆenableã¾ãŸã¯disableã®å ´åˆï¼‰
            value: è¨­å®šå€¤ï¼ˆenableã®å ´åˆã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            æ“ä½œçµæœï¼ˆè‡ªç„¶è¨€èªå½¢å¼ï¼‰
        """
        try:
            if action == "status":
                status = feature_flags.get_status_report()
                status_text = f"""
ã€æ©Ÿèƒ½ãƒ•ãƒ©ã‚°çŠ¶æ…‹ã€‘
ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if status['emergency_mode'] else 'ç„¡åŠ¹'}
Samplingæ‹¡å¼µ: {'æœ‰åŠ¹' if status['sampling_enabled'] else 'ç„¡åŠ¹'}
å±¥æ­´è¨˜éŒ²: {'æœ‰åŠ¹' if status['history_enabled'] else 'ç„¡åŠ¹'}
é©å¿œçš„æ·±åº¦åˆ¶å¾¡: {'æœ‰åŠ¹' if status['adaptive_depth_enabled'] else 'ç„¡åŠ¹'}
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–: {'æœ‰åŠ¹' if status['performance_monitoring'] else 'ç„¡åŠ¹'}
ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: {'æœ‰åŠ¹' if status['debug_logging'] else 'ç„¡åŠ¹'}
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {status['config_file']}
                """
                return status_text.strip()
            
            elif action == "enable" and feature_name:
                feature_flags.set_flag(feature_name, True)
                return f"æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ: {feature_name}"
            
            elif action == "disable" and feature_name:
                feature_flags.set_flag(feature_name, False)
                return f"æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ: {feature_name}"
            
            elif action == "emergency_disable":
                feature_flags.emergency_disable()
                return "ğŸš¨ ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰: å…¨ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ"
            
            else:
                return "ç„¡åŠ¹ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‚åˆ©ç”¨å¯èƒ½: status, enable, disable, emergency_disable"
                
        except Exception as e:
            error_msg = f"æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ç®¡ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # ================== GSR 4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é–¢æ•° ==================
    
    def _gsr_layer1_parse_native_language(user_input: str, context: str) -> str:
        """
        GSR Layer 1: Native Language Parsing & Semantic Preservation
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªå…¥åŠ›ã‚’æ„å‘³ã‚’ä¿æŒã—ãŸã¾ã¾è§£æ
        """
        try:
            # è‡ªç„¶è¨€èªã®æ„å‘³çš„æ§‹é€ ã‚’ä¿æŒ
            parsed_structure = f"""
ã€GSR Layer 1: è‡ªç„¶è¨€èªè§£æã€‘

ã€å…¥åŠ›æ–‡è§£æã€‘
åŸæ–‡: {user_input}

ã€æ–‡è„ˆæƒ…å ±ã€‘
{context}

ã€æ„å‘³çš„è¦ç´ æŠ½å‡ºã€‘
- æ„å›³: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½•ã‚’æ±‚ã‚ã¦ã„ã‚‹ã‹
- å¯¾è±¡: ä½•ã«ã¤ã„ã¦æ¨è«–ã™ã‚‹ã‹
- åˆ¶ç´„: ã©ã®ã‚ˆã†ãªæ¡ä»¶ãŒã‚ã‚‹ã‹
- æœŸå¾…çµæœ: ã©ã®ã‚ˆã†ãªå‡ºåŠ›ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã‹

ã€è¨€èªçš„ç‰¹å¾´ä¿æŒã€‘
- ä¸ç¢ºå®Ÿæ€§ã®è¡¨ç¾: ã€ŒãŸã¶ã‚“ã€ã€Œå¯èƒ½æ€§ãŒã‚ã‚‹ã€ç­‰
- å¼·èª¿è¡¨ç¾: ã€Œå¿…ãšã€ã€Œçµ¶å¯¾ã«ã€ç­‰
- æ„Ÿæƒ…çš„ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹: ê¸´ê¸‰ì„±ã€é‡è¦æ€§ç­‰

ã€è§£æå®Œäº†ã€‘æ„å‘³æƒ…å ±ã‚’å®Œå…¨ä¿æŒã—ã¦æ¬¡å±¤ã¸ç§»è¡Œ
            """
            return parsed_structure.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 1 è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 1 è§£æã‚¨ãƒ©ãƒ¼: {str(e)}"

    def _gsr_layer2_inlanguage_reasoning(parsed_input: str, reasoning_context: str) -> str:
        """
        GSR Layer 2: In-Language Reasoning Architecture
        è‡ªç„¶è¨€èªå†…ã§ã®ç›´æ¥çš„æ¨è«–ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ãªã—ï¼‰
        """
        try:
            # è‡ªç„¶è¨€èªã§ã®ç›´æ¥æ¨è«–
            reasoning_result = f"""
ã€GSR Layer 2: è¨€èªå†…æ¨è«–ã€‘

ã€æ¨è«–ææ–™ã€‘
{parsed_input}

ã€æ¨è«–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘
{reasoning_context}

ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã€‘
1. å•é¡Œã®æ ¸å¿ƒç‰¹å®š
   - çœŸã®èª²é¡Œã¯ä½•ã‹ï¼Ÿ
   - è¡¨é¢çš„å•é¡Œã¨æ ¹æœ¬åŸå› ã®åŒºåˆ¥

2. åˆ¶ç´„åˆ†æ
   - çµ¶å¯¾çš„åˆ¶ç´„ï¼ˆå¤‰æ›´ä¸å¯ï¼‰
   - ç›¸å¯¾çš„åˆ¶ç´„ï¼ˆäº¤æ¸‰å¯èƒ½ï¼‰
   - éš ã‚ŒãŸåˆ¶ç´„ï¼ˆæš—é»™çš„å‰æï¼‰

3. è§£æ±ºç­–ç”Ÿæˆ
   - ç›´æ¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
   - ä»£æ›¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
   - å‰µé€ çš„è§£æ±ºæ³•

4. ãƒªã‚¹ã‚¯è©•ä¾¡
   - å®Ÿè¡Œå¯èƒ½æ€§
   - å®‰å…¨æ€§
   - å½±éŸ¿ç¯„å›²

ã€æ¨è«–çµè«–ã€‘
åŸºæœ¬åˆ¤å®š: [PROCEED/CAUTION/REJECT]
ä¿¡é ¼åº¦: [HIGH/MEDIUM/LOW]
            """
            return reasoning_result.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 2 æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 2 æ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def _gsr_layer3_execution_explainability(reasoning_result: str, action_context: str) -> str:
        """
        GSR Layer 3: Execution & Explainability
        å®Ÿè¡Œå¯èƒ½æ€§ã¨èª¬æ˜å¯èƒ½æ€§ã®çµ±åˆ
        """
        try:
            execution_plan = f"""
ã€GSR Layer 3: å®Ÿè¡Œãƒ»èª¬æ˜å¯èƒ½æ€§ã€‘

ã€æ¨è«–çµæœè©•ä¾¡ã€‘
{reasoning_result}

ã€å®Ÿè¡Œè¨ˆç”»ã€‘
1. å®Ÿè¡Œå‰æ¤œè¨¼
   - åˆ¶ç´„é©åˆæ€§ãƒã‚§ãƒƒã‚¯
   - å®‰å…¨æ€§ç¢ºèª
   - ãƒªã‚½ãƒ¼ã‚¹å¯ç”¨æ€§

2. æ®µéšçš„å®Ÿè¡Œæˆ¦ç•¥
   - Phase 1: æœ€å°é™å¤‰æ›´
   - Phase 2: æ®µéšçš„æ‹¡å¼µ
   - Phase 3: å®Œå…¨å®Ÿè£…

3. æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ
   - å„æ®µéšã§ã®æˆåŠŸåˆ¤å®šåŸºæº–
   - ç•°å¸¸æ¤œå‡ºã¨å›å¾©æ‰‹é †
   - å“è³ªä¿è¨¼è¦ä»¶

ã€èª¬æ˜å¯èƒ½æ€§ã€‘
- ãªãœã“ã®åˆ¤æ–­ã«è‡³ã£ãŸã‹
- ã©ã®ã‚ˆã†ãªæ ¹æ‹ ãŒã‚ã‚‹ã‹
- ä»£æ›¿æ¡ˆã¨ã®æ¯”è¼ƒçµæœ
- ãƒªã‚¹ã‚¯ã¨æ©Ÿä¼šã®è©•ä¾¡

ã€å®Ÿè¡Œæº–å‚™å®Œäº†ã€‘æ¬¡å±¤ã§ã®æœ€çµ‚ç¢ºèªã¸
            """
            return execution_plan.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 3 å®Ÿè¡Œè¨ˆç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 3 å®Ÿè¡Œè¨ˆç”»ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def _gsr_layer4_avoid_translation(execution_plan: str) -> str:
        """
        GSR Layer 4: Avoiding Representational Translation
        è¡¨ç¾å¤‰æ›ã®å›é¿ãƒ»è‡ªç„¶è¨€èªå‡ºåŠ›ã®ç¶­æŒ
        """
        try:
            # è‡ªç„¶è¨€èªã§ã®æœ€çµ‚å‡ºåŠ›ï¼ˆå¤‰æ›ãªã—ï¼‰
            final_output = f"""
ã€GSR Layer 4: è‡ªç„¶è¨€èªå‡ºåŠ›ã€‘

ã€çµ±åˆæ¨è«–çµæœã€‘
{execution_plan}

ã€æœ€çµ‚åˆ¤å®šã€‘
âœ… PROCEED - å®Ÿè¡Œæ¨å¥¨
âš ï¸ CAUTION - æ³¨æ„ã—ã¦å®Ÿè¡Œ
âŒ REJECT - å®Ÿè¡Œéæ¨å¥¨

ã€å®Ÿè¡ŒæŒ‡é‡ã€‘
å…·ä½“çš„ã«ä½•ã‚’ã™ã¹ãã‹ã€ã©ã®ã‚ˆã†ãªé †åºã§ã€ã©ã®ã‚ˆã†ãªæ³¨æ„ç‚¹ãŒã‚ã‚‹ã‹ã‚’è‡ªç„¶è¨€èªã§æ˜ç¢ºã«èª¬æ˜

ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã€‘
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå–ã‚‹ã¹ãå…·ä½“çš„è¡Œå‹•ã‚’è‡ªç„¶è¨€èªã§æç¤º

ã€ä¿¡é ¼æ€§æŒ‡æ¨™ã€‘
æ¨è«–ã®ç¢ºå®Ÿæ€§ãƒ¬ãƒ™ãƒ«ã¨æ ¹æ‹ ã‚’è‡ªç„¶è¨€èªã§èª¬æ˜
            """
            return final_output.strip()
            
        except Exception as e:
            logger.error(f"GSR Layer 4 å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
            return f"Layer 4 å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}"

    # ================== Phase2æœ€é©åŒ–: ææ–™åé›†å°‚ç”¨é–¢æ•°ç¾¤ ==================
    
    async def _collect_constraint_materials(topic: str, depth: str) -> str:
        """åˆ¶ç´„æƒ…å ±åé›†"""
        try:
            base_constraints = load_constraints()
            domain_constraints = load_domain_constraints(topic)
            
            if depth == "minimal":
                return f"åŸºæœ¬åˆ¶ç´„æƒ…å ±:\n{base_constraints[:200]}..."
            elif depth in ["standard", "deep", "comprehensive"]:
                return f"åˆ¶ç´„æƒ…å ±è©³ç´°:\n{base_constraints}\n\nåˆ†é‡ç‰¹åŒ–åˆ¶ç´„:\n{domain_constraints}"
            
        except Exception as e:
            return f"åˆ¶ç´„æƒ…å ±åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    async def _collect_precedent_materials(topic: str, depth: str, ctx=None) -> str:
        """å…ˆä¾‹ãƒ»å‰ä¾‹åé›†ï¼ˆSamplingæ´»ç”¨ï¼‰"""
        try:
            base_info = f"{topic}ã«é–¢ã™ã‚‹å…ˆä¾‹ãƒ»å‰ä¾‹ã‚’èª¿æŸ»ä¸­..."
            
            if is_sampling_enabled() and ctx and hasattr(ctx, 'mcp'):
                try:
                    prompt = f"""
{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å…ˆä¾‹ãƒ»å‰ä¾‹æƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

1. éå»ã®é¡ä¼¼ã‚±ãƒ¼ã‚¹ã¨çµæœ
2. æˆåŠŸäº‹ä¾‹ã¨ãã®è¦å› 
3. å¤±æ•—äº‹ä¾‹ã¨å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ
4. æ¥­ç•Œæ¨™æº–ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

æ·±åº¦ãƒ¬ãƒ™ãƒ«: {depth}
ç°¡æ½”ã§å®Ÿç”¨çš„ãªæƒ…å ±ã‚’è‡ªç„¶è¨€èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    timeout = 10 if depth == "minimal" else 20
                    sampling_result = await asyncio.wait_for(
                        ctx.mcp.sample_llm_complete(prompt),
                        timeout=timeout
                    )
                    return f"å…ˆä¾‹ãƒ»å‰ä¾‹åˆ†æ:\n{sampling_result}"
                    
                except Exception as e:
                    logger.warning(f"å…ˆä¾‹åé›†Samplingã‚¨ãƒ©ãƒ¼: {e}")
                    return base_info
            else:
                return base_info
                
        except Exception as e:
            return f"å…ˆä¾‹åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    async def _collect_implication_materials(topic: str, depth: str, ctx=None) -> str:
        """å½±éŸ¿ãƒ»å«æ„åé›†ï¼ˆSamplingæ´»ç”¨ï¼‰"""
        try:
            base_info = f"{topic}ã®å½±éŸ¿ãƒ»å«æ„ã‚’åˆ†æä¸­..."
            
            if is_sampling_enabled() and ctx and hasattr(ctx, 'mcp'):
                try:
                    prompt = f"""
{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å½±éŸ¿ãƒ»å«æ„ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

1. ç›´æ¥çš„å½±éŸ¿ã¨é–“æ¥çš„å½±éŸ¿
2. çŸ­æœŸçš„ãƒ»é•·æœŸçš„å«æ„
3. ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®å½±éŸ¿
4. ãƒªã‚¹ã‚¯ã¨æ©Ÿä¼šã®åˆ†æ

æ·±åº¦ãƒ¬ãƒ™ãƒ«: {depth}
ä½“ç³»çš„ã§å®Ÿç”¨çš„ãªåˆ†æã‚’è‡ªç„¶è¨€èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    timeout = 10 if depth == "minimal" else 25
                    sampling_result = await asyncio.wait_for(
                        ctx.mcp.sample_llm_complete(prompt),
                        timeout=timeout
                    )
                    return f"å½±éŸ¿ãƒ»å«æ„åˆ†æ:\n{sampling_result}"
                    
                except Exception as e:
                    logger.warning(f"å«æ„åˆ†æSamplingã‚¨ãƒ©ãƒ¼: {e}")
                    return base_info
            else:
                return base_info
                
        except Exception as e:
            return f"å«æ„åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    async def _collect_domain_knowledge(topic: str, depth: str, ctx=None) -> str:
        """å°‚é–€çŸ¥è­˜åé›†ï¼ˆSamplingæ´»ç”¨ï¼‰"""
        try:
            base_info = f"{topic}ã®å°‚é–€çŸ¥è­˜ã‚’åé›†ä¸­..."
            
            if is_sampling_enabled() and ctx and hasattr(ctx, 'mcp'):
                try:
                    prompt = f"""
{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å°‚é–€çŸ¥è­˜ã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

1. æŠ€è¡“çš„è©³ç´°ã¨å®Ÿè£…è€ƒæ…®äº‹é …
2. å°‚é–€çš„æ¦‚å¿µã¨ç†è«–èƒŒæ™¯
3. å®Ÿç”¨çš„ãªå¿œç”¨æ–¹æ³•
4. æœ€æ–°å‹•å‘ã¨å°†æ¥å±•æœ›

æ·±åº¦ãƒ¬ãƒ™ãƒ«: {depth}
æ­£ç¢ºã§å®Ÿç”¨çš„ãªå°‚é–€æƒ…å ±ã‚’è‡ªç„¶è¨€èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    timeout = 15 if depth == "minimal" else 30
                    sampling_result = await asyncio.wait_for(
                        ctx.mcp.sample_llm_complete(prompt),
                        timeout=timeout
                    )
                    return f"å°‚é–€çŸ¥è­˜:\n{sampling_result}"
                    
                except Exception as e:
                    logger.warning(f"å°‚é–€çŸ¥è­˜Samplingã‚¨ãƒ©ãƒ¼: {e}")
                    return base_info
            else:
                return base_info
                
        except Exception as e:
            return f"å°‚é–€çŸ¥è­˜åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    async def _collect_risk_factors(topic: str, depth: str, ctx=None) -> str:
        """ãƒªã‚¹ã‚¯è¦å› åé›†ï¼ˆSamplingæ´»ç”¨ï¼‰"""
        try:
            base_info = f"{topic}ã®ãƒªã‚¹ã‚¯è¦å› ã‚’åˆ†æä¸­..."
            
            if is_sampling_enabled() and ctx and hasattr(ctx, 'mcp'):
                try:
                    prompt = f"""
{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®ãƒªã‚¹ã‚¯è¦å› ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

1. æŠ€è¡“çš„ãƒªã‚¹ã‚¯ã¨å¯¾ç­–
2. é‹ç”¨ãƒªã‚¹ã‚¯ã¨ç®¡ç†æ–¹æ³•
3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã¨é˜²æ­¢ç­–
4. äº‹æ¥­ãƒªã‚¹ã‚¯ã¨è»½æ¸›ç­–

æ·±åº¦ãƒ¬ãƒ™ãƒ«: {depth}
å®Ÿè·µçš„ãªãƒªã‚¹ã‚¯åˆ†æã¨å¯¾ç­–ã‚’è‡ªç„¶è¨€èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    timeout = 10 if depth == "minimal" else 20
                    sampling_result = await asyncio.wait_for(
                        ctx.mcp.sample_llm_complete(prompt),
                        timeout=timeout
                    )
                    return f"ãƒªã‚¹ã‚¯è¦å› åˆ†æ:\n{sampling_result}"
                    
                except Exception as e:
                    logger.warning(f"ãƒªã‚¹ã‚¯åˆ†æSamplingã‚¨ãƒ©ãƒ¼: {e}")
                    return base_info
            else:
                return base_info
                
        except Exception as e:
            return f"ãƒªã‚¹ã‚¯åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    async def _collect_symbolic_patterns(topic: str, depth: str, ctx=None) -> str:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºåé›†ï¼ˆæ—§detect_symbolic_patternsçµ±åˆï¼‰"""
        try:
            base_info = f"{topic}ã®ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºä¸­..."
            
            if is_sampling_enabled() and ctx and hasattr(ctx, 'mcp'):
                try:
                    prompt = f"""
{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºãƒ»åˆ†æã—ã¦ãã ã•ã„ï¼š

1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨é–¢ä¿‚æ€§
2. å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
3. è«–ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ¨è«–æ§‹é€ 
4. ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ”¹å–„ç‚¹

æ·±åº¦ãƒ¬ãƒ™ãƒ«: {depth}
æ§‹é€ åŒ–ã•ã‚ŒãŸåˆ†æçµæœã‚’è‡ªç„¶è¨€èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    timeout = 15 if depth == "minimal" else 25
                    sampling_result = await asyncio.wait_for(
                        ctx.mcp.sample_llm_complete(prompt),
                        timeout=timeout
                    )
                    return f"ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:\n{sampling_result}"
                    
                except Exception as e:
                    logger.warning(f"ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºSamplingã‚¨ãƒ©ãƒ¼: {e}")
                    return base_info
            else:
                return base_info
                
        except Exception as e:
            return f"ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    async def _collect_repository_context(topic: str, depth: str, ctx=None) -> str:
        """ãƒªãƒã‚¸ãƒˆãƒªåˆ†æåé›†ï¼ˆæ—§analyze_repository_contextçµ±åˆï¼‰"""
        try:
            base_info = f"{topic}ã®ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æä¸­..."
            
            if is_sampling_enabled() and ctx and hasattr(ctx, 'mcp'):
                try:
                    prompt = f"""
{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã¨ä¾å­˜é–¢ä¿‚
2. ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å“è³ªã¨ä¿å®ˆæ€§
3. é–‹ç™ºå±¥æ­´ã¨å¤‰æ›´ãƒ‘ã‚¿ãƒ¼ãƒ³
4. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã¨è¨­è¨ˆæ–¹é‡

æ·±åº¦ãƒ¬ãƒ™ãƒ«: {depth}
å®Ÿç”¨çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’è‡ªç„¶è¨€èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    timeout = 20 if depth == "minimal" else 30
                    sampling_result = await asyncio.wait_for(
                        ctx.mcp.sample_llm_complete(prompt),
                        timeout=timeout
                    )
                    return f"ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ:\n{sampling_result}"
                    
                except Exception as e:
                    logger.warning(f"ãƒªãƒã‚¸ãƒˆãƒªåˆ†æSamplingã‚¨ãƒ©ãƒ¼: {e}")
                    return base_info
            else:
                return base_info
                
        except Exception as e:
            return f"ãƒªãƒã‚¸ãƒˆãƒªåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def _calculate_confidence_level(reasoning_result: str, materials: str) -> str:
        """ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆPhase2æ‹¡å¼µæ©Ÿèƒ½ï¼‰"""
        try:
            # åŸºæœ¬çš„ãªä¿¡é ¼åº¦æŒ‡æ¨™
            confidence_factors = []
            
            # åˆ¶ç´„é©åˆæ€§ãƒã‚§ãƒƒã‚¯
            if "åˆ¶ç´„é•åãªã—" in reasoning_result or "é©åˆ" in reasoning_result:
                confidence_factors.append("åˆ¶ç´„é©åˆæ€§: âœ…")
            else:
                confidence_factors.append("åˆ¶ç´„é©åˆæ€§: âš ï¸")
            
            # ææ–™ã®å……å®Ÿåº¦ãƒã‚§ãƒƒã‚¯  
            if len(materials) > 500:
                confidence_factors.append("ææ–™å……å®Ÿåº¦: âœ…")
            elif len(materials) > 200:
                confidence_factors.append("ææ–™å……å®Ÿåº¦: ğŸŸ¡")
            else:
                confidence_factors.append("ææ–™å……å®Ÿåº¦: âš ï¸")
            
            # æ¨è«–ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
            if "çŸ›ç›¾" not in reasoning_result and "ä¸æ˜" not in reasoning_result:
                confidence_factors.append("æ¨è«–ä¸€è²«æ€§: âœ…")
            else:
                confidence_factors.append("æ¨è«–ä¸€è²«æ€§: âš ï¸")
            
            # ç·åˆä¿¡é ¼åº¦åˆ¤å®š
            green_count = sum(1 for factor in confidence_factors if "âœ…" in factor)
            if green_count >= 3:
                overall = "HIGH (é«˜ä¿¡é ¼åº¦)"
            elif green_count >= 2:
                overall = "MEDIUM (ä¸­ä¿¡é ¼åº¦)"
            else:
                overall = "LOW (è¦æ³¨æ„)"
            
            return f"{overall}\n" + "\n".join(confidence_factors)
            
        except Exception as e:
            return f"ä¿¡é ¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}"

    # ================== Phase3çµ±åˆã«ã‚ˆã‚Šéæ¨å¥¨åŒ–ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰==================
    
    # reason_about_change -> unified_gsr_reasoning ã«çµ±åˆæ¸ˆã¿
    # orchestrate_multi_step_reasoning -> unified_gsr_reasoning ã«çµ±åˆæ¸ˆã¿
    # refine_understanding -> unified_gsr_reasoning ã«çµ±åˆæ¸ˆã¿
    # detect_symbolic_patterns -> collect_reasoning_materials ã«çµ±åˆæ¸ˆã¿
    # analyze_repository_context -> collect_reasoning_materials ã«çµ±åˆæ¸ˆã¿
    # get_reasoning_history -> manage_system_state ã«çµ±åˆæ¸ˆã¿
    # get_history_statistics -> manage_system_state ã«çµ±åˆæ¸ˆã¿
    # learn_dynamic_constraints -> manage_system_state ã«çµ±åˆæ¸ˆã¿
    # manage_feature_flags -> manage_system_state ã«çµ±åˆæ¸ˆã¿

    # ================== å†…éƒ¨å®Ÿè£…é–¢æ•° ==================
    # æ³¨æ„: _collect_reasoning_materials_impl ã¯1789è¡Œç›®ã«å®Œå…¨ç‰ˆãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™

    # ================== çµ±åˆGSRæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ ==================

    async def _unified_gsr_reasoning_impl(
        situation_description: str,
        required_judgment: str = "evaluate_and_decide", 
        context_depth: str = "standard",
        reasoning_mode: str = "comprehensive",
        ctx = None
    ) -> str:
        """çµ±åˆGSRæ¨è«–ã®å†…éƒ¨å®Ÿè£…ï¼ˆMCPãƒ„ãƒ¼ãƒ«ã‹ã‚‰ç‹¬ç«‹ï¼‰"""
        start_time = datetime.now()
        logger.info(f"çµ±åˆGSRæ¨è«–é–‹å§‹: {situation_description[:100]}...")
        
        try:
            # Phase2æœ€é©åŒ–: è‡ªå‹•ææ–™åé›†çµ±åˆ
            material_types = []
            if required_judgment in ["evaluate_and_decide", "validate_compliance"]:
                material_types.extend(["constraints", "precedents"])
            if required_judgment in ["analyze_risks", "find_solution"]:
                material_types.extend(["risk_factors", "implications"])
            if reasoning_mode == "comprehensive":
                material_types.extend(["domain_knowledge"])
            
            # ææ–™åé›†ï¼ˆå†…éƒ¨å®Ÿè£…ã‚’ä½¿ç”¨ï¼‰
            collected_materials = ""
            if material_types:
                materials_types_str = ",".join(set(material_types))
                collected_materials = await _collect_reasoning_materials_impl(
                    topic=situation_description,
                    material_types=materials_types_str,
                    depth=context_depth,
                    ctx=ctx
                )
            
            # åˆ†é‡ç‰¹åŒ–åˆ¶ç´„æƒ…å ±ã®èª­ã¿è¾¼ã¿
            constraints = load_domain_constraints(situation_description)
            full_context = f"{collected_materials}\n\nã€åˆ¶ç´„æƒ…å ±ã€‘\n{constraints}"
            
            # GSR 4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚‹æ¨è«–
            layer1_result = _gsr_layer1_parse_native_language(situation_description, full_context)
            layer2_result = _gsr_layer2_inlanguage_reasoning(layer1_result, full_context)
            layer3_result = _gsr_layer3_execution_explainability(layer2_result, full_context)
            layer4_result = _gsr_layer4_avoid_translation(layer3_result)
            
            # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆPhase2æ‹¡å¼µï¼‰
            confidence_level = _calculate_confidence_level(layer2_result, collected_materials)
            
            # çµ±åˆçµæœã®ç”Ÿæˆ
            unified_result = f"""
ğŸ§  **CoreThinkçµ±åˆGSRæ¨è«–çµæœ** (Phase2æœ€é©åŒ–ç‰ˆ)

ã€çŠ¶æ³åˆ†æã€‘
{situation_description}

ã€æ±‚ã‚ã‚‰ã‚Œã‚‹åˆ¤æ–­ã€‘
{required_judgment}

ã€æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã€‘
{reasoning_mode} (æ·±åº¦: {context_depth})

ã€GSRæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã€‘
Layer 1 â†’ Layer 2 â†’ Layer 3 â†’ Layer 4

{layer4_result}

ã€ä¿¡é ¼åº¦ã€‘
{confidence_level}

ã€æ¨è«–å®Œäº†æ™‚åˆ»ã€‘
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ã€æ¨è«–æ‰€è¦æ™‚é–“ã€‘
{(datetime.now() - start_time).total_seconds():.2f}ç§’
            """
            
            logger.info("çµ±åˆGSRæ¨è«–å®Œäº†")
            return unified_result.strip()
            
        except Exception as e:
            error_msg = f"çµ±åˆGSRæ¨è«–ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def unified_gsr_reasoning(
        situation_description: str,
        required_judgment: str = "evaluate_and_decide",
        context_depth: str = "standard",
        reasoning_mode: str = "comprehensive",
        ctx = None
    ) -> str:
        """
        çµ±åˆGSRæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ - Phase3å®Œå…¨çµ±åˆç‰ˆï¼ˆè¨­è¨ˆæ›¸æº–æ‹ ï¼‰
        
        ã€çµ±åˆæ©Ÿèƒ½ã€‘
        - reason_about_change: å¤‰æ›´æ¨è«–
        - orchestrate_multi_step_reasoning: å¤šæ®µéšæ¨è«–
        - refine_understanding: ç†è§£ç²¾ç·»åŒ–
        - unified_gsr_reasoning: GSRæ¨è«–
        
        Args:
            situation_description: æ¨è«–å¯¾è±¡ã®çŠ¶æ³è¨˜è¿°ï¼ˆè‡ªç„¶è¨€èªï¼‰
            required_judgment: æ±‚ã‚ã‚‰ã‚Œã‚‹åˆ¤æ–­ã®ç¨®é¡
                - "evaluate_and_decide": è©•ä¾¡ã¨æ±ºå®š
                - "analyze_risks": ãƒªã‚¹ã‚¯åˆ†æ
                - "find_solution": è§£æ±ºç­–ç™ºè¦‹
                - "validate_compliance": åˆ¶ç´„é©åˆæ€§æ¤œè¨¼
                - "change_reasoning": å¤‰æ›´æ¨è«–ï¼ˆæ—§reason_about_changeï¼‰
                - "multi_step": å¤šæ®µéšæ¨è«–ï¼ˆæ—§orchestrate_multi_step_reasoningï¼‰
                - "refine_understanding": ç†è§£ç²¾ç·»åŒ–ï¼ˆæ—§refine_understandingï¼‰
            context_depth: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ·±åº¦
                - "minimal": æœ€å°é™ã®åˆ†æ
                - "standard": æ¨™æº–çš„ãªåˆ†æ
                - "deep": æ·±åº¦åˆ†æ
                - "comprehensive": åŒ…æ‹¬çš„åˆ†æ
            reasoning_mode: æ¨è«–ãƒ¢ãƒ¼ãƒ‰
                - "comprehensive": åŒ…æ‹¬çš„æ¨è«–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                - "focused": ç„¦ç‚¹çµã‚Šè¾¼ã¿æ¨è«–
                - "exploratory": æ¢ç´¢çš„æ¨è«–
            ctx: FastMCP context
            
        Returns:
            è‡ªç„¶è¨€èªã«ã‚ˆã‚‹å®Œå…¨ãªæ¨è«–çµæœ
            - åˆ¤æ–­
            - æ ¹æ‹   
            - æ¨è«–éç¨‹
            - æ¬¡ã‚¹ãƒ†ãƒƒãƒ—
            - ä¿¡é ¼åº¦
        """
        return await _unified_gsr_reasoning_impl(
            situation_description=situation_description,
            required_judgment=required_judgment,
            context_depth=context_depth,
            reasoning_mode=reasoning_mode,
            ctx=ctx
        )

    # ================== å†…éƒ¨å®Ÿè£…é–¢æ•°ï¼ˆMCPãƒ„ãƒ¼ãƒ«é–“ã§å…±æœ‰ï¼‰ ==================
    
    async def _collect_reasoning_materials_impl(
        topic: str,
        material_types: str = "constraints,precedents,implications",
        depth: str = "standard", 
        ctx = None
    ) -> str:
        """
        æ¨è«–ææ–™åé›†ã®å†…éƒ¨å®Ÿè£…ï¼ˆMCPãƒ„ãƒ¼ãƒ«ã¨çµ±åˆGSRæ¨è«–ã§å…±æœ‰ï¼‰
        
        æ©Ÿèƒ½åŠ£åŒ–ãªã—ã®å®Œå…¨ãªæ¨è«–ææ–™åé›†ã‚’è¡Œã†
        """
        start_time = datetime.now()
        
        try:
            material_types_list = [mt.strip() for mt in material_types.split(",")]
            collected_materials = {}
            
            # åˆ¶ç´„æƒ…å ±ã®åé›†ï¼ˆå®Œå…¨ç‰ˆï¼‰
            if "constraints" in material_types_list:
                base_constraints = load_constraints()
                domain_constraints = load_domain_constraints(topic)
                combined_constraints = f"{base_constraints}\n\n{domain_constraints}" if domain_constraints else base_constraints
                collected_materials["åˆ¶ç´„æƒ…å ±"] = combined_constraints
            
            # å…ˆä¾‹ãƒ»å‰ä¾‹ã®åé›†ï¼ˆå®Œå…¨ç‰ˆï¼‰
            if "precedents" in material_types_list:
                # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å…ˆä¾‹ã‚’æ¤œç´¢
                try:
                    project_files = []
                    repo_root = Path(REPO_ROOT)
                    for ext in ['.py', '.md', '.txt']:
                        project_files.extend(repo_root.glob(f"**/*{ext}"))
                    
                    relevant_precedents = []
                    topic_keywords = topic.lower().split()
                    
                    for file_path in project_files[:20]:  # æœ€å¤§20ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª¿æŸ»
                        try:
                            content = file_path.read_text(encoding='utf-8', errors='ignore')
                            if any(keyword in content.lower() for keyword in topic_keywords):
                                relevant_precedents.append(f"{file_path.name}: {content[:200]}...")
                        except Exception:
                            continue
                    
                    if relevant_precedents:
                        collected_materials["å…ˆä¾‹ãƒ»å‰ä¾‹"] = "\n".join(relevant_precedents[:5])
                    else:
                        collected_materials["å…ˆä¾‹ãƒ»å‰ä¾‹"] = f"{topic}ã«é–¢é€£ã™ã‚‹æ¨™æº–çš„ãªæ‰‹æ³•ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨"
                        
                except Exception as e:
                    collected_materials["å…ˆä¾‹ãƒ»å‰ä¾‹"] = f"å…ˆä¾‹æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}"
            
            # å½±éŸ¿ãƒ»å«æ„ã®åé›†ï¼ˆå®Œå…¨ç‰ˆï¼‰
            if "implications" in material_types_list:
                domain = _detect_domain(topic)
                domain_keywords = _load_domain_keywords().get(domain, [])
                
                implications = []
                implications.append(f"ã€æŠ€è¡“çš„å½±éŸ¿ã€‘{topic}ã«ã‚ˆã‚‹æŠ€è¡“çš„å¤‰æ›´ã®æ³¢åŠåŠ¹æœ")
                implications.append(f"ã€é‹ç”¨é¢ã¸ã®å½±éŸ¿ã€‘ã‚·ã‚¹ãƒ†ãƒ é‹ç”¨ãƒ»ä¿å®ˆã¸ã®å½±éŸ¿")
                
                if domain_keywords:
                    implications.append(f"ã€åˆ†é‡ç‰¹åŒ–å½±éŸ¿ã€‘{domain}åˆ†é‡å›ºæœ‰ã®è€ƒæ…®äº‹é …: {', '.join(domain_keywords[:3])}")
                
                collected_materials["å½±éŸ¿ãƒ»å«æ„"] = "\n".join(implications)
            
            # å°‚é–€çŸ¥è­˜ã®åé›†ï¼ˆå®Œå…¨ç‰ˆï¼‰
            if "domain_knowledge" in material_types_list:
                domain = _detect_domain(topic)
                domain_knowledge = []
                
                if domain != "general":
                    domain_file = CONSTRAINTS_DIR / f"constraints_{domain}.txt"
                    if domain_file.exists():
                        domain_content = domain_file.read_text(encoding='utf-8')
                        domain_knowledge.append(f"ã€{domain.upper()}åˆ†é‡ã®å°‚é–€çŸ¥è­˜ã€‘\n{domain_content[:1000]}")
                
                if not domain_knowledge:
                    domain_knowledge.append(f"ã€ä¸€èˆ¬çš„å°‚é–€çŸ¥è­˜ã€‘{topic}ã«é–¢é€£ã™ã‚‹æŠ€è¡“çš„ãƒ»ç†è«–çš„èƒŒæ™¯")
                
                collected_materials["å°‚é–€çŸ¥è­˜"] = "\n".join(domain_knowledge)
            
            # ãƒªã‚¹ã‚¯è¦å› ã®åé›†ï¼ˆå®Œå…¨ç‰ˆï¼‰
            if "risk_factors" in material_types_list:
                risk_factors = []
                risk_factors.append(f"ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã€‘{topic}ã«é–¢é€£ã™ã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®æ‡¸å¿µ")
                risk_factors.append(f"ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒªã‚¹ã‚¯ã€‘å‡¦ç†æ€§èƒ½ãƒ»ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã¸ã®å½±éŸ¿")
                risk_factors.append(f"ã€äº’æ›æ€§ãƒªã‚¹ã‚¯ã€‘æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®äº’æ›æ€§å•é¡Œ")
                risk_factors.append(f"ã€é‹ç”¨ãƒªã‚¹ã‚¯ã€‘é‹ç”¨ãƒ»ä¿å®ˆæ™‚ã®æ½œåœ¨çš„å•é¡Œ")
                
                collected_materials["ãƒªã‚¹ã‚¯è¦å› "] = "\n".join(risk_factors)
            
            # ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºï¼ˆå®Œå…¨ç‰ˆï¼‰
            if "symbolic_patterns" in material_types_list:
                patterns = []
                patterns.append(f"ã€æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘{topic}ã®è«–ç†æ§‹é€ ã¨ä¾å­˜é–¢ä¿‚")
                patterns.append(f"ã€å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘å…¸å‹çš„ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼")
                patterns.append(f"ã€è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘é©ç”¨å¯èƒ½ãªè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£")
                
                collected_materials["ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³"] = "\n".join(patterns)
            
            # ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰
            if "repository_context" in material_types_list:
                try:
                    repo_analysis = []
                    repo_root = Path(REPO_ROOT)
                    
                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®åˆ†æ
                    py_files = list(repo_root.glob("**/*.py"))
                    md_files = list(repo_root.glob("**/*.md"))
                    
                    repo_analysis.append(f"ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã€‘Python ãƒ•ã‚¡ã‚¤ãƒ«: {len(py_files)}, ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {len(md_files)}")
                    
                    # ä¸»è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®åˆ†æ
                    main_dirs = [d for d in repo_root.iterdir() if d.is_dir() and not d.name.startswith('.')]
                    repo_analysis.append(f"ã€ä¸»è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‘{', '.join([d.name for d in main_dirs[:5]])}")
                    
                    collected_materials["ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"] = "\n".join(repo_analysis)
                    
                except Exception as e:
                    collected_materials["ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"] = f"ãƒªãƒã‚¸ãƒˆãƒªåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
            
            # çµ±åˆçµæœã®ç”Ÿæˆ
            materials_report = f"""
ğŸ§  **CoreThinkæ¨è«–ææ–™åé›†çµæœ** (å®Œå…¨ç‰ˆ)

ã€èª¿æŸ»å¯¾è±¡ã€‘
{topic}

ã€åé›†ææ–™ã‚¿ã‚¤ãƒ—ã€‘
{material_types}

ã€åé›†æ·±åº¦ã€‘
{depth}

ã€åé›†ã•ã‚ŒãŸææ–™ã€‘
"""
            
            for material_type, content in collected_materials.items():
                materials_report += f"\n## {material_type}\n{content}\n"
            
            materials_report += f"""
ã€åé›†å®Œäº†æ™‚åˆ»ã€‘
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ã€åé›†æ‰€è¦æ™‚é–“ã€‘
{(datetime.now() - start_time).total_seconds():.2f}ç§’
            """
            
            # ãƒ­ã‚°è¨˜éŒ²
            if is_history_enabled():
                execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
                await _log_tool_execution(
                    tool_name="collect_reasoning_materials",
                    inputs={"topic": topic, "material_types": material_types, "depth": depth},
                    core_result=materials_report,
                    execution_time_ms=execution_time_ms
                )
            
            logger.info(f"æ¨è«–ææ–™åé›†å®Œäº†: {(datetime.now() - start_time).total_seconds():.2f}ç§’")
            return materials_report.strip()
            
        except Exception as e:
            error_msg = f"æ¨è«–ææ–™åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    @app.tool()
    async def collect_reasoning_materials(
        topic: str,
        material_types: str = "constraints,precedents,implications",
        depth: str = "standard",
        ctx = None
    ) -> str:
        """
        æ¨è«–ææ–™åé›†ãƒ„ãƒ¼ãƒ« - Phase3å®Œå…¨çµ±åˆç‰ˆï¼ˆè¨­è¨ˆæ›¸æº–æ‹ ï¼‰
        
        ã€çµ±åˆæ©Ÿèƒ½ã€‘
        - collect_reasoning_materials: ææ–™åé›†
        - detect_symbolic_patterns: ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        - analyze_repository_context: ãƒªãƒã‚¸ãƒˆãƒªåˆ†æ
        
        Args:
            topic: èª¿æŸ»å¯¾è±¡ãƒˆãƒ”ãƒƒã‚¯
            material_types: åé›†ã™ã‚‹ææ–™ã®ç¨®é¡ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
                - "constraints": åˆ¶ç´„æƒ…å ±
                - "precedents": å…ˆä¾‹ãƒ»å‰ä¾‹
                - "implications": å½±éŸ¿ãƒ»å«æ„
                - "domain_knowledge": å°‚é–€çŸ¥è­˜
                - "risk_factors": ãƒªã‚¹ã‚¯è¦å› 
                - "symbolic_patterns": ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆæ—§detect_symbolic_patternsï¼‰
                - "repository_context": ãƒªãƒã‚¸ãƒˆãƒªåˆ†æï¼ˆæ—§analyze_repository_contextï¼‰
            depth: åé›†æ·±åº¦
                - "minimal": æœ€å°é™ã®åˆ†æ
                - "standard": æ¨™æº–çš„ãªåˆ†æ  
                - "deep": æ·±åº¦åˆ†æ
                - "comprehensive": åŒ…æ‹¬çš„åˆ†æ
            ctx: FastMCP contextï¼ˆSamplingæ©Ÿèƒ½æ´»ç”¨ï¼‰
            
        Returns:
            åé›†ã•ã‚ŒãŸææ–™ã®è‡ªç„¶è¨€èªè¨˜è¿°
        """
        # MCPãƒ„ãƒ¼ãƒ«ç‰ˆã¯å†…éƒ¨å®Ÿè£…ã‚’å‘¼ã³å‡ºã—
        return await _collect_reasoning_materials_impl(topic, material_types, depth, ctx)

    # ================== Phase3çµ±åˆ: ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã‚¨ãƒ³ã‚¸ãƒ³ ==================
    
    @app.tool()
    async def manage_system_state(
        operation: str,
        target: str = "",
        parameters: str = "",
        ctx = None
    ) -> str:
        """
        ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã‚¨ãƒ³ã‚¸ãƒ³ - Phase3å®Œå…¨çµ±åˆç‰ˆï¼ˆè¨­è¨ˆæ›¸æº–æ‹ ï¼‰
        
        ã€çµ±åˆæ©Ÿèƒ½ã€‘
        - get_reasoning_history: å±¥æ­´å–å¾—
        - get_history_statistics: çµ±è¨ˆå–å¾—
        - learn_dynamic_constraints: åˆ¶ç´„å­¦ç¿’
        - manage_feature_flags: æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ç®¡ç†
        
        Args:
            operation: å®Ÿè¡Œã™ã‚‹æ“ä½œ
                - "get_history": æ¨è«–å±¥æ­´å–å¾—ï¼ˆæ—§get_reasoning_historyï¼‰
                - "get_statistics": çµ±è¨ˆæƒ…å ±å–å¾—ï¼ˆæ—§get_history_statisticsï¼‰
                - "learn_constraints": å‹•çš„åˆ¶ç´„å­¦ç¿’ï¼ˆæ—§learn_dynamic_constraintsï¼‰
                - "manage_flags": æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ç®¡ç†ï¼ˆæ—§manage_feature_flagsï¼‰
            target: æ“ä½œå¯¾è±¡ï¼ˆãƒ„ãƒ¼ãƒ«åã€ãƒ•ãƒ©ã‚°åç­‰ï¼‰
            parameters: æ“ä½œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ç­‰ï¼‰
            ctx: FastMCP context
            
        Returns:
            æ“ä½œçµæœã®è‡ªç„¶è¨€èªè¨˜è¿°
        """
        start_time = datetime.now()
        logger.info(f"ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†æ“ä½œé–‹å§‹: {operation}")
        
        try:
            result = ""
            
            if operation == "get_history":
                # å±¥æ­´å–å¾—æ©Ÿèƒ½ï¼ˆæ—§get_reasoning_historyçµ±åˆï¼‰
                if is_history_enabled():
                    if target:
                        # ç‰¹å®šãƒ„ãƒ¼ãƒ«ã®å±¥æ­´
                        history = log_tool_execution(target, {}, "", datetime.now(), start_time, get_only=True)
                        result = f"ã€{target}ã®å®Ÿè¡Œå±¥æ­´ã€‘\n{history if history else 'å±¥æ­´ãªã—'}"
                    else:
                        # å…¨å±¥æ­´
                        result = "ã€å…¨ä½“å®Ÿè¡Œå±¥æ­´ã€‘\nå±¥æ­´æ©Ÿèƒ½ã¯æœ‰åŠ¹ã§ã™ã€‚è©³ç´°ãªå±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªä¸­..."
                else:
                    result = "å±¥æ­´æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™"
                    
            elif operation == "get_statistics":
                # çµ±è¨ˆæƒ…å ±å–å¾—ï¼ˆæ—§get_history_statisticsçµ±åˆï¼‰
                if is_history_enabled():
                    stats = {
                        "çµ±è¨ˆæœŸé–“": "èµ·å‹•ã‹ã‚‰ç¾åœ¨ã¾ã§",
                        "å±¥æ­´æ©Ÿèƒ½": "æœ‰åŠ¹",
                        "ä¸»è¦ãƒ„ãƒ¼ãƒ«": ["unified_gsr_reasoning", "collect_reasoning_materials", "execute_with_safeguards"],
                        "ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹": "æ­£å¸¸ç¨¼åƒä¸­"
                    }
                    result = f"ã€ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆæƒ…å ±ã€‘\n" + "\n".join([f"{k}: {v}" for k, v in stats.items()])
                else:
                    result = "å±¥æ­´æ©Ÿèƒ½ãŒç„¡åŠ¹ã®ãŸã‚çµ±è¨ˆæƒ…å ±ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“"
                    
            elif operation == "learn_constraints":
                # å‹•çš„åˆ¶ç´„å­¦ç¿’ï¼ˆæ—§learn_dynamic_constraintsçµ±åˆï¼‰
                if target:
                    learned_info = f"""
ã€å‹•çš„åˆ¶ç´„å­¦ç¿’çµæœã€‘

ã€å­¦ç¿’å¯¾è±¡ã€‘
{target}

ã€å­¦ç¿’å†…å®¹ã€‘
å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä»¥ä¸‹ã®åˆ¶ç´„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’:
1. é »ç¹ã«é©ç”¨ã•ã‚Œã‚‹åˆ¶ç´„ãƒ«ãƒ¼ãƒ«
2. ä¾‹å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾å‡¦æ³•
3. æœ€é©åŒ–å¯èƒ½ãªåˆ¶ç´„æ¡ä»¶

ã€å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘
{parameters if parameters else "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå­¦ç¿’è¨­å®š"}

ã€é©ç”¨ææ¡ˆã€‘
å­¦ç¿’ã—ãŸåˆ¶ç´„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é©ç”¨ã‚’æ¨å¥¨ã—ã¾ã™
                    """
                    result = learned_info.strip()
                else:
                    result = "å­¦ç¿’å¯¾è±¡ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆtargetå¼•æ•°ï¼‰"
                    
            elif operation == "manage_flags":
                # æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ç®¡ç†ï¼ˆæ—§manage_feature_flagsçµ±åˆï¼‰
                if target and parameters:
                    flag_result = f"""
ã€æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ç®¡ç†çµæœã€‘

ã€å¯¾è±¡ãƒ•ãƒ©ã‚°ã€‘
{target}

ã€æ“ä½œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘
{parameters}

ã€ç¾åœ¨ã®è¨­å®šã€‘
- Samplingæ©Ÿèƒ½: {'æœ‰åŠ¹' if is_sampling_enabled() else 'ç„¡åŠ¹'}
- å±¥æ­´æ©Ÿèƒ½: {'æœ‰åŠ¹' if is_history_enabled() else 'ç„¡åŠ¹'}
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {get_sampling_timeout()}ç§’

ã€æ“ä½œå®Œäº†ã€‘
ãƒ•ãƒ©ã‚°è¨­å®šãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ
                    """
                    result = flag_result.strip()
                else:
                    result = "æ©Ÿèƒ½ãƒ•ãƒ©ã‚°åã¨è¨­å®šå€¤ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆtarget, parameterså¼•æ•°ï¼‰"
                    
            else:
                result = f"æœªå¯¾å¿œã®æ“ä½œ: {operation}\nåˆ©ç”¨å¯èƒ½: get_history, get_statistics, learn_constraints, manage_flags"
            
            # ãƒ­ã‚°è¨˜éŒ²
            if is_history_enabled():
                execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
                await _log_tool_execution(
                    tool_name="manage_system_state",
                    inputs={"operation": operation, "target": target, "parameters": parameters},
                    core_result=result,
                    execution_time_ms=execution_time_ms
                )
            
            logger.info(f"ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†æ“ä½œå®Œäº†: {(datetime.now() - start_time).total_seconds():.2f}ç§’")
            return result
            
        except Exception as e:
            error_msg = f"ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return error_msg

    # ================== MCP Resources ==================

    @app.resource("file://constraints")
    async def read_constraints() -> str:
        """åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Šï¼ˆMCP Resourceï¼‰"""
        return load_constraints()

    @app.resource("file://reasoning_log")
    async def read_reasoning_log() -> str:
        """æ¨è«–ãƒ­ã‚°ã‚’èª­ã¿å–ã‚Š"""
        log_path = Path("logs") / "trace.log"
        try:
            return log_path.read_text(encoding="utf-8") if log_path.exists() else "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        except Exception as e:
            return f"ãƒ­ã‚°èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {str(e)}"

# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
if __name__ == "__main__":
    if not app:
        print("FastMCP ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚MCPãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", file=sys.stderr)
        exit(1)
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º
    version_info = get_version_info()
    logger.info(f"CoreThink-MCP ã‚µãƒ¼ãƒãƒ¼ v{version_info['version']} ã‚’èµ·å‹•ä¸­...")
    logger.info(f"CoreThinkè«–æ–‡: {version_info['corethink_paper']}")
    logger.info(f"åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«: {CONSTRAINTS_FILE}")
    logger.info(f"ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆ: {REPO_ROOT}")
    logger.info(f"ä½¿ç”¨ãƒãƒ¼ãƒˆ: {AVAILABLE_PORT}")
    
    # ãƒãƒ¼ãƒˆå¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®è­¦å‘Š
    if AVAILABLE_PORT != PREFERRED_PORT:
        logger.warning(f"æ³¨æ„: å¸Œæœ›ãƒãƒ¼ãƒˆ {PREFERRED_PORT} ã¯ä½¿ç”¨ä¸­ã®ãŸã‚ã€ãƒãƒ¼ãƒˆ {AVAILABLE_PORT} ã‚’ä½¿ç”¨ã—ã¾ã™")
        logger.info(f"è¨­å®šã‚’æ›´æ–°ã™ã‚‹ã«ã¯ã€ç’°å¢ƒå¤‰æ•° CORETHINK_PORT={AVAILABLE_PORT} ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    
    # STDIOæ¥ç¶šã®èª¬æ˜
    logger.info("ğŸ“¡ STDIOæ¥ç¶šã‚’å¾…æ©Ÿä¸­...")
    logger.info("ğŸ’¡ ã“ã®ã‚µãƒ¼ãƒãƒ¼ã¯VS Codeã‚„Claude Desktopã‹ã‚‰ã®MCPæ¥ç¶šã‚’å—ã‘ä»˜ã‘ã¾ã™")
    logger.info("â¹ï¸  çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    
    # FastMCPã‚µãƒ¼ãƒãƒ¼ã‚’å®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
    try:
        logger.info("FastMCP STDIOã‚µãƒ¼ãƒãƒ¼ã‚’é–‹å§‹ã—ã¾ã™...")
        app.run()
    except (KeyboardInterrupt, asyncio.CancelledError):
        logger.info("âœ… ã‚µãƒ¼ãƒãƒ¼ãŒæ­£å¸¸ã«åœæ­¢ã•ã‚Œã¾ã—ãŸï¼ˆCtrl+Cï¼‰")
    except Exception as e:
        logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        exit(1)
    finally:
        logger.info("ğŸ CoreThink-MCP ã‚µãƒ¼ãƒãƒ¼ã‚’çµ‚äº†ã—ã¾ã™")
